{
  
    
        "post0": {
            "title": "(9주차) 11월2일 -- draft",
            "content": "ref . Cairo, A. Functional Art, The: An Introduction to Information Graphics and Visualization, New Riders, 2012. San Francisco, US. . - ((일반적생각, 카이로의 생각), 제 생각)으로 나누어서 설명 . Presentation vs Exploration . Presentation . . - 프리젠테이션방식의 시각화는 화자가 다듬은 이야기를 전달하기에 좋은 시각화이다. 즉 잘 정리된 메시지를 전달하기에 좋다. . Exploration . . 문학적유기체라는 작품이다. 링크. | 어떤 소설책을 시각화. | 수형도 + 칼라 | 수형도의 의미: 단원, 문단, 문장, 단어 (수형도 계층적 구조를 시각화 하기에 뛰어남. ex: 리그레션트리!) | 색깔: 여행, 음악, 파티 등 소설에서 자주 등장하는 소재 (색은 범주형 변수를 표현하기에 뛰어남) | . - 익스플로래이션 방식은 독자가 스스로 그림에서 메시지를 찾아낸다. . - 소설을 읽어보지 않은 사람: 이 그래픽으로 소설책의 전체 주제를 미리 파악가능 . - 소설을 이미 읽어본 사람: 분석 &amp; 탐구를 할 수 있음. ex: 파티와 음악이 동시에 등장하는 경우가 많다. . &#51208;&#52649; . - 카이로: 사실 프리젠테이션과 익스플로레이션은 절충가능함 . . aes(x=&#39;GDP&#39;,y=&#39;불평등&#39;,text=&#39;년도&#39;,color=&#39;정부&#39;) | 초록색정부: 소득이 증가 &amp; 불평등이 훨씬 더 증가 | 갈색정부: 매우 빠른 경제 성장 | 포인트간의 간격이 조밀하다 = 변화가 더디다 // 포인트간의 간격이 넓다 = 변화가 빠르다. | . - 언뜻보기에는 우리에게 익숙한 라인플랏인듯 보이지만 의외로 정보를 해석할만한 요소가 있다. . 익스플로레이션형의 그래프는 그릴줄도 알아야 하지만 남이 그린 그래프를 해석할 수도 있어야함. . &#47700;&#49884;&#51648;&#47484; &#46263;&#48155;&#52840;&#54616;&#45716; &#44536;&#47548;&#51012; &#44536;&#47140;&#50556; &#54620;&#45796; . &#51064;&#44396;&#47928;&#51228;&#50640; &#45824;&#54620; &#54200;&#44204; . - 주장1: 가난한 나라에서 애를 너무 많이 낳음 $ to$ 세계인구가 90억까지 증가할 것이다. (현재 70억) . - 주장2: 잘사는 나라에서는 애를 적게 낳음 $ to$ 고령화 문제 . &#47532;&#46308;&#47532;&#51032; &#47700;&#49884;&#51648; . - 둘다 틀렸다. . - (내가 해보니까) 가난한 나라의 출산율은 점점 감소 . - (내가 해보니까) 잘사는 나라의 출산율은 점점 증가 . - 결국 세계의 인구는 안정화 될 것 (증가하지도 감소하지도 않는다) . - 아래의 그림이 그 증거이다. . . &#52852;&#51060;&#47196; . - 리들러의 메시지는 아래의 그림들이 더 잘 전달한다. . . 스웨덴, 노르웨이 -&gt; 출산률 증가 | 브라질, 인도 -&gt; 출산률 대폭감소 | . &#49548;&#44048; . - 어떠한 통계량 혹은 현상을 살펴볼때 그것의 부분집합들이 역시 그러한지 살펴보는것은 기본임 (그룹별로 파악하면 정반대의 결과가 나올 수 있음) . - 중요한 선을 제외한 나머지는 회색처리(일러스트레이터 사용) 한 것이 시각적으로 우수하며, 인상적이었음 . - 과학적인 논문작업에 들어갈 그림이라면 임의로 회색처리한 것이 다소 비판을 받을 수 있음. . . &#55141;&#48120;&#47196;&#50868; &#51088;&#47308;&#50752; &#53952;&#47536;&#54644;&#49437; . . Left: aes(x=&#39;출산율&#39;, y=&#39;수입&#39;) | Right: aes(x=&#39;출산율&#39;, y=&#39;전체 중학생중 여학생이 차지하는 비율&#39;) | . - 해설: 당신이 부자가 될수록 당신은 더 적은 아이를 가질 것이다 + 중학교에 진학하는 여성이 적을수록 아이를 많이 낳는다. (그림밑에 주석을 해석) . - 여학생들을 중학교에 보내지 않으면 출산율이 올라가나요??? . &#50696;&#49244;&#44536;&#47548;&#51012; &#44536;&#47532;&#47140;&#45796;&#44032; &#47700;&#49884;&#51648;&#44032; &#55120;&#47140;&#51648;&#51648; &#50506;&#46020;&#47197; &#54616;&#46972; . &#49324;&#47168;1: &#45224;&#48120;&#44397;&#44032;&#51032; &#44397;&#48169;&#47141; . - 아래는 남미국가들의 국방력을 시각화한 그림 . . 쓸모없는 그래픽 | 뭐 기억나는 것이 있나요? | . - 아래가 더 우수한 그림이다. 더 정확한 비교를 할 수 있어요. . . - 그리고 위의 그림보다 아래의 그림이 더 우수한 시각화이다. . . 브라질이 국방력도 우수하고 예산도 많이 투자하는 것 같지만 인구가 흑막인것 같다. | . - 흑막을 제거 . . - 최종적으로 제안하는 그래프 . . 좌측하단: aes(x=&#39;인구&#39;, y=&#39;군인수&#39;, size=&#39;예산&#39;) | 우측하단: 관심있는 그래프가 아님 | . 사실 저는 좌측하단의 그래프가 좋은 시각화라고 생각안해요 . - 1사분면의 의미: 인구도 높고 군인수도 많은 나라 (똑같은 정보임 의미가 없다. 마치 x축이 토익점수, y축이 텝스점수 같은느낌임) . 모든 점들이 직선에 몰려있다면? $ to$ 왜 2차원으로 표현함? | . - 저같으면 aes(x=&#39;예산(인구효과제거)&#39;, y=&#39;군인수(인구효과제거)&#39;,size=&#39;인구&#39;)로 할것 같아요. . 1사분면의 의미: 예산도 많이 쓰고 군인수도 많은나라 = 콜롬비아. | 4사분면의 의미: 예산은 많이 쓰는데 군인수가 적은나라 = 브라질 | . - 산점도에서 데이터를 한눈에 파악하고 특징을 요약하기 위해서는 X,Y를 너무 비슷한 성질의 변수로 설정하지마라. . 아래중 어떤것이 더 바람직한 그래프인가? . aes(x=&#39;토익&#39;, y=&#39;텝스&#39;, color=&#39;합/불&#39;, shape=&#39;회사의종류&#39;) | aes(x=&#39;토익&#39;, y=&#39;GPA&#39;, color=&#39;합/불&#39;, shape=&#39;회사의종류&#39;) | . &#49324;&#47168;2: &#49828;&#54168;&#51064;&#51032; &#49892;&#50629;&#47456; . . 명암으로 왜 크기비교를 하는것인가? | . - 비교를 위해서는 바플랏이 더 우수하다. . . &#49324;&#47168;3: &#48260;&#48660;&#51032; &#45224;&#50857; . - 카이로교수님의 강의자료에 등장하는 그림 . - 회색이 befor, 검은색이 after . . 크기비교는 바플랏으로 하는것이 아니다. | . - 우리눈은 작원원이 큰원의 절반정도 차지한다고 느껴진다. . . - 그렇지만 실제로는 아래와 같음 . . - 버블차트는 크기를 왜곡시킨다. . . - 하지만 아래의 버블차트는 우수하다. . . - 선거지도는 수치비교에 별로 관심이 없다. . - 대신에 민주당표와 공화당표가 어떤 지역에 몰렸는지 파악하는 것이중요 . - 따라서 aes중 가장 중요한 x,y를 모두 지역에 투자함 . . &#46972;&#51064;&#54540;&#46991;, &#48148;&#54540;&#46991;, &#49328;&#51216;&#46020; . - 시간경과에 따른 변화를 보여주고 싶으면 라인플랏, 비교를 하고 싶다면 바플랏, 관계를 알고싶다면 산점도. . .",
            "url": "https://guebin.github.io/DV2022/2022/11/02/(9%EC%A3%BC%EC%B0%A8)-11%EC%9B%942%EC%9D%BC.html",
            "relUrl": "/2022/11/02/(9%EC%A3%BC%EC%B0%A8)-11%EC%9B%942%EC%9D%BC.html",
            "date": " • Nov 2, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "draft",
            "content": "Make tidy data . - 느낌: ggplot으로 그림 그리기 좋은 데이터 + pandas로 query, group by 등을 쓰기 좋은 자료 . - 정의: https://r4ds.had.co.nz/tidy-data.html . Each variable must have its own column. | Each observation must have its own row. | Each value must have its own cell. | . 예시1 (tidy data) . obs x y shape color . 0 | 0 | 0 | &#39;star&#39; | &#39;F&#39; | . 1 | 0 | 1 | &#39;circ&#39; | &#39;F&#39; | . 2 | 1 | 0 | &#39;star&#39; | &#39;M&#39; | . 3 | 1 | 1 | &#39;circ&#39; | &#39;M&#39; | . 예시2 (tidy data x) . shape=star shape=circ . color=F | (0,0) | (0,1) | . color=M | (1,0) | (1,1) | . &#50696;&#51228; . - https://raw.githubusercontent.com/PacktPublishing/Pandas-Cookbook/master/data/state_fruit.csv . &#54400;&#51060;1: stack + reset_index . - 문제의 깃헙주소로 들어가서 데이터를 관찰 $ to$ 좌측상단이 비워져있음 $ to$ index_col=0 옵션을 사용 . df=pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/phone.csv&#39;,index_col=0) df . Samsung Apple Huawei Xiaomi Oppo Mobicel Motorola LG Others Realme Google Nokia Lenovo OnePlus Sony Asus . Date . 2019-10 461 | 324 | 136 | 109 | 76 | 81 | 43 | 37 | 135 | 28 | 39 | 14 | 22 | 17 | 20 | 17 | . 2019-11 461 | 358 | 167 | 141 | 86 | 61 | 29 | 36 | 141 | 27 | 29 | 20 | 23 | 10 | 19 | 27 | . 2019-12 426 | 383 | 143 | 105 | 53 | 45 | 51 | 48 | 129 | 30 | 20 | 26 | 28 | 18 | 18 | 19 | . 2020-01 677 | 494 | 212 | 187 | 110 | 79 | 65 | 49 | 158 | 23 | 13 | 19 | 19 | 22 | 27 | 22 | . 2020-02 593 | 520 | 217 | 195 | 112 | 67 | 62 | 71 | 157 | 25 | 18 | 16 | 24 | 18 | 23 | 20 | . 2020-03 637 | 537 | 246 | 187 | 92 | 66 | 59 | 67 | 145 | 21 | 16 | 24 | 18 | 31 | 22 | 14 | . 2020-04 647 | 583 | 222 | 154 | 98 | 59 | 48 | 64 | 113 | 20 | 23 | 25 | 19 | 19 | 23 | 21 | . 2020-05 629 | 518 | 192 | 176 | 91 | 87 | 50 | 66 | 150 | 43 | 27 | 15 | 18 | 19 | 19 | 13 | . 2020-06 663 | 552 | 209 | 185 | 93 | 69 | 54 | 60 | 140 | 39 | 16 | 16 | 17 | 29 | 25 | 16 | . 2020-07 599 | 471 | 214 | 193 | 89 | 78 | 65 | 59 | 130 | 40 | 27 | 25 | 21 | 18 | 18 | 12 | . 2020-08 615 | 567 | 204 | 182 | 105 | 82 | 62 | 42 | 129 | 47 | 16 | 23 | 21 | 27 | 23 | 20 | . 2020-09 621 | 481 | 230 | 220 | 102 | 88 | 56 | 49 | 143 | 54 | 14 | 15 | 17 | 15 | 19 | 15 | . 2020-10 637 | 555 | 232 | 203 | 90 | 52 | 63 | 49 | 140 | 33 | 17 | 20 | 22 | 9 | 22 | 21 | . url = &#39;https://raw.githubusercontent.com/PacktPublishing/Pandas-Cookbook/master/data/state_fruit.csv&#39; df=pd.read_csv(url,index_col=0) df . Apple Orange Banana . Texas 12 | 10 | 40 | . Arizona 9 | 7 | 12 | . Florida 0 | 14 | 190 | . - 데이터변형 . df.stack() . Date 2019-10 Samsung 461 Apple 324 Huawei 136 Xiaomi 109 Oppo 76 ... 2020-10 Nokia 20 Lenovo 22 OnePlus 9 Sony 22 Asus 21 Length: 208, dtype: int64 . df.stack().reset_index() . Date level_1 0 . 0 2019-10 | Samsung | 461 | . 1 2019-10 | Apple | 324 | . 2 2019-10 | Huawei | 136 | . 3 2019-10 | Xiaomi | 109 | . 4 2019-10 | Oppo | 76 | . ... ... | ... | ... | . 203 2020-10 | Nokia | 20 | . 204 2020-10 | Lenovo | 22 | . 205 2020-10 | OnePlus | 9 | . 206 2020-10 | Sony | 22 | . 207 2020-10 | Asus | 21 | . 208 rows × 3 columns . df.stack().reset_index().rename(columns={&#39;level_0&#39;:&#39;group1&#39;,&#39;level_1&#39;:&#39;group2&#39;,0:&#39;X&#39;}) . Date group2 X . 0 2019-10 | Samsung | 461 | . 1 2019-10 | Apple | 324 | . 2 2019-10 | Huawei | 136 | . 3 2019-10 | Xiaomi | 109 | . 4 2019-10 | Oppo | 76 | . ... ... | ... | ... | . 203 2020-10 | Nokia | 20 | . 204 2020-10 | Lenovo | 22 | . 205 2020-10 | OnePlus | 9 | . 206 2020-10 | Sony | 22 | . 207 2020-10 | Asus | 21 | . 208 rows × 3 columns . &#54400;&#51060;2: melt(id_vars=??) . - index_col=0 옵션을 사용하지않음 . url = &#39;https://raw.githubusercontent.com/PacktPublishing/Pandas-Cookbook/master/data/state_fruit.csv&#39; df2=pd.read_csv(url) df2 . Unnamed: 0 Apple Orange Banana . 0 Texas | 12 | 10 | 40 | . 1 Arizona | 9 | 7 | 12 | . 2 Florida | 0 | 14 | 190 | . df2.rename(columns={&#39;Unnamed: 0&#39;:&#39;group1&#39;}) . group1 Apple Orange Banana . 0 Texas | 12 | 10 | 40 | . 1 Arizona | 9 | 7 | 12 | . 2 Florida | 0 | 14 | 190 | . df2.rename(columns={&#39;Unnamed: 0&#39;:&#39;group1&#39;}).melt(id_vars=&#39;group1&#39;) . group1 variable value . 0 Texas | Apple | 12 | . 1 Arizona | Apple | 9 | . 2 Florida | Apple | 0 | . 3 Texas | Orange | 10 | . 4 Arizona | Orange | 7 | . 5 Florida | Orange | 14 | . 6 Texas | Banana | 40 | . 7 Arizona | Banana | 12 | . 8 Florida | Banana | 190 | . df2.rename(columns={&#39;Unnamed: 0&#39;:&#39;group1&#39;}).melt(id_vars=&#39;group1&#39;) .rename(columns={&#39;variable&#39;:&#39;group2&#39;,&#39;value&#39;:&#39;X&#39;}) . group1 group2 X . 0 Texas | Apple | 12 | . 1 Arizona | Apple | 9 | . 2 Florida | Apple | 0 | . 3 Texas | Orange | 10 | . 4 Arizona | Orange | 7 | . 5 Florida | Orange | 14 | . 6 Texas | Banana | 40 | . 7 Arizona | Banana | 12 | . 8 Florida | Banana | 190 | . &#53952;&#47536;&#54400;&#51060;1 . df . Samsung Apple Huawei Xiaomi Oppo Mobicel Motorola LG Others Realme Google Nokia Lenovo OnePlus Sony Asus . Date . 2019-10 461 | 324 | 136 | 109 | 76 | 81 | 43 | 37 | 135 | 28 | 39 | 14 | 22 | 17 | 20 | 17 | . 2019-11 461 | 358 | 167 | 141 | 86 | 61 | 29 | 36 | 141 | 27 | 29 | 20 | 23 | 10 | 19 | 27 | . 2019-12 426 | 383 | 143 | 105 | 53 | 45 | 51 | 48 | 129 | 30 | 20 | 26 | 28 | 18 | 18 | 19 | . 2020-01 677 | 494 | 212 | 187 | 110 | 79 | 65 | 49 | 158 | 23 | 13 | 19 | 19 | 22 | 27 | 22 | . 2020-02 593 | 520 | 217 | 195 | 112 | 67 | 62 | 71 | 157 | 25 | 18 | 16 | 24 | 18 | 23 | 20 | . 2020-03 637 | 537 | 246 | 187 | 92 | 66 | 59 | 67 | 145 | 21 | 16 | 24 | 18 | 31 | 22 | 14 | . 2020-04 647 | 583 | 222 | 154 | 98 | 59 | 48 | 64 | 113 | 20 | 23 | 25 | 19 | 19 | 23 | 21 | . 2020-05 629 | 518 | 192 | 176 | 91 | 87 | 50 | 66 | 150 | 43 | 27 | 15 | 18 | 19 | 19 | 13 | . 2020-06 663 | 552 | 209 | 185 | 93 | 69 | 54 | 60 | 140 | 39 | 16 | 16 | 17 | 29 | 25 | 16 | . 2020-07 599 | 471 | 214 | 193 | 89 | 78 | 65 | 59 | 130 | 40 | 27 | 25 | 21 | 18 | 18 | 12 | . 2020-08 615 | 567 | 204 | 182 | 105 | 82 | 62 | 42 | 129 | 47 | 16 | 23 | 21 | 27 | 23 | 20 | . 2020-09 621 | 481 | 230 | 220 | 102 | 88 | 56 | 49 | 143 | 54 | 14 | 15 | 17 | 15 | 19 | 15 | . 2020-10 637 | 555 | 232 | 203 | 90 | 52 | 63 | 49 | 140 | 33 | 17 | 20 | 22 | 9 | 22 | 21 | . df.melt() . variable value . 0 Samsung | 461 | . 1 Samsung | 461 | . 2 Samsung | 426 | . 3 Samsung | 677 | . 4 Samsung | 593 | . ... ... | ... | . 203 Asus | 16 | . 204 Asus | 12 | . 205 Asus | 20 | . 206 Asus | 15 | . 207 Asus | 21 | . 208 rows × 2 columns . &#53952;&#47536;&#54400;&#51060;2 . df2 . Unnamed: 0 Apple Orange Banana . 0 Texas | 12 | 10 | 40 | . 1 Arizona | 9 | 7 | 12 | . 2 Florida | 0 | 14 | 190 | . df2.stack() . 0 Unnamed: 0 Texas Apple 12 Orange 10 Banana 40 1 Unnamed: 0 Arizona Apple 9 Orange 7 Banana 12 2 Unnamed: 0 Florida Apple 0 Orange 14 Banana 190 dtype: object . &#54400;&#51060;3 . df . Samsung Apple Huawei Xiaomi Oppo Mobicel Motorola LG Others Realme Google Nokia Lenovo OnePlus Sony Asus . Date . 2019-10 461 | 324 | 136 | 109 | 76 | 81 | 43 | 37 | 135 | 28 | 39 | 14 | 22 | 17 | 20 | 17 | . 2019-11 461 | 358 | 167 | 141 | 86 | 61 | 29 | 36 | 141 | 27 | 29 | 20 | 23 | 10 | 19 | 27 | . 2019-12 426 | 383 | 143 | 105 | 53 | 45 | 51 | 48 | 129 | 30 | 20 | 26 | 28 | 18 | 18 | 19 | . 2020-01 677 | 494 | 212 | 187 | 110 | 79 | 65 | 49 | 158 | 23 | 13 | 19 | 19 | 22 | 27 | 22 | . 2020-02 593 | 520 | 217 | 195 | 112 | 67 | 62 | 71 | 157 | 25 | 18 | 16 | 24 | 18 | 23 | 20 | . 2020-03 637 | 537 | 246 | 187 | 92 | 66 | 59 | 67 | 145 | 21 | 16 | 24 | 18 | 31 | 22 | 14 | . 2020-04 647 | 583 | 222 | 154 | 98 | 59 | 48 | 64 | 113 | 20 | 23 | 25 | 19 | 19 | 23 | 21 | . 2020-05 629 | 518 | 192 | 176 | 91 | 87 | 50 | 66 | 150 | 43 | 27 | 15 | 18 | 19 | 19 | 13 | . 2020-06 663 | 552 | 209 | 185 | 93 | 69 | 54 | 60 | 140 | 39 | 16 | 16 | 17 | 29 | 25 | 16 | . 2020-07 599 | 471 | 214 | 193 | 89 | 78 | 65 | 59 | 130 | 40 | 27 | 25 | 21 | 18 | 18 | 12 | . 2020-08 615 | 567 | 204 | 182 | 105 | 82 | 62 | 42 | 129 | 47 | 16 | 23 | 21 | 27 | 23 | 20 | . 2020-09 621 | 481 | 230 | 220 | 102 | 88 | 56 | 49 | 143 | 54 | 14 | 15 | 17 | 15 | 19 | 15 | . 2020-10 637 | 555 | 232 | 203 | 90 | 52 | 63 | 49 | 140 | 33 | 17 | 20 | 22 | 9 | 22 | 21 | . df.reset_index() . Date Samsung Apple Huawei Xiaomi Oppo Mobicel Motorola LG Others Realme Google Nokia Lenovo OnePlus Sony Asus . 0 2019-10 | 461 | 324 | 136 | 109 | 76 | 81 | 43 | 37 | 135 | 28 | 39 | 14 | 22 | 17 | 20 | 17 | . 1 2019-11 | 461 | 358 | 167 | 141 | 86 | 61 | 29 | 36 | 141 | 27 | 29 | 20 | 23 | 10 | 19 | 27 | . 2 2019-12 | 426 | 383 | 143 | 105 | 53 | 45 | 51 | 48 | 129 | 30 | 20 | 26 | 28 | 18 | 18 | 19 | . 3 2020-01 | 677 | 494 | 212 | 187 | 110 | 79 | 65 | 49 | 158 | 23 | 13 | 19 | 19 | 22 | 27 | 22 | . 4 2020-02 | 593 | 520 | 217 | 195 | 112 | 67 | 62 | 71 | 157 | 25 | 18 | 16 | 24 | 18 | 23 | 20 | . 5 2020-03 | 637 | 537 | 246 | 187 | 92 | 66 | 59 | 67 | 145 | 21 | 16 | 24 | 18 | 31 | 22 | 14 | . 6 2020-04 | 647 | 583 | 222 | 154 | 98 | 59 | 48 | 64 | 113 | 20 | 23 | 25 | 19 | 19 | 23 | 21 | . 7 2020-05 | 629 | 518 | 192 | 176 | 91 | 87 | 50 | 66 | 150 | 43 | 27 | 15 | 18 | 19 | 19 | 13 | . 8 2020-06 | 663 | 552 | 209 | 185 | 93 | 69 | 54 | 60 | 140 | 39 | 16 | 16 | 17 | 29 | 25 | 16 | . 9 2020-07 | 599 | 471 | 214 | 193 | 89 | 78 | 65 | 59 | 130 | 40 | 27 | 25 | 21 | 18 | 18 | 12 | . 10 2020-08 | 615 | 567 | 204 | 182 | 105 | 82 | 62 | 42 | 129 | 47 | 16 | 23 | 21 | 27 | 23 | 20 | . 11 2020-09 | 621 | 481 | 230 | 220 | 102 | 88 | 56 | 49 | 143 | 54 | 14 | 15 | 17 | 15 | 19 | 15 | . 12 2020-10 | 637 | 555 | 232 | 203 | 90 | 52 | 63 | 49 | 140 | 33 | 17 | 20 | 22 | 9 | 22 | 21 | . df.reset_index().melt(id_vars=&#39;index&#39;) . KeyError Traceback (most recent call last) ~/anaconda3/envs/py37/lib/python3.7/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance) 3360 try: -&gt; 3361 return self._engine.get_loc(casted_key) 3362 except KeyError as err: ~/anaconda3/envs/py37/lib/python3.7/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc() ~/anaconda3/envs/py37/lib/python3.7/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc() pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item() pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item() KeyError: &#39;index&#39; The above exception was the direct cause of the following exception: KeyError Traceback (most recent call last) /tmp/ipykernel_1920834/2325455802.py in &lt;module&gt; -&gt; 1 df.reset_index().melt(id_vars=&#39;index&#39;) ~/anaconda3/envs/py37/lib/python3.7/site-packages/pandas/core/frame.py in melt(self, id_vars, value_vars, var_name, value_name, col_level, ignore_index) 8344 value_name=value_name, 8345 col_level=col_level, -&gt; 8346 ignore_index=ignore_index, 8347 ) 8348 ~/anaconda3/envs/py37/lib/python3.7/site-packages/pandas/core/reshape/melt.py in melt(frame, id_vars, value_vars, var_name, value_name, col_level, ignore_index) 135 mdata = {} 136 for col in id_vars: --&gt; 137 id_data = frame.pop(col) 138 if is_extension_array_dtype(id_data): 139 id_data = cast(&#34;Series&#34;, concat([id_data] * K, ignore_index=True)) ~/anaconda3/envs/py37/lib/python3.7/site-packages/pandas/core/frame.py in pop(self, item) 5224 3 monkey NaN 5225 &#34;&#34;&#34; -&gt; 5226 return super().pop(item=item) 5227 5228 @doc(NDFrame.replace, **_shared_doc_kwargs) ~/anaconda3/envs/py37/lib/python3.7/site-packages/pandas/core/generic.py in pop(self, item) 868 869 def pop(self, item: Hashable) -&gt; Series | Any: --&gt; 870 result = self[item] 871 del self[item] 872 ~/anaconda3/envs/py37/lib/python3.7/site-packages/pandas/core/frame.py in __getitem__(self, key) 3456 if self.columns.nlevels &gt; 1: 3457 return self._getitem_multilevel(key) -&gt; 3458 indexer = self.columns.get_loc(key) 3459 if is_integer(indexer): 3460 indexer = [indexer] ~/anaconda3/envs/py37/lib/python3.7/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance) 3361 return self._engine.get_loc(casted_key) 3362 except KeyError as err: -&gt; 3363 raise KeyError(key) from err 3364 3365 if is_scalar(key) and isna(key) and not self.hasnans: KeyError: &#39;index&#39; . df.reset_index().melt(id_vars=&#39;index&#39;) .rename(columns={&#39;index&#39;:&#39;group1&#39;,&#39;variable&#39;:&#39;group2&#39;,&#39;value&#39;:&#39;X&#39;}) . group1 group2 X . 0 Texas | Apple | 12 | . 1 Arizona | Apple | 9 | . 2 Florida | Apple | 0 | . 3 Texas | Orange | 10 | . 4 Arizona | Orange | 7 | . 5 Florida | Orange | 14 | . 6 Texas | Banana | 40 | . 7 Arizona | Banana | 12 | . 8 Florida | Banana | 190 | . &#54400;&#51060;4 . df2.set_index(&#39;Unnamed: 0&#39;) . Apple Orange Banana . Unnamed: 0 . Texas 12 | 10 | 40 | . Arizona 9 | 7 | 12 | . Florida 0 | 14 | 190 | . df2.set_index(&#39;Unnamed: 0&#39;).stack() . Unnamed: 0 Texas Apple 12 Orange 10 Banana 40 Arizona Apple 9 Orange 7 Banana 12 Florida Apple 0 Orange 14 Banana 190 dtype: int64 . df2.set_index(&#39;Unnamed: 0&#39;).stack().reset_index() . Unnamed: 0 level_1 0 . 0 Texas | Apple | 12 | . 1 Texas | Orange | 10 | . 2 Texas | Banana | 40 | . 3 Arizona | Apple | 9 | . 4 Arizona | Orange | 7 | . 5 Arizona | Banana | 12 | . 6 Florida | Apple | 0 | . 7 Florida | Orange | 14 | . 8 Florida | Banana | 190 | . df2.set_index(&#39;Unnamed: 0&#39;).stack().reset_index() .rename(columns={&#39;Unnamed: 0&#39;:&#39;group1&#39;,&#39;level_1&#39;:&#39;group2&#39;,0:&#39;X&#39;}) . group1 group2 X . 0 Texas | Apple | 12 | . 1 Texas | Orange | 10 | . 2 Texas | Banana | 40 | . 3 Arizona | Apple | 9 | . 4 Arizona | Orange | 7 | . 5 Arizona | Banana | 12 | . 6 Florida | Apple | 0 | . 7 Florida | Orange | 14 | . 8 Florida | Banana | 190 | . Barplot + &#54644;&#46308;&#47532;&#50948;&#52980;&#51032; &#44536;&#47000;&#54532;&#47112;&#51060;&#50612; . &#44592;&#48376;&#49324;&#50857;&#48277; . g=[&#39;A&#39;]*100+[&#39;B&#39;]*200 y=list(np.random.randn(100)*2+2)+list(np.random.randn(200)+3) df=pd.DataFrame({&#39;g&#39;:g,&#39;y&#39;:y}) df . g y . 0 A | -1.594055 | . 1 A | 1.225490 | . 2 A | 2.223234 | . 3 A | 1.842460 | . 4 A | 1.624541 | . ... ... | ... | . 295 B | 3.011681 | . 296 B | 3.558141 | . 297 B | 4.348230 | . 298 B | 3.966407 | . 299 B | 2.694083 | . 300 rows × 2 columns . ggplot(df)+geom_bar(aes(x=&#39;g&#39;,fill=&#39;g&#39;)) ## 디폴트로 카운트를 수행해줌 . &lt;ggplot: (8726962443840)&gt; . - 이것은 아래의 코드와 같다. . df.groupby(by=&#39;g&#39;).count() . y . g . A 100 | . B 200 | . fig=ggplot(df.groupby(by=&#39;g&#39;).count().reset_index()) fig+geom_bar(aes(x=&#39;g&#39;,y=&#39;y&#39;,fill=&#39;g&#39;),stat=&#39;identity&#39;) . &lt;ggplot: (8726962432681)&gt; . - barplot은 기본적으로 groupby+count()가 내장되어 있다. 따라서 아래의 코드 . ggplot(df)+geom_bar(aes(x=&#39;g&#39;,fill=&#39;g&#39;)) ## 디폴트로 카운트를 수행해줌 . 를 좀더 엄밀하게 쓰면 . ggplot(df)+geom_bar(aes(x=&#39;g&#39;,fill=&#39;g&#39;),stat=&#39;count&#39;) . &lt;ggplot: (8726962477975)&gt; . - 이것은 때때로 불편하다. 왜냐하면 데이터프레임을 변환하는 것은 판다스를 이용하는게 더 쉽고 자유로움 . barplot&#51032; &#48520;&#54200;&#54620;&#51216;1 . td=df.groupby(by=&#39;g&#39;).count().reset_index() td . g y . 0 A | 100 | . 1 B | 200 | . - 그냥 &#39;x=g, y=y&#39;를 맵핑하여 그리면 안되나? . plt.bar(td.g,td.y) . &lt;BarContainer object of 2 artists&gt; . td.plot(kind=&#39;bar&#39;,x=&#39;g&#39;,y=&#39;y&#39;) . &lt;AxesSubplot:xlabel=&#39;g&#39;&gt; . - 그런데 ggplot을 쓰려고 하면? . ggplot(td)+geom_bar(aes(x=&#39;g&#39;,y=&#39;y&#39;,fill=&#39;g&#39;)) . PlotnineError Traceback (most recent call last) ~/anaconda3/envs/dv2021/lib/python3.8/site-packages/IPython/core/formatters.py in __call__(self, obj) 700 type_pprinters=self.type_printers, 701 deferred_pprinters=self.deferred_printers) --&gt; 702 printer.pretty(obj) 703 printer.flush() 704 return stream.getvalue() ~/anaconda3/envs/dv2021/lib/python3.8/site-packages/IPython/lib/pretty.py in pretty(self, obj) 392 if cls is not object 393 and callable(cls.__dict__.get(&#39;__repr__&#39;)): --&gt; 394 return _repr_pprint(obj, self, cycle) 395 396 return _default_pprint(obj, self, cycle) ~/anaconda3/envs/dv2021/lib/python3.8/site-packages/IPython/lib/pretty.py in _repr_pprint(obj, p, cycle) 698 &#34;&#34;&#34;A pprint that just redirects to the normal repr function.&#34;&#34;&#34; 699 # Find newlines and replace them with p.break_() --&gt; 700 output = repr(obj) 701 lines = output.splitlines() 702 with p.group(): ~/anaconda3/envs/dv2021/lib/python3.8/site-packages/plotnine/ggplot.py in __repr__(self) 95 Print/show the plot 96 &#34;&#34;&#34; &gt; 97 self.__str__() 98 return &#39;&lt;ggplot: (%d)&gt;&#39; % self.__hash__() 99 ~/anaconda3/envs/dv2021/lib/python3.8/site-packages/plotnine/ggplot.py in __str__(self) 86 Print/show the plot 87 &#34;&#34;&#34; &gt; 88 self.draw(show=True) 89 90 # Return and empty string so that print(p) is &#34;pretty&#34; ~/anaconda3/envs/dv2021/lib/python3.8/site-packages/plotnine/ggplot.py in draw(self, return_ggplot, show) 203 self = deepcopy(self) 204 with plot_context(self, show=show): --&gt; 205 self._build() 206 207 # setup ~/anaconda3/envs/dv2021/lib/python3.8/site-packages/plotnine/ggplot.py in _build(self) 298 299 # Apply and map statistics --&gt; 300 layers.compute_statistic(layout) 301 layers.map_statistic(self) 302 ~/anaconda3/envs/dv2021/lib/python3.8/site-packages/plotnine/layer.py in compute_statistic(self, layout) 71 def compute_statistic(self, layout): 72 for l in self: &gt; 73 l.compute_statistic(layout) 74 75 def map_statistic(self, plot): ~/anaconda3/envs/dv2021/lib/python3.8/site-packages/plotnine/layer.py in compute_statistic(self, layout) 322 data = self.stat.use_defaults(data) 323 data = self.stat.setup_data(data) --&gt; 324 data = self.stat.compute_layer(data, params, layout) 325 self.data = data 326 ~/anaconda3/envs/dv2021/lib/python3.8/site-packages/plotnine/stats/stat.py in compute_layer(cls, data, params, layout) 274 return cls.compute_panel(pdata, pscales, **params) 275 --&gt; 276 return groupby_apply(data, &#39;PANEL&#39;, fn) 277 278 @classmethod ~/anaconda3/envs/dv2021/lib/python3.8/site-packages/plotnine/utils.py in groupby_apply(df, cols, func, *args, **kwargs) 632 # function fn should be free to modify dataframe d, therefore 633 # do not mark d as a slice of df i.e no SettingWithCopyWarning --&gt; 634 lst.append(func(d, *args, **kwargs)) 635 return pd.concat(lst, axis=axis, ignore_index=True) 636 ~/anaconda3/envs/dv2021/lib/python3.8/site-packages/plotnine/stats/stat.py in fn(pdata) 272 return pdata 273 pscales = layout.get_scales(pdata[&#39;PANEL&#39;].iat[0]) --&gt; 274 return cls.compute_panel(pdata, pscales, **params) 275 276 return groupby_apply(data, &#39;PANEL&#39;, fn) ~/anaconda3/envs/dv2021/lib/python3.8/site-packages/plotnine/stats/stat.py in compute_panel(cls, data, scales, **params) 305 stats = [] 306 for _, old in data.groupby(&#39;group&#39;): --&gt; 307 new = cls.compute_group(old, scales, **params) 308 unique = uniquecols(old) 309 missing = unique.columns.difference(new.columns) ~/anaconda3/envs/dv2021/lib/python3.8/site-packages/plotnine/stats/stat_count.py in compute_group(cls, data, scales, **params) 51 if (&#39;y&#39; in data) or (&#39;y&#39; in params): 52 msg = &#39;stat_count() must not be used with a y aesthetic&#39; &gt; 53 raise PlotnineError(msg) 54 55 weight = data.get(&#39;weight&#39;, np.ones(len(x), dtype=int)) PlotnineError: &#39;stat_count() must not be used with a y aesthetic&#39; . 너무 불편해요.. stat=&#39;identity&#39; 를 항상 써야하는것이! | . barplot&#51032; &#48520;&#54200;&#54620;&#51216;2 . - groupby 를 자동으로 해주므로 익숙해지면 ggplot2 방식이 더 편하지 않을까? $ to$ groupby 하는게 더 편해요.. . df.groupby(&#39;g&#39;).agg({&#39;y&#39;:[np.mean,np.median,np.std,lambda x: np.max(x)-np.min(x)]}) . y . mean median std &lt;lambda_0&gt; . g . A 1.805694 | 1.960777 | 2.060555 | 10.166683 | . B 2.900715 | 2.906418 | 1.004063 | 5.174041 | . df.groupby(&#39;g&#39;) .agg({&#39;y&#39;:[np.mean,np.median,np.std,lambda x: np.max(x)-np.min(x)]}) .rename(columns={&#39;&lt;lambda_0&gt;&#39;:&#39;range&#39;}).stack().reset_index() . g level_1 y . 0 A | mean | 1.805694 | . 1 A | median | 1.960777 | . 2 A | range | 10.166683 | . 3 A | std | 2.060555 | . 4 B | mean | 2.900715 | . 5 B | median | 2.906418 | . 6 B | range | 5.174041 | . 7 B | std | 1.004063 | . td=df.groupby(&#39;g&#39;) .agg({&#39;y&#39;:[np.mean,np.median,np.std,lambda x: np.max(x)-np.min(x)]}) .rename(columns={&#39;&lt;lambda_0&gt;&#39;:&#39;range&#39;}).stack().reset_index() . ggplot(td)+geom_bar(aes(x=&#39;level_1&#39;,y=&#39;y&#39;,fill=&#39;g&#39;),stat=&#39;identity&#39;) . &lt;ggplot: (8726959187327)&gt; . 쌓인상태로 보이는것이 불편함. $ to$ position=&#39;dodge&#39; 로! | . position . ggplot(td)+geom_bar(aes(x=&#39;level_1&#39;,y=&#39;y&#39;,fill=&#39;g&#39;),stat=&#39;identity&#39;,position=&#39;dodge&#39;) . &lt;ggplot: (8726958675716)&gt; . coord_flip() . - 때때로 아래와 같이 보는 것이 더 좋은 경우도 있음 . ggplot(td) +geom_bar(aes(x=&#39;level_1&#39;,y=&#39;y&#39;,fill=&#39;g&#39;),stat=&#39;identity&#39;,position=&#39;dodge&#39;) +coord_flip() . &lt;ggplot: (8726962202191)&gt; . facet_wrap() . ggplot(td) +geom_bar(aes(x=&#39;level_1&#39;,y=&#39;y&#39;,fill=&#39;g&#39;),stat=&#39;identity&#39;,position=&#39;dodge&#39;) +coord_flip()+facet_wrap(&#39;level_1&#39;) . &lt;ggplot: (8726962596675)&gt; . ggplot(td) +geom_bar(aes(x=&#39;g&#39;,y=&#39;y&#39;,fill=&#39;g&#39;),stat=&#39;identity&#39;,position=&#39;dodge&#39;) +coord_flip()+facet_wrap(&#39;level_1&#39;) . &lt;ggplot: (8726958748290)&gt; . ggplot(td)+facet_grid(&#39;level_1~g&#39;) +geom_bar(aes(x=&#39;g&#39;,y=&#39;y&#39;,fill=&#39;g&#39;),stat=&#39;identity&#39;,position=&#39;dodge&#39;)+coord_flip() . &lt;ggplot: (8726962231423)&gt; . &#54644;&#46308;&#47532;&#50948;&#52980;&#51032; &#44536;&#47000;&#54532;&#47112;&#51060;&#50612; . - 데이터셋 + 맵핑 + 지옴 + 포지션 + 스탯 + 축 + 면분할 . 데이터셋: 판다스 | 맵핑: x축, y축, 색깔, 크기, 투명도 | 지옴: 포인트지옴, 바지옴, 라인지옴, 스무스지옴 | 포지션: jitter, dodge, intentity | 스탯: identity, count | 축: coord_flip() | 면분할: facet_wrap(), facet_grid() | . &#49900;&#49832;&#51032; &#50669;&#49444; . DEP=([&#39;A1&#39;]*2+[&#39;A2&#39;]*2+[&#39;B1&#39;]*2+[&#39;B2&#39;]*2)*2 GEN=[&#39;M&#39;]*8+[&#39;F&#39;]*8 STATE=[&#39;PASS&#39;,&#39;FAIL&#39;]*8 COUNT=[1,9,2,8,80,20,85,15,5,5,5,5,9,1,9,1] . df=pd.DataFrame({&#39;DEP&#39;:DEP,&#39;STATE&#39;:STATE,&#39;GEN&#39;:GEN,&#39;COUNT&#39;:COUNT}) . df . DEP STATE GEN COUNT . 0 A1 | PASS | M | 1 | . 1 A1 | FAIL | M | 9 | . 2 A2 | PASS | M | 2 | . 3 A2 | FAIL | M | 8 | . 4 B1 | PASS | M | 80 | . 5 B1 | FAIL | M | 20 | . 6 B2 | PASS | M | 85 | . 7 B2 | FAIL | M | 15 | . 8 A1 | PASS | F | 5 | . 9 A1 | FAIL | F | 5 | . 10 A2 | PASS | F | 5 | . 11 A2 | FAIL | F | 5 | . 12 B1 | PASS | F | 9 | . 13 B1 | FAIL | F | 1 | . 14 B2 | PASS | F | 9 | . 15 B2 | FAIL | F | 1 | . df.groupby([&#39;GEN&#39;,&#39;STATE&#39;]).agg({&#39;COUNT&#39;:np.sum}) . COUNT . GEN STATE . F FAIL 12 | . PASS 28 | . M FAIL 52 | . PASS 168 | . &#49884;&#44033;&#54868;1: &#51204;&#52404;&#54633;&#44201;&#47456; . df.groupby([&#39;GEN&#39;,&#39;STATE&#39;]).agg({&#39;COUNT&#39;:np.sum}) . COUNT . GEN STATE . F FAIL 12 | . PASS 28 | . M FAIL 52 | . PASS 168 | . df.groupby([&#39;GEN&#39;,&#39;STATE&#39;]).agg({&#39;COUNT&#39;:np.sum}).reset_index() . GEN STATE COUNT . 0 F | FAIL | 12 | . 1 F | PASS | 28 | . 2 M | FAIL | 52 | . 3 M | PASS | 168 | . df.groupby([&#39;GEN&#39;]).agg({&#39;COUNT&#39;:np.sum}).reset_index() . GEN COUNT . 0 F | 40 | . 1 M | 220 | . - 두개의 데이터프레임을 합쳐야 한다. . _df1=df.groupby([&#39;GEN&#39;,&#39;STATE&#39;]).agg({&#39;COUNT&#39;:np.sum}).reset_index() _df2=df.groupby([&#39;GEN&#39;]).agg({&#39;COUNT&#39;:np.sum}).reset_index().rename(columns={&#39;COUNT&#39;:&#39;SUM&#39;}) . display(_df1) display(_df2) . GEN STATE COUNT . 0 F | FAIL | 12 | . 1 F | PASS | 28 | . 2 M | FAIL | 52 | . 3 M | PASS | 168 | . GEN SUM . 0 F | 40 | . 1 M | 220 | . - 단순한 방법 . def f(x): if x==&#39;F&#39;: return 40 if x==&#39;M&#39;: return 220 . _df1[&#39;SUM&#39;]=list(map(f,_df1.GEN)) _df1 . GEN STATE COUNT SUM . 0 F | FAIL | 12 | 40 | . 1 F | PASS | 28 | 40 | . 2 M | FAIL | 52 | 220 | . 3 M | PASS | 168 | 220 | . - 좀 더 좋은 방법 . _df1=df.groupby([&#39;GEN&#39;,&#39;STATE&#39;]).agg({&#39;COUNT&#39;:np.sum}).reset_index() . _df1를 다시 롤백 | . def f(_df2): return lambda x: _df2.query(&#39;GEN == @x&#39;).SUM.item() . _df1.GEN . 0 F 1 F 2 M 3 M Name: GEN, dtype: object . _df1[&#39;SUM&#39;]=list(map(f(_df2),_df1.GEN)) _df1 . GEN STATE COUNT SUM . 0 F | FAIL | 12 | 40 | . 1 F | PASS | 28 | 40 | . 2 M | FAIL | 52 | 220 | . 3 M | PASS | 168 | 220 | . - 더 좋은 방법 . _df1=df.groupby([&#39;GEN&#39;,&#39;STATE&#39;]).agg({&#39;COUNT&#39;:np.sum}).reset_index() . _df1을 다시 롤백 | . _df1 . GEN STATE COUNT . 0 F | FAIL | 12 | . 1 F | PASS | 28 | . 2 M | FAIL | 52 | . 3 M | PASS | 168 | . _df2 . GEN SUM . 0 F | 40 | . 1 M | 220 | . pd.merge(_df1,_df2) . GEN STATE COUNT SUM . 0 F | FAIL | 12 | 40 | . 1 F | PASS | 28 | 40 | . 2 M | FAIL | 52 | 220 | . 3 M | PASS | 168 | 220 | . _df1.merge(_df2) . GEN STATE COUNT SUM . 0 F | FAIL | 12 | 40 | . 1 F | PASS | 28 | 40 | . 2 M | FAIL | 52 | 220 | . 3 M | PASS | 168 | 220 | . _df2.merge(_df1) . GEN SUM STATE COUNT . 0 F | 40 | FAIL | 12 | . 1 F | 40 | PASS | 28 | . 2 M | 220 | FAIL | 52 | . 3 M | 220 | PASS | 168 | . td=_df2.merge(_df1) td . GEN SUM STATE COUNT . 0 F | 40 | FAIL | 12 | . 1 F | 40 | PASS | 28 | . 2 M | 220 | FAIL | 52 | . 3 M | 220 | PASS | 168 | . td[&#39;PROP&#39;]=td.COUNT/td.SUM . td . GEN SUM STATE COUNT PROP . 0 F | 40 | FAIL | 12 | 0.300000 | . 1 F | 40 | PASS | 28 | 0.700000 | . 2 M | 220 | FAIL | 52 | 0.236364 | . 3 M | 220 | PASS | 168 | 0.763636 | . ggplot(td.query(&#39;STATE==&quot;PASS&quot;&#39;))+geom_bar(aes(x=&#39;GEN&#39;,y=&#39;PROP&#39;,fill=&#39;GEN&#39;),stat=&#39;identity&#39;) . &lt;ggplot: (8726958443650)&gt; . - 남자의 합격률이 더 높다. $ to$ 성차별이 있어보인다(?) . &#49884;&#44033;&#54868;2: &#54617;&#44284;&#48324; &#54633;&#44201;&#47456; . - 학과별 합격률 . df . DEP STATE GEN COUNT . 0 A1 | PASS | M | 1 | . 1 A1 | FAIL | M | 9 | . 2 A2 | PASS | M | 2 | . 3 A2 | FAIL | M | 8 | . 4 B1 | PASS | M | 80 | . 5 B1 | FAIL | M | 20 | . 6 B2 | PASS | M | 85 | . 7 B2 | FAIL | M | 15 | . 8 A1 | PASS | F | 5 | . 9 A1 | FAIL | F | 5 | . 10 A2 | PASS | F | 5 | . 11 A2 | FAIL | F | 5 | . 12 B1 | PASS | F | 9 | . 13 B1 | FAIL | F | 1 | . 14 B2 | PASS | F | 9 | . 15 B2 | FAIL | F | 1 | . td=df.groupby([&#39;DEP&#39;,&#39;GEN&#39;]).agg({&#39;COUNT&#39;:sum}).reset_index() .rename(columns={&#39;COUNT&#39;:&#39;SUM&#39;}).merge(df) . td[&#39;PROP&#39;]=td.COUNT/td.SUM . td . DEP GEN SUM STATE COUNT PROP . 0 A1 | F | 10 | PASS | 5 | 0.50 | . 1 A1 | F | 10 | FAIL | 5 | 0.50 | . 2 A1 | M | 10 | PASS | 1 | 0.10 | . 3 A1 | M | 10 | FAIL | 9 | 0.90 | . 4 A2 | F | 10 | PASS | 5 | 0.50 | . 5 A2 | F | 10 | FAIL | 5 | 0.50 | . 6 A2 | M | 10 | PASS | 2 | 0.20 | . 7 A2 | M | 10 | FAIL | 8 | 0.80 | . 8 B1 | F | 10 | PASS | 9 | 0.90 | . 9 B1 | F | 10 | FAIL | 1 | 0.10 | . 10 B1 | M | 100 | PASS | 80 | 0.80 | . 11 B1 | M | 100 | FAIL | 20 | 0.20 | . 12 B2 | F | 10 | PASS | 9 | 0.90 | . 13 B2 | F | 10 | FAIL | 1 | 0.10 | . 14 B2 | M | 100 | PASS | 85 | 0.85 | . 15 B2 | M | 100 | FAIL | 15 | 0.15 | . td.query(&#39;STATE==&quot;PASS&quot;&#39;) . DEP GEN SUM STATE COUNT PROP . 0 A1 | F | 10 | PASS | 5 | 0.50 | . 2 A1 | M | 10 | PASS | 1 | 0.10 | . 4 A2 | F | 10 | PASS | 5 | 0.50 | . 6 A2 | M | 10 | PASS | 2 | 0.20 | . 8 B1 | F | 10 | PASS | 9 | 0.90 | . 10 B1 | M | 100 | PASS | 80 | 0.80 | . 12 B2 | F | 10 | PASS | 9 | 0.90 | . 14 B2 | M | 100 | PASS | 85 | 0.85 | . ggplot(td.query(&#39;STATE==&quot;PASS&quot;&#39;)) +geom_bar(aes(x=&#39;GEN&#39;,y=&#39;PROP&#39;,fill=&#39;GEN&#39;),stat=&#39;identity&#39;) +facet_wrap(&#39;DEP&#39;) . &lt;ggplot: (8726962449285)&gt; .",
            "url": "https://guebin.github.io/DV2022/2022/11/01/draft.html",
            "relUrl": "/2022/11/01/draft.html",
            "date": " • Nov 1, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "중간고사분포 -- 11월2일 삭제예정",
            "content": "import pandas as pd import numpy as np from plotnine import * . df = pd.DataFrame({&#39;Midterm&#39;:[28,40,15,25,10,15,25,15,70,50,20,50,35,60,30,25,30,70,25,30,8,35,60,50,35,45,35,54,25,70,14,35,45,35,45,30,25,34,24,30,30,50,45,25,35,20,55,30]}) df.Midterm.sort_values(ascending=False).reset_index(drop=True) . 0 70 1 70 2 70 3 60 4 60 5 55 6 54 7 50 8 50 9 50 10 50 11 45 12 45 13 45 14 45 15 40 16 35 17 35 18 35 19 35 20 35 21 35 22 35 23 34 24 30 25 30 26 30 27 30 28 30 29 30 30 30 31 28 32 25 33 25 34 25 35 25 36 25 37 25 38 25 39 24 40 20 41 20 42 15 43 15 44 15 45 14 46 10 47 8 Name: Midterm, dtype: int64 . df.describe() . Midterm . count 48.000000 | . mean 35.250000 | . std 15.641598 | . min 8.000000 | . 25% 25.000000 | . 50% 32.000000 | . 75% 45.000000 | . max 70.000000 | . df.Midterm.hist() . &lt;AxesSubplot:&gt; . ggplot(df.assign(Quantile=pd.cut(df.Midterm,[-np.inf,25,32,45,np.inf]))) +geom_point(aes(x=&#39;Quantile&#39;,y=&#39;Midterm&#39;,color=&#39;Quantile&#39;),position=&#39;jitter&#39;) +geom_boxplot(aes(x=&#39;Quantile&#39;,y=&#39;Midterm&#39;,color=&#39;Quantile&#39;),alpha=0.6) . &lt;ggplot: (8786339350361)&gt; .",
            "url": "https://guebin.github.io/DV2022/2022/11/01/Untitled.html",
            "relUrl": "/2022/11/01/Untitled.html",
            "date": " • Nov 1, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "데이터시각화2022 중간고사 -- 풀이포함",
            "content": "import numpy as np import matplotlib.pyplot as plt import pandas as pd import seaborn as sns from plotnine import * . 1. &#49884;&#44033;&#54868;&#51032; &#54644;&#49437; - &#45796;&#51020;&#51012; &#51096; &#51069;&#44256; &#47932;&#51020;&#50640; &#45813;&#54616;&#46972;. (20&#51216;) . (1) 아래의 그림을 보고 올바르게 해석한 것을 고르라. (모두 맞출경우만 정답으로 인정) . 소윤: (a)의 경우 $(x_i,y_i)$의 산점도가 직선형태이므로 표본상관계수의 값을 해석하는 것이 두 자료의 관계를 파악할때 도움을 준다. | 다호: (b)의 경우 $(x_i,y_i)$의 산점도가 이차곡선이므로 표본상관계수의 해석으로 두 자료의 관계를 모두 파악할 수 없다. | 하니: (c)의 경우 주황색으로 표시된 점을 제외한다면 표본상관계수로 자료를 해석하기에 바람직하다. | 도한: (d)도 (c)와 마찬가지로 주황색으로 표시된 점을 제외한다면 표본상관계수로 자료를 해석하기에 바람직하다. | . (풀이) . 정답: 소윤, 다호, 하니가 맞게 서술함. | 도한이 틀린이유: 주황색점을 제외할 경우 $x$의 변화량이 0이므로 분모가 0으로 수렴. 따라서 상관계수의 해석이 무의미하다. | . (2) 아래의 그림을 보고 올바르게 해석한 것을 모두 고르라. (모두 맞출경우만 정답으로 인정) . 그림에 대한 배경설명은 10월17일,19일의 &quot;아이스크림을 많이 먹으면 걸리는 병&quot;을 참고 | . /home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. . &lt;ggplot: (8776319243321)&gt; . 소윤: 아이스크림과 소아마비는 상관계수는 양수이다. | 다호: 상관계수가 양수라는 정보만으로는 소아마비와 아이스크림사이에 인과성이 있다고 주장하기 어렵다. | 하니: 소아마비와 아이스크림 사이에 존재하는 은닉변수 온도를 통제한다면 소아마비와 아이스크림 사이의 상관계수는 0에 가깝다. | 도한: 하니의 분석에 따르면 소아마비와 아이스크림 사이의 인과성은 없다고 보아야 한다. (단 소아마비와 아이스크림 사이의 은닉된 변수는 온도가 유일하다고 가정한다) | . (풀이) . 정답: 소윤, 다호, 하니, 도한 모두 맞게 서술함 | . 2. &#49884;&#44033;&#54868;&#44396;&#54788; I - &#45796;&#51020;&#51012; &#51096; &#51069;&#44256; &#47932;&#51020;&#50640; &#45813;&#54616;&#46972;. (10&#51216;) . (1)~(3) 주어진 자료에 대하여 다음을 시각화 하라. (maplotlib 이용) . x=[1,2,3,4] y=[1,2,3,2] . (1) 출제의도: 마커변경, 색깔변경 . plt.plot(x,y,&#39;x&#39;,color=&#39;C1&#39;); . 채점기준: 색깔이 정확하게 일치하지 않을 경우 0점으로 처리 | . (2) 출제의도: title설정 . plt.plot(x,y,) plt.title(&#39;TITLE&#39;,size=15); . (3) 출제의도: linetype 변경, dot connected-plot . plt.plot(x,y,&#39;or--&#39;); . . (4) ~ (5) 주어진 자료에 대하여 다음을 시각화 하라. . x=[1,2,3,4] y1=[1,2,4,3] y2=[1.1,1.9,3,5] . (4) 출제의도: legend . plt.plot(x,y1,&#39;o--&#39;,label=&#39;y1&#39;) plt.plot(x,y2,&#39;o--&#39;,label=&#39;y2&#39;) plt.legend(); . (5) 출제의도: linetype, linewidth 변경 . fig,ax = plt.subplots(1,2) ax[0].plot(x,y1,&#39;--&#39;,lw=2) ax[1].plot(x,y2,&#39;--&#39;,lw=4); . 채점기준: 선의두께가 예시와 조금 달라도 만점으로 인정 (두께의 변화만 있으면 정답으로 인정함) | . 3. &#49884;&#44033;&#54868;&#44396;&#54788; II -- &#45796;&#51020;&#51012; &#51096; &#51069;&#44256; &#47932;&#51020;&#50640; &#45813;&#54616;&#46972;. (10&#51216;) . 주어진 자료가 아래와 같다고 하자. . np.random.seed(43052) x1,y1 = np.random.multivariate_normal([-2,-2],[[1,-0.8],[-0.8,1]],size=500).T x2,y2 = np.random.multivariate_normal([2,2],[[1,-0.7],[-0.7,1]],size=500).T . (1) matplotlib와 seaborn을 이용하여 아래와 같이 시각화 하라. . alpha=0.1을 사용 | . fig,ax = plt.subplots(2,2) ax[0,0].plot(x1,y1,&#39;.&#39;) ax[0,0].plot(x2,y2,&#39;.&#39;,alpha=0.1) ax[0,0].set_title(&quot;(a) matplotlib - highlight (x1,y1)&quot;) sns.scatterplot(x=x1,y=y1,ax=ax[0,1]) sns.scatterplot(x=x2,y=y2,ax=ax[0,1],alpha=0.1) ax[0,1].set_title(&quot;(b) seaborn - highlight (x1,y1)&quot;) ax[1,0].plot(x1,y1,&#39;.&#39;,alpha=0.1) ax[1,0].plot(x2,y2,&#39;.&#39;) sns.scatterplot(x=x1,y=y1,ax=ax[1,1],alpha=0.1) ax[1,0].set_title(&quot;(c) matplotlib - highlight (x2,y2)&quot;) sns.scatterplot(x=x2,y=y2,ax=ax[1,1]) ax[1,1].set_title(&quot;(d) seaborn - highlight (x2,y2)&quot;) plt.tight_layout() . 채점기준: (b)와 (d)의 그림을 seaborn으로 생성하지 않을 경우 정답으로 인정안함 | . (2) plotnine을 이용하여 아래와 같이 시각화하라. . alpha=0.1을 사용 | . x=np.concatenate([x1,x2]) y=np.concatenate([y1,y2]) df = pd.DataFrame({&#39;x&#39;:x,&#39;y&#39;:y,&#39;cat&#39;:[&#39;A&#39;]*len(x1)+[&#39;B&#39;]*len(x2)}) ggplot(df)+geom_point(aes(x=&#39;x&#39;,y=&#39;y&#39;,color=&#39;cat&#39;),alpha=0.1) +geom_smooth(aes(x=&#39;x&#39;,y=&#39;y&#39;,color=&#39;cat&#39;)) +geom_smooth(aes(x=&#39;x&#39;,y=&#39;y&#39;)) . /home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. . &lt;ggplot: (8776325576381)&gt; . 채점기준: 산점도, 그룹별추세선, 전체추세선이 모두 있을 경우만 정답으로 인정 | . 4. &#51088;&#47308;&#48516;&#49437; &#48143; &#49884;&#44033;&#54868; I (40&#51216;) -- FIFA22&#51088;&#47308; . 아래의 코드를 활용하여 FIFA22의 자료를 불러온뒤 물음에 답하라. . df = pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/DV2021/master/_notebooks/2021-10-25-FIFA22_official_data.csv&#39;) df . ID Name Age Photo Nationality Flag Overall Potential Club Club Logo ... SlidingTackle GKDiving GKHandling GKKicking GKPositioning GKReflexes Best Position Best Overall Rating Release Clause DefensiveAwareness . 0 212198 | Bruno Fernandes | 26 | https://cdn.sofifa.com/players/212/198/22_60.png | Portugal | https://cdn.sofifa.com/flags/pt.png | 88 | 89 | Manchester United | https://cdn.sofifa.com/teams/11/30.png | ... | 65.0 | 12.0 | 14.0 | 15.0 | 8.0 | 14.0 | CAM | 88.0 | €206.9M | 72.0 | . 1 209658 | L. Goretzka | 26 | https://cdn.sofifa.com/players/209/658/22_60.png | Germany | https://cdn.sofifa.com/flags/de.png | 87 | 88 | FC Bayern München | https://cdn.sofifa.com/teams/21/30.png | ... | 77.0 | 13.0 | 8.0 | 15.0 | 11.0 | 9.0 | CM | 87.0 | €160.4M | 74.0 | . 2 176580 | L. Suárez | 34 | https://cdn.sofifa.com/players/176/580/22_60.png | Uruguay | https://cdn.sofifa.com/flags/uy.png | 88 | 88 | Atlético de Madrid | https://cdn.sofifa.com/teams/240/30.png | ... | 38.0 | 27.0 | 25.0 | 31.0 | 33.0 | 37.0 | ST | 88.0 | €91.2M | 42.0 | . 3 192985 | K. De Bruyne | 30 | https://cdn.sofifa.com/players/192/985/22_60.png | Belgium | https://cdn.sofifa.com/flags/be.png | 91 | 91 | Manchester City | https://cdn.sofifa.com/teams/10/30.png | ... | 53.0 | 15.0 | 13.0 | 5.0 | 10.0 | 13.0 | CM | 91.0 | €232.2M | 68.0 | . 4 224334 | M. Acuña | 29 | https://cdn.sofifa.com/players/224/334/22_60.png | Argentina | https://cdn.sofifa.com/flags/ar.png | 84 | 84 | Sevilla FC | https://cdn.sofifa.com/teams/481/30.png | ... | 82.0 | 8.0 | 14.0 | 13.0 | 13.0 | 14.0 | LB | 84.0 | €77.7M | 80.0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 16705 240558 | 18 L. Clayton | 17 | https://cdn.sofifa.com/players/240/558/18_60.png | England | https://cdn.sofifa.com/flags/gb-eng.png | 53 | 70 | Cheltenham Town | https://cdn.sofifa.com/teams/1936/30.png | ... | 12.0 | 55.0 | 54.0 | 52.0 | 50.0 | 59.0 | GK | 52.0 | €238K | NaN | . 16706 262846 | �. Dobre | 20 | https://cdn.sofifa.com/players/262/846/22_60.png | Romania | https://cdn.sofifa.com/flags/ro.png | 53 | 63 | FC Academica Clinceni | https://cdn.sofifa.com/teams/113391/30.png | ... | 12.0 | 57.0 | 52.0 | 53.0 | 48.0 | 58.0 | GK | 53.0 | €279K | 5.0 | . 16707 241317 | 21 Xue Qinghao | 19 | https://cdn.sofifa.com/players/241/317/21_60.png | China PR | https://cdn.sofifa.com/flags/cn.png | 47 | 60 | Shanghai Shenhua FC | https://cdn.sofifa.com/teams/110955/30.png | ... | 9.0 | 49.0 | 48.0 | 45.0 | 38.0 | 52.0 | GK | 47.0 | €223K | 21.0 | . 16708 259646 | A. Shaikh | 18 | https://cdn.sofifa.com/players/259/646/22_60.png | India | https://cdn.sofifa.com/flags/in.png | 47 | 67 | ATK Mohun Bagan FC | https://cdn.sofifa.com/teams/113146/30.png | ... | 13.0 | 49.0 | 41.0 | 39.0 | 45.0 | 49.0 | GK | 47.0 | €259K | 7.0 | . 16709 178453 | 07 A. Censori | 17 | https://cdn.sofifa.com/players/178/453/07_60.png | Italy | https://cdn.sofifa.com/flags/it.png | 28 | 38 | Arezzo | https://cdn.sofifa.com/teams/110907/30.png | ... | NaN | 7.0 | 1.0 | 36.0 | 6.0 | 9.0 | ST | 36.0 | NaN | NaN | . 16710 rows × 65 columns . (1) 연령별로 선수들의 잠재력을 시각화하고 싶다. 여기에서 잠재력은 아래의 수식의 Potential2를 의미한다. . Potential2 = Potential - Overall . 아래의 세부지침에 맞추어 연령별 Potential2의 산점도와 boxplot을 그려라. -- (10점) . (세부지침) . step1: 결측치가 가장 많은 2개의 컬럼을 찾고 이를 제거하라. . step2: dropna()를 이용하여 결측치를 제거하라. . step3: Potential2 = Potential - Overall 를 이용하여 Potential2를 구하라. . step4: 구간 [0,20,22,26,100]를 설정하고 이를 기준으로 Age를 그룹화하라. (총 4개의 그룹으로 나누어져야 한다) . step5: 그룹화된 Age를 x축으로, Potential2를 y축으로, 색깔을 그룹화된 Age로 설정한 뒤 산점도와 박스플랏을 겹쳐그려라. . 산점도의 파라메터: alpha=0.5,size=0.1,position=&#39;jitter&#39; | 박스플랏의 파라메터: alpha=0.8 | . (풀이) . df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 16710 entries, 0 to 16709 Data columns (total 65 columns): # Column Non-Null Count Dtype -- -- 0 ID 16710 non-null int64 1 Name 16710 non-null object 2 Age 16710 non-null int64 3 Photo 16710 non-null object 4 Nationality 16710 non-null object 5 Flag 16710 non-null object 6 Overall 16710 non-null int64 7 Potential 16710 non-null int64 8 Club 16446 non-null object 9 Club Logo 16710 non-null object 10 Value 16710 non-null object 11 Wage 16710 non-null object 12 Special 16710 non-null int64 13 Preferred Foot 16710 non-null object 14 International Reputation 16710 non-null float64 15 Weak Foot 16710 non-null float64 16 Skill Moves 16710 non-null float64 17 Work Rate 16710 non-null object 18 Body Type 16681 non-null object 19 Real Face 16681 non-null object 20 Position 16684 non-null object 21 Jersey Number 16684 non-null float64 22 Joined 15198 non-null object 23 Loaned From 1132 non-null object 24 Contract Valid Until 16359 non-null object 25 Height 16710 non-null object 26 Weight 16710 non-null object 27 Crossing 16710 non-null float64 28 Finishing 16710 non-null float64 29 HeadingAccuracy 16710 non-null float64 30 ShortPassing 16710 non-null float64 31 Volleys 16673 non-null float64 32 Dribbling 16710 non-null float64 33 Curve 16673 non-null float64 34 FKAccuracy 16710 non-null float64 35 LongPassing 16710 non-null float64 36 BallControl 16710 non-null float64 37 Acceleration 16710 non-null float64 38 SprintSpeed 16710 non-null float64 39 Agility 16673 non-null float64 40 Reactions 16710 non-null float64 41 Balance 16673 non-null float64 42 ShotPower 16710 non-null float64 43 Jumping 16673 non-null float64 44 Stamina 16710 non-null float64 45 Strength 16710 non-null float64 46 LongShots 16710 non-null float64 47 Aggression 16710 non-null float64 48 Interceptions 16702 non-null float64 49 Positioning 16702 non-null float64 50 Vision 16673 non-null float64 51 Penalties 16710 non-null float64 52 Composure 16459 non-null float64 53 Marking 892 non-null float64 54 StandingTackle 16710 non-null float64 55 SlidingTackle 16673 non-null float64 56 GKDiving 16710 non-null float64 57 GKHandling 16710 non-null float64 58 GKKicking 16710 non-null float64 59 GKPositioning 16710 non-null float64 60 GKReflexes 16710 non-null float64 61 Best Position 16710 non-null object 62 Best Overall Rating 16710 non-null float64 63 Release Clause 14961 non-null object 64 DefensiveAwareness 15818 non-null float64 dtypes: float64(40), int64(5), object(20) memory usage: 8.3+ MB . &#39;Loaned From&#39;와 &#39;Marking&#39;이 가장 결측치가 많이 포함되어있음 | . data1= df.drop(columns=[&#39;Loaned From&#39;, &#39;Marking&#39;]).dropna() .eval(&#39;Potential2 = Potential- Overall&#39;) .assign(Age = lambda df: pd.cut(df[&#39;Age&#39;],[0,20,22,26,100])) data1 . ID Name Age Photo Nationality Flag Overall Potential Club Club Logo ... GKDiving GKHandling GKKicking GKPositioning GKReflexes Best Position Best Overall Rating Release Clause DefensiveAwareness Potential2 . 0 212198 | Bruno Fernandes | (22, 26] | https://cdn.sofifa.com/players/212/198/22_60.png | Portugal | https://cdn.sofifa.com/flags/pt.png | 88 | 89 | Manchester United | https://cdn.sofifa.com/teams/11/30.png | ... | 12.0 | 14.0 | 15.0 | 8.0 | 14.0 | CAM | 88.0 | €206.9M | 72.0 | 1 | . 1 209658 | L. Goretzka | (22, 26] | https://cdn.sofifa.com/players/209/658/22_60.png | Germany | https://cdn.sofifa.com/flags/de.png | 87 | 88 | FC Bayern München | https://cdn.sofifa.com/teams/21/30.png | ... | 13.0 | 8.0 | 15.0 | 11.0 | 9.0 | CM | 87.0 | €160.4M | 74.0 | 1 | . 2 176580 | L. Suárez | (26, 100] | https://cdn.sofifa.com/players/176/580/22_60.png | Uruguay | https://cdn.sofifa.com/flags/uy.png | 88 | 88 | Atlético de Madrid | https://cdn.sofifa.com/teams/240/30.png | ... | 27.0 | 25.0 | 31.0 | 33.0 | 37.0 | ST | 88.0 | €91.2M | 42.0 | 0 | . 3 192985 | K. De Bruyne | (26, 100] | https://cdn.sofifa.com/players/192/985/22_60.png | Belgium | https://cdn.sofifa.com/flags/be.png | 91 | 91 | Manchester City | https://cdn.sofifa.com/teams/10/30.png | ... | 15.0 | 13.0 | 5.0 | 10.0 | 13.0 | CM | 91.0 | €232.2M | 68.0 | 0 | . 4 224334 | M. Acuña | (26, 100] | https://cdn.sofifa.com/players/224/334/22_60.png | Argentina | https://cdn.sofifa.com/flags/ar.png | 84 | 84 | Sevilla FC | https://cdn.sofifa.com/teams/481/30.png | ... | 8.0 | 14.0 | 13.0 | 13.0 | 14.0 | LB | 84.0 | €77.7M | 80.0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 16703 259718 | F. Gebhardt | (0, 20] | https://cdn.sofifa.com/players/259/718/22_60.png | Germany | https://cdn.sofifa.com/flags/de.png | 52 | 66 | FC Basel 1893 | https://cdn.sofifa.com/teams/896/30.png | ... | 53.0 | 45.0 | 47.0 | 52.0 | 57.0 | GK | 52.0 | €361K | 6.0 | 14 | . 16704 251433 | B. Voll | (0, 20] | https://cdn.sofifa.com/players/251/433/22_60.png | Germany | https://cdn.sofifa.com/flags/de.png | 58 | 69 | F.C. Hansa Rostock | https://cdn.sofifa.com/teams/27/30.png | ... | 59.0 | 60.0 | 56.0 | 55.0 | 61.0 | GK | 58.0 | €656K | 5.0 | 11 | . 16706 262846 | �. Dobre | (0, 20] | https://cdn.sofifa.com/players/262/846/22_60.png | Romania | https://cdn.sofifa.com/flags/ro.png | 53 | 63 | FC Academica Clinceni | https://cdn.sofifa.com/teams/113391/30.png | ... | 57.0 | 52.0 | 53.0 | 48.0 | 58.0 | GK | 53.0 | €279K | 5.0 | 10 | . 16707 241317 | 21 Xue Qinghao | (0, 20] | https://cdn.sofifa.com/players/241/317/21_60.png | China PR | https://cdn.sofifa.com/flags/cn.png | 47 | 60 | Shanghai Shenhua FC | https://cdn.sofifa.com/teams/110955/30.png | ... | 49.0 | 48.0 | 45.0 | 38.0 | 52.0 | GK | 47.0 | €223K | 21.0 | 13 | . 16708 259646 | A. Shaikh | (0, 20] | https://cdn.sofifa.com/players/259/646/22_60.png | India | https://cdn.sofifa.com/flags/in.png | 47 | 67 | ATK Mohun Bagan FC | https://cdn.sofifa.com/teams/113146/30.png | ... | 49.0 | 41.0 | 39.0 | 45.0 | 49.0 | GK | 47.0 | €259K | 7.0 | 20 | . 14398 rows × 64 columns . fig = ggplot(data=data1) scatter = geom_point(aes(x=&#39;Age&#39;,y=&#39;Potential2&#39;,colour=&#39;Age&#39;),alpha=0.5,size=0.1,position=&#39;jitter&#39;) boxplot = geom_boxplot(aes(x=&#39;Age&#39;,y=&#39;Potential2&#39;,colour=&#39;Age&#39;),alpha=0.8) fig+scatter+boxplot . &lt;ggplot: (8776319269061)&gt; . 채점기준: Age의 Label을 사용하지 않아도 만점으로 인정함. | . (2) 포지션별로 선수들의 능력치와 Wage를 시각화하고 싶다. 아래의 dictionary를 이용하여 Position을 재정의하라. . position_dict = { &#39;GOALKEEPER&#39;:{&#39;GK&#39;}, &#39;DEFENDER&#39;:{&#39;CB&#39;,&#39;RCB&#39;,&#39;LCB&#39;,&#39;RB&#39;,&#39;LB&#39;,&#39;RWB&#39;,&#39;LWB&#39;}, &#39;MIDFIELDER&#39;:{&#39;CM&#39;,&#39;RCM&#39;,&#39;LCM&#39;,&#39;CDM&#39;,&#39;RDM&#39;,&#39;LDM&#39;,&#39;CAM&#39;,&#39;RAM&#39;,&#39;LAM&#39;,&#39;RM&#39;,&#39;LM&#39;}, &#39;FORWARD&#39;:{&#39;ST&#39;,&#39;CF&#39;,&#39;RF&#39;,&#39;LF&#39;,&#39;RW&#39;,&#39;LW&#39;,&#39;RS&#39;,&#39;LS&#39;}, &#39;SUB&#39;:{&#39;SUB&#39;}, &#39;RES&#39;:{&#39;RES&#39;} } position_dict . {&#39;GOALKEEPER&#39;: {&#39;GK&#39;}, &#39;DEFENDER&#39;: {&#39;CB&#39;, &#39;LB&#39;, &#39;LCB&#39;, &#39;LWB&#39;, &#39;RB&#39;, &#39;RCB&#39;, &#39;RWB&#39;}, &#39;MIDFIELDER&#39;: {&#39;CAM&#39;, &#39;CDM&#39;, &#39;CM&#39;, &#39;LAM&#39;, &#39;LCM&#39;, &#39;LDM&#39;, &#39;LM&#39;, &#39;RAM&#39;, &#39;RCM&#39;, &#39;RDM&#39;, &#39;RM&#39;}, &#39;FORWARD&#39;: {&#39;CF&#39;, &#39;LF&#39;, &#39;LS&#39;, &#39;LW&#39;, &#39;RF&#39;, &#39;RS&#39;, &#39;RW&#39;, &#39;ST&#39;}, &#39;SUB&#39;: {&#39;SUB&#39;}, &#39;RES&#39;: {&#39;RES&#39;}} . 아래의 세부지침에 맞추어 포지션별 ShotPower와 SlidingTackle의 산점도를 그려라. -- (30점) . 세부지침 . step1: 결측치가 가장 많은 2개의 컬럼을 찾고 이를 제거하라. . step2: dropna()를 이용하여 결측치를 제거하라. . step3: hint1과 position_dict을 참고하여 Position을 적절하게 변환하라. (변환된 값을 Position으로 저장할 것) . step4: hint2를 참고하여 Wage를 적절하게 변환하라. (변환된 값을 Wage에 저장할 것) . step5: Position==&quot;DEFENDER&quot; or Position==&quot;FORWARD&quot;에 해당하는 관측치를 고른 뒤 x축에 ShotPower, y축에 SlidingTackle 을 시각화하라. Position은 color로 구분하고 Wage는 size와 alpha로 구분하라. . hint1: Position column의 변환을 위한 코드 . &#39;&lt;span class=&quot;pos pos18&quot;&gt;CAM&#39;.split(&#39;&gt;&#39;) . [&#39;&lt;span class=&#34;pos pos18&#34;&#39;, &#39;CAM&#39;] . hint2: Wage column의 변환을 위한 함수 . def f(x): if x[-1] == &#39;K&#39; : y= float(x[1:-1])*1000 elif x[-1] == &#39;M&#39; : y= float(x[1:-1])*1000000 else: y= 0 return y . (풀이) . data2=df.drop(columns=[&#39;Loaned From&#39;, &#39;Marking&#39;]).dropna() .assign(Wage = lambda df: list(map(f,df[&#39;Wage&#39;]))) .assign(Position = lambda df: list(map(lambda x: x.split(&#39;&gt;&#39;)[-1], df.Position))) .assign(Position = lambda df: [key for x in df.Position for key in position_dict if x in position_dict[key]] ) data2 . ID Name Age Photo Nationality Flag Overall Potential Club Club Logo ... SlidingTackle GKDiving GKHandling GKKicking GKPositioning GKReflexes Best Position Best Overall Rating Release Clause DefensiveAwareness . 0 212198 | Bruno Fernandes | 26 | https://cdn.sofifa.com/players/212/198/22_60.png | Portugal | https://cdn.sofifa.com/flags/pt.png | 88 | 89 | Manchester United | https://cdn.sofifa.com/teams/11/30.png | ... | 65.0 | 12.0 | 14.0 | 15.0 | 8.0 | 14.0 | CAM | 88.0 | €206.9M | 72.0 | . 1 209658 | L. Goretzka | 26 | https://cdn.sofifa.com/players/209/658/22_60.png | Germany | https://cdn.sofifa.com/flags/de.png | 87 | 88 | FC Bayern München | https://cdn.sofifa.com/teams/21/30.png | ... | 77.0 | 13.0 | 8.0 | 15.0 | 11.0 | 9.0 | CM | 87.0 | €160.4M | 74.0 | . 2 176580 | L. Suárez | 34 | https://cdn.sofifa.com/players/176/580/22_60.png | Uruguay | https://cdn.sofifa.com/flags/uy.png | 88 | 88 | Atlético de Madrid | https://cdn.sofifa.com/teams/240/30.png | ... | 38.0 | 27.0 | 25.0 | 31.0 | 33.0 | 37.0 | ST | 88.0 | €91.2M | 42.0 | . 3 192985 | K. De Bruyne | 30 | https://cdn.sofifa.com/players/192/985/22_60.png | Belgium | https://cdn.sofifa.com/flags/be.png | 91 | 91 | Manchester City | https://cdn.sofifa.com/teams/10/30.png | ... | 53.0 | 15.0 | 13.0 | 5.0 | 10.0 | 13.0 | CM | 91.0 | €232.2M | 68.0 | . 4 224334 | M. Acuña | 29 | https://cdn.sofifa.com/players/224/334/22_60.png | Argentina | https://cdn.sofifa.com/flags/ar.png | 84 | 84 | Sevilla FC | https://cdn.sofifa.com/teams/481/30.png | ... | 82.0 | 8.0 | 14.0 | 13.0 | 13.0 | 14.0 | LB | 84.0 | €77.7M | 80.0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 16703 259718 | F. Gebhardt | 19 | https://cdn.sofifa.com/players/259/718/22_60.png | Germany | https://cdn.sofifa.com/flags/de.png | 52 | 66 | FC Basel 1893 | https://cdn.sofifa.com/teams/896/30.png | ... | 10.0 | 53.0 | 45.0 | 47.0 | 52.0 | 57.0 | GK | 52.0 | €361K | 6.0 | . 16704 251433 | B. Voll | 20 | https://cdn.sofifa.com/players/251/433/22_60.png | Germany | https://cdn.sofifa.com/flags/de.png | 58 | 69 | F.C. Hansa Rostock | https://cdn.sofifa.com/teams/27/30.png | ... | 10.0 | 59.0 | 60.0 | 56.0 | 55.0 | 61.0 | GK | 58.0 | €656K | 5.0 | . 16706 262846 | �. Dobre | 20 | https://cdn.sofifa.com/players/262/846/22_60.png | Romania | https://cdn.sofifa.com/flags/ro.png | 53 | 63 | FC Academica Clinceni | https://cdn.sofifa.com/teams/113391/30.png | ... | 12.0 | 57.0 | 52.0 | 53.0 | 48.0 | 58.0 | GK | 53.0 | €279K | 5.0 | . 16707 241317 | 21 Xue Qinghao | 19 | https://cdn.sofifa.com/players/241/317/21_60.png | China PR | https://cdn.sofifa.com/flags/cn.png | 47 | 60 | Shanghai Shenhua FC | https://cdn.sofifa.com/teams/110955/30.png | ... | 9.0 | 49.0 | 48.0 | 45.0 | 38.0 | 52.0 | GK | 47.0 | €223K | 21.0 | . 16708 259646 | A. Shaikh | 18 | https://cdn.sofifa.com/players/259/646/22_60.png | India | https://cdn.sofifa.com/flags/in.png | 47 | 67 | ATK Mohun Bagan FC | https://cdn.sofifa.com/teams/113146/30.png | ... | 13.0 | 49.0 | 41.0 | 39.0 | 45.0 | 49.0 | GK | 47.0 | €259K | 7.0 | . 14398 rows × 63 columns . fig = ggplot(data=data2.query(&#39;Position==&quot;DEFENDER&quot; or Position==&quot;FORWARD&quot;&#39;)) scatter = geom_point(aes(x=&#39;ShotPower&#39;,y=&#39;SlidingTackle&#39;,color=&#39;Position&#39;,size=&#39;Wage&#39;,alpha=&#39;Wage&#39;)) fig+scatter . &lt;ggplot: (8776325574701)&gt; . 채점기준: df[&#39;Position&#39;]이 아니라 df[&#39;Best Position&#39;]을 이용하여 자료를 변형하고 시각화 하는 경우 부분점수 없이 0점임 | . 5. &#51088;&#47308;&#48516;&#49437; &#48143; &#49884;&#44033;&#54868; II (20&#51216;) -- HRDataset_v14 . 아래의 코드를 활용하여 Kaggle의 HRdataset을 불러오고 물음에 답하라. . df = pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/DV2022/master/_notebooks/HRDataset_v14.csv&#39;) df . Employee_Name EmpID MarriedID MaritalStatusID GenderID EmpStatusID DeptID PerfScoreID FromDiversityJobFairID Salary ... ManagerName ManagerID RecruitmentSource PerformanceScore EngagementSurvey EmpSatisfaction SpecialProjectsCount LastPerformanceReview_Date DaysLateLast30 Absences . 0 Adinolfi, Wilson K | 10026 | 0 | 0 | 1 | 1 | 5 | 4 | 0 | 62506 | ... | Michael Albert | 22.0 | LinkedIn | Exceeds | 4.60 | 5 | 0 | 1/17/2019 | 0 | 1 | . 1 Ait Sidi, Karthikeyan | 10084 | 1 | 1 | 1 | 5 | 3 | 3 | 0 | 104437 | ... | Simon Roup | 4.0 | Indeed | Fully Meets | 4.96 | 3 | 6 | 2/24/2016 | 0 | 17 | . 2 Akinkuolie, Sarah | 10196 | 1 | 1 | 0 | 5 | 5 | 3 | 0 | 64955 | ... | Kissy Sullivan | 20.0 | LinkedIn | Fully Meets | 3.02 | 3 | 0 | 5/15/2012 | 0 | 3 | . 3 Alagbe,Trina | 10088 | 1 | 1 | 0 | 1 | 5 | 3 | 0 | 64991 | ... | Elijiah Gray | 16.0 | Indeed | Fully Meets | 4.84 | 5 | 0 | 1/3/2019 | 0 | 15 | . 4 Anderson, Carol | 10069 | 0 | 2 | 0 | 5 | 5 | 3 | 0 | 50825 | ... | Webster Butler | 39.0 | Google Search | Fully Meets | 5.00 | 4 | 0 | 2/1/2016 | 0 | 2 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 306 Woodson, Jason | 10135 | 0 | 0 | 1 | 1 | 5 | 3 | 0 | 65893 | ... | Kissy Sullivan | 20.0 | LinkedIn | Fully Meets | 4.07 | 4 | 0 | 2/28/2019 | 0 | 13 | . 307 Ybarra, Catherine | 10301 | 0 | 0 | 0 | 5 | 5 | 1 | 0 | 48513 | ... | Brannon Miller | 12.0 | Google Search | PIP | 3.20 | 2 | 0 | 9/2/2015 | 5 | 4 | . 308 Zamora, Jennifer | 10010 | 0 | 0 | 0 | 1 | 3 | 4 | 0 | 220450 | ... | Janet King | 2.0 | Employee Referral | Exceeds | 4.60 | 5 | 6 | 2/21/2019 | 0 | 16 | . 309 Zhou, Julia | 10043 | 0 | 0 | 0 | 1 | 3 | 3 | 0 | 89292 | ... | Simon Roup | 4.0 | Employee Referral | Fully Meets | 5.00 | 3 | 5 | 2/1/2019 | 0 | 11 | . 310 Zima, Colleen | 10271 | 0 | 4 | 0 | 1 | 5 | 3 | 0 | 45046 | ... | David Stanley | 14.0 | LinkedIn | Fully Meets | 4.50 | 5 | 0 | 1/30/2019 | 0 | 2 | . 311 rows × 36 columns . (1) 데이터를 조사하고 올바르게 분석한 사람을 모두 고르라. (모두 맞칠경우만 정답으로 인정) . 소윤: 근무인원수가 가장 많은 인종(RaceDesc)은 &#39;White&#39;이며 이는 &#39;Asian&#39;인종과 &#39;Black or African American&#39;의 합보다 많다. | 다호: &#39;RaceDesc==White&#39;의 성별(Sex)임금차이는 2000이상이다. | 하니: 퇴직한사람(Termd==1)은 모두 104명이며 백인여성의 퇴직자수가 가장 많다. | 도한: 퇴직한사람중 아시아인의 비율은 10%가 넘지 않는다. | . (풀이) . 데이터조사 . df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 311 entries, 0 to 310 Data columns (total 36 columns): # Column Non-Null Count Dtype -- -- 0 Employee_Name 311 non-null object 1 EmpID 311 non-null int64 2 MarriedID 311 non-null int64 3 MaritalStatusID 311 non-null int64 4 GenderID 311 non-null int64 5 EmpStatusID 311 non-null int64 6 DeptID 311 non-null int64 7 PerfScoreID 311 non-null int64 8 FromDiversityJobFairID 311 non-null int64 9 Salary 311 non-null int64 10 Termd 311 non-null int64 11 PositionID 311 non-null int64 12 Position 311 non-null object 13 State 311 non-null object 14 Zip 311 non-null int64 15 DOB 311 non-null object 16 Sex 311 non-null object 17 MaritalDesc 311 non-null object 18 CitizenDesc 311 non-null object 19 HispanicLatino 311 non-null object 20 RaceDesc 311 non-null object 21 DateofHire 311 non-null object 22 DateofTermination 104 non-null object 23 TermReason 311 non-null object 24 EmploymentStatus 311 non-null object 25 Department 311 non-null object 26 ManagerName 311 non-null object 27 ManagerID 303 non-null float64 28 RecruitmentSource 311 non-null object 29 PerformanceScore 311 non-null object 30 EngagementSurvey 311 non-null float64 31 EmpSatisfaction 311 non-null int64 32 SpecialProjectsCount 311 non-null int64 33 LastPerformanceReview_Date 311 non-null object 34 DaysLateLast30 311 non-null int64 35 Absences 311 non-null int64 dtypes: float64(2), int64(16), object(18) memory usage: 87.6+ KB . EmpID가 missing이 없는 열임 | . 소윤: 근무인원수가 가장 많은 인종(RaceDesc)은 &#39;White&#39;이며 이는 &#39;Asian&#39;인종과 &#39;Black or African American&#39;의 합보다 많다. . 참 | . df.groupby(by=&#39;RaceDesc&#39;).agg({&#39;EmpID&#39;:len}) . EmpID . RaceDesc . American Indian or Alaska Native 3 | . Asian 29 | . Black or African American 80 | . Hispanic 1 | . Two or more races 11 | . White 187 | . 29+80 . 109 . 다호: &#39;RaceDesc==White&#39;의 성별(Sex)임금차이는 2000이상이다. . 참 | . df.groupby(by=[&#39;RaceDesc&#39;,&#39;Sex&#39;]).agg({&#39;Salary&#39;:np.mean}) . Salary . RaceDesc Sex . American Indian or Alaska Native F 63436.500000 | . M 70545.000000 | . Asian F 67520.117647 | . M 69939.416667 | . Black or African American F 66963.829787 | . M 85066.121212 | . Hispanic M 83667.000000 | . Two or more races F 58068.500000 | . M 62313.800000 | . White F 68846.519231 | . M 65334.132530 | . 68846.519231 - 65334.132530 . 3512.386700999996 . 하니: 퇴직한사람(Termd==1)은 모두 104명이며 백인여성의 퇴직자수가 가장 많다. . 참 | . (df.Termd==1).sum() . 104 . df.groupby(by=[&#39;RaceDesc&#39;,&#39;Sex&#39;]).agg({&#39;Termd&#39;:np.sum}) . Termd . RaceDesc Sex . American Indian or Alaska Native F 0 | . M 0 | . Asian F 6 | . M 3 | . Black or African American F 15 | . M 14 | . Hispanic M 0 | . Two or more races F 2 | . M 1 | . White F 37 | . M 26 | . 도한: 퇴직한사람중 아시아인의 비율은 10%가 넘지 않는다. . 참 | . (df.Termd==1).sum() . 104 . df.groupby(by=[&#39;RaceDesc&#39;]).agg({&#39;Termd&#39;:np.sum}) . Termd . RaceDesc . American Indian or Alaska Native 0 | . Asian 9 | . Black or African American 29 | . Hispanic 0 | . Two or more races 3 | . White 63 | . 9/104 . 0.08653846153846154 . (2) White, Black or African American, Asian 인종(RaceDesc)에 대하여 남여급여차이를 조사하고자 한다. 아래와 같은 Boxplot을 생성하라. . (풀이) . ggplot(data=df.query(&#39;RaceDesc == &quot;White&quot; or RaceDesc == &quot;Black or African American&quot; or RaceDesc == &quot;Asian&quot;&#39;)) +geom_boxplot(aes(x=&#39;RaceDesc&#39;,y=&#39;Salary&#39;,color=&#39;Sex&#39;)) . &lt;ggplot: (8776333683953)&gt; .",
            "url": "https://guebin.github.io/DV2022/2022/10/30/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%942022-%EC%A4%91%EA%B0%84%EA%B3%A0%EC%82%AC.html",
            "relUrl": "/2022/10/30/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%942022-%EC%A4%91%EA%B0%84%EA%B3%A0%EC%82%AC.html",
            "date": " • Oct 30, 2022"
        }
        
    
  
    
        ,"post4": {
            "title": "(8주차) 10월24일, 10월26일",
            "content": "&#44053;&#51032;&#50689;&#49345; . . imports . # !pip install pandas_profiling . import pandas as pd import numpy as np import pandas_profiling from plotnine import * . df: &#49352;&#47196;&#50868; &#50676;&#51032; &#54624;&#45817; 2&#45800;&#44228; (&#50672;&#49604;&#54624;&#45817;) . &#47784;&#54000;&#48652; . - 원본데이터를 가급적 손상시키지 않으면서 데이터를 변형하고 싶음. . df = pd.DataFrame({&#39;A&#39;:range(0,5),&#39;B&#39;:range(1,6)}) df . A B . 0 0 | 1 | . 1 1 | 2 | . 2 2 | 3 | . 3 3 | 4 | . 4 4 | 5 | . 복사본 생성 . df2 = df df2 . A B . 0 0 | 1 | . 1 1 | 2 | . 2 2 | 3 | . 3 3 | 4 | . 4 4 | 5 | . df2[&#39;C&#39;] = (df2.A+ df2.B)/2 df2 . A B C . 0 0 | 1 | 0.5 | . 1 1 | 2 | 1.5 | . 2 2 | 3 | 2.5 | . 3 3 | 4 | 3.5 | . 4 4 | 5 | 4.5 | . df2[&#39;D&#39;]= (df2.C - np.mean(df2.C))/np.std(df2.C) df2 . A B C D . 0 0 | 1 | 0.5 | -1.414214 | . 1 1 | 2 | 1.5 | -0.707107 | . 2 2 | 3 | 2.5 | 0.000000 | . 3 3 | 4 | 3.5 | 0.707107 | . 4 4 | 5 | 4.5 | 1.414214 | . df # 니가 왜 거기서 나와?? . A B C D . 0 0 | 1 | 0.5 | -1.414214 | . 1 1 | 2 | 1.5 | -0.707107 | . 2 2 | 3 | 2.5 | 0.000000 | . 3 3 | 4 | 3.5 | 0.707107 | . 4 4 | 5 | 4.5 | 1.414214 | . &#54644;&#44208;&#52293;1: df.copy()&#51060;&#50857;, .eval()&#51060;&#50857; . - 올바른코드1 . df = pd.DataFrame({&#39;A&#39;:range(0,5),&#39;B&#39;:range(1,6)}) df2 = df.copy() df2[&#39;C&#39;] = (df2.A+ df2.B)/2 df2[&#39;D&#39;]= (df2.C - np.mean(df2.C))/np.std(df2.C) . df2 . A B C D . 0 0 | 1 | 0.5 | -1.414214 | . 1 1 | 2 | 1.5 | -0.707107 | . 2 2 | 3 | 2.5 | 0.000000 | . 3 3 | 4 | 3.5 | 0.707107 | . 4 4 | 5 | 4.5 | 1.414214 | . df . A B . 0 0 | 1 | . 1 1 | 2 | . 2 2 | 3 | . 3 3 | 4 | . 4 4 | 5 | . - 올바른코드2 . df = pd.DataFrame({&#39;A&#39;:range(0,5),&#39;B&#39;:range(1,6)}) mean = np.mean std = np.std df.eval(&#39;C=(A+B)/2&#39;).eval(&#39;D=(C-@mean(C))/@std(C)&#39;) . A B C D . 0 0 | 1 | 0.5 | -1.414214 | . 1 1 | 2 | 1.5 | -0.707107 | . 2 2 | 3 | 2.5 | 0.000000 | . 3 3 | 4 | 3.5 | 0.707107 | . 4 4 | 5 | 4.5 | 1.414214 | . 어디까지 eval expression 안에서 지원되는지 명확하지 않고 | 외부에 함수를 선언하고 eval expression 안에 @를 붙이는게 좀 귀찮음 | . - 올바른코드3 (assign) --&gt; 실패 . df = pd.DataFrame({&#39;A&#39;:range(0,5),&#39;B&#39;:range(1,6)}) df.assign(C= (df.A+df.B)/2) . A B C . 0 0 | 1 | 0.5 | . 1 1 | 2 | 1.5 | . 2 2 | 3 | 2.5 | . 3 3 | 4 | 3.5 | . 4 4 | 5 | 4.5 | . df.assign(C= (df.A+df.B)/2).assign(D= (df.C- np.mean(df.C))/np.std(df.C)) . AttributeError Traceback (most recent call last) /tmp/ipykernel_1924156/1318175824.py in &lt;module&gt; -&gt; 1 df.assign(C= (df.A+df.B)/2).assign(D= (df.C- np.mean(df.C))/np.std(df.C)) ~/anaconda3/envs/py37/lib/python3.7/site-packages/pandas/core/generic.py in __getattr__(self, name) 5485 ): 5486 return self[name] -&gt; 5487 return object.__getattribute__(self, name) 5488 5489 def __setattr__(self, name: str, value) -&gt; None: AttributeError: &#39;DataFrame&#39; object has no attribute &#39;C&#39; . 아래와 같이 고쳐야함 . _df = df.assign(C= (df.A+df.B)/2) _df.assign(D= (_df.C- np.mean(_df.C))/np.std(_df.C)) . A B C D . 0 0 | 1 | 0.5 | -1.414214 | . 1 1 | 2 | 1.5 | -0.707107 | . 2 2 | 3 | 2.5 | 0.000000 | . 3 3 | 4 | 3.5 | 0.707107 | . 4 4 | 5 | 4.5 | 1.414214 | . 이건 우리의 철학이랑 안맞음.. | . &#54644;&#44208;&#52293;2: assign&#51012; &#51060;&#50857;&#54620; &#50672;&#49604;&#54624;&#45817; . 실패한코드는 아래와 같다. . df.assign(C= (df.A+df.B)/2).assign(D= (df.C- np.mean(df.C))/np.std(df.C)) . AttributeError Traceback (most recent call last) /tmp/ipykernel_1924156/1318175824.py in &lt;module&gt; -&gt; 1 df.assign(C= (df.A+df.B)/2).assign(D= (df.C- np.mean(df.C))/np.std(df.C)) ~/anaconda3/envs/py37/lib/python3.7/site-packages/pandas/core/generic.py in __getattr__(self, name) 5485 ): 5486 return self[name] -&gt; 5487 return object.__getattribute__(self, name) 5488 5489 def __setattr__(self, name: str, value) -&gt; None: AttributeError: &#39;DataFrame&#39; object has no attribute &#39;C&#39; . 두번째 assign에서 표현된 df.C 에서, df가 current df (= df.assign(C= (df.A+df.B)/2) 까지 연산된 상태) 를 의미하도록 만들고 싶다. $ to$ 아래와 같이 lambda df: 를 추가하면 된다. . df.assign(C= (df.A+df.B)/2).assign(D= lambda df: (df.C- np.mean(df.C))/np.std(df.C)) . A B C D . 0 0 | 1 | 0.5 | -1.414214 | . 1 1 | 2 | 1.5 | -0.707107 | . 2 2 | 3 | 2.5 | 0.000000 | . 3 3 | 4 | 3.5 | 0.707107 | . 4 4 | 5 | 4.5 | 1.414214 | . - 연쇄할당 . df.assign(C = (df.A+df.B)/2).assign(D = lambda df: df.C +2).assign(E = lambda df: df.D - 2) . A B C D E . 0 0 | 1 | 0.5 | 2.5 | 0.5 | . 1 1 | 2 | 1.5 | 3.5 | 1.5 | . 2 2 | 3 | 2.5 | 4.5 | 2.5 | . 3 3 | 4 | 3.5 | 5.5 | 3.5 | . 4 4 | 5 | 4.5 | 6.5 | 4.5 | . FIFA23 &#45936;&#51060;&#53552;&#48516;&#49437; . FIFA23 data . - FIFA23라는 축구게임이 있음 . - 게임에 실제 선수들이 나오면서 선수들의 능력치가 세밀하게 구현되어 있음 . - 선수들 능력치에 대한 데이터셋은 캐글에 공개되어 있음 . https://www.kaggle.com/datasets/bryanb/fifa-player-stats-database?select=FIFA23_official_data.csv | . &#45936;&#51060;&#53552;&#49332;&#54196;&#48372;&#44592; . - 일단 살펴보기 . df=pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/DV2022/master/_notebooks/FIFA23_official_data.csv&#39;) df.head() . ID Name Age Photo Nationality Flag Overall Potential Club Club Logo ... Real Face Position Joined Loaned From Contract Valid Until Height Weight Release Clause Kit Number Best Overall Rating . 0 209658 | L. Goretzka | 27 | https://cdn.sofifa.net/players/209/658/23_60.png | Germany | https://cdn.sofifa.net/flags/de.png | 87 | 88 | FC Bayern München | https://cdn.sofifa.net/teams/21/30.png | ... | Yes | &lt;span class=&quot;pos pos28&quot;&gt;SUB | Jul 1, 2018 | NaN | 2026 | 189cm | 82kg | €157M | 8.0 | NaN | . 1 212198 | Bruno Fernandes | 27 | https://cdn.sofifa.net/players/212/198/23_60.png | Portugal | https://cdn.sofifa.net/flags/pt.png | 86 | 87 | Manchester United | https://cdn.sofifa.net/teams/11/30.png | ... | Yes | &lt;span class=&quot;pos pos15&quot;&gt;LCM | Jan 30, 2020 | NaN | 2026 | 179cm | 69kg | €155M | 8.0 | NaN | . 2 224334 | M. Acuña | 30 | https://cdn.sofifa.net/players/224/334/23_60.png | Argentina | https://cdn.sofifa.net/flags/ar.png | 85 | 85 | Sevilla FC | https://cdn.sofifa.net/teams/481/30.png | ... | No | &lt;span class=&quot;pos pos7&quot;&gt;LB | Sep 14, 2020 | NaN | 2024 | 172cm | 69kg | €97.7M | 19.0 | NaN | . 3 192985 | K. De Bruyne | 31 | https://cdn.sofifa.net/players/192/985/23_60.png | Belgium | https://cdn.sofifa.net/flags/be.png | 91 | 91 | Manchester City | https://cdn.sofifa.net/teams/10/30.png | ... | Yes | &lt;span class=&quot;pos pos13&quot;&gt;RCM | Aug 30, 2015 | NaN | 2025 | 181cm | 70kg | €198.9M | 17.0 | NaN | . 4 224232 | N. Barella | 25 | https://cdn.sofifa.net/players/224/232/23_60.png | Italy | https://cdn.sofifa.net/flags/it.png | 86 | 89 | Inter | https://cdn.sofifa.net/teams/44/30.png | ... | Yes | &lt;span class=&quot;pos pos13&quot;&gt;RCM | Sep 1, 2020 | NaN | 2026 | 172cm | 68kg | €154.4M | 23.0 | NaN | . 5 rows × 29 columns . 트랜스포즈하여 보는 것이 편할때도 있음 . df.T . 0 1 2 3 4 5 6 7 8 9 ... 17650 17651 17652 17653 17654 17655 17656 17657 17658 17659 . ID 209658 | 212198 | 224334 | 192985 | 224232 | 212622 | 197445 | 187961 | 208333 | 210514 | ... | 256879 | 269546 | 267647 | 253186 | 267461 | 269526 | 267946 | 270567 | 256624 | 256376 | . Name L. Goretzka | Bruno Fernandes | M. Acuña | K. De Bruyne | N. Barella | J. Kimmich | D. Alaba | 22 Paulinho | E. Can | João Cancelo | ... | 22 G. Leijon | Wu Fei | 22 E. Grosz | 22 S. Booth | 22 L. Grimpe | Deng Xiongtao | 22 Lim Jun Sub | A. Demir | 21 S. Czajor | 21 F. Jakobsson | . Age 27 | 27 | 30 | 31 | 25 | 27 | 30 | 32 | 28 | 28 | ... | 19 | 32 | 18 | 20 | 17 | 19 | 17 | 25 | 18 | 20 | . Photo https://cdn.sofifa.net/players/209/658/23_60.png | https://cdn.sofifa.net/players/212/198/23_60.png | https://cdn.sofifa.net/players/224/334/23_60.png | https://cdn.sofifa.net/players/192/985/23_60.png | https://cdn.sofifa.net/players/224/232/23_60.png | https://cdn.sofifa.net/players/212/622/23_60.png | https://cdn.sofifa.net/players/197/445/23_60.png | https://cdn.sofifa.net/players/187/961/22_60.png | https://cdn.sofifa.net/players/208/333/23_60.png | https://cdn.sofifa.net/players/210/514/23_60.png | ... | https://cdn.sofifa.net/players/256/879/22_60.png | https://cdn.sofifa.net/players/269/546/23_60.png | https://cdn.sofifa.net/players/267/647/22_60.png | https://cdn.sofifa.net/players/253/186/22_60.png | https://cdn.sofifa.net/players/267/461/22_60.png | https://cdn.sofifa.net/players/269/526/23_60.png | https://cdn.sofifa.net/players/267/946/22_60.png | https://cdn.sofifa.net/players/270/567/23_60.png | https://cdn.sofifa.net/players/256/624/21_60.png | https://cdn.sofifa.net/players/256/376/21_60.png | . Nationality Germany | Portugal | Argentina | Belgium | Italy | Germany | Austria | Brazil | Germany | Portugal | ... | Sweden | China PR | Romania | England | Germany | China PR | Korea Republic | Turkey | Poland | Sweden | . Flag https://cdn.sofifa.net/flags/de.png | https://cdn.sofifa.net/flags/pt.png | https://cdn.sofifa.net/flags/ar.png | https://cdn.sofifa.net/flags/be.png | https://cdn.sofifa.net/flags/it.png | https://cdn.sofifa.net/flags/de.png | https://cdn.sofifa.net/flags/at.png | https://cdn.sofifa.net/flags/br.png | https://cdn.sofifa.net/flags/de.png | https://cdn.sofifa.net/flags/pt.png | ... | https://cdn.sofifa.net/flags/se.png | https://cdn.sofifa.net/flags/cn.png | https://cdn.sofifa.net/flags/ro.png | https://cdn.sofifa.net/flags/gb-eng.png | https://cdn.sofifa.net/flags/de.png | https://cdn.sofifa.net/flags/cn.png | https://cdn.sofifa.net/flags/kr.png | https://cdn.sofifa.net/flags/tr.png | https://cdn.sofifa.net/flags/pl.png | https://cdn.sofifa.net/flags/se.png | . Overall 87 | 86 | 85 | 91 | 86 | 89 | 86 | 83 | 82 | 88 | ... | 52 | 51 | 52 | 51 | 54 | 48 | 48 | 51 | 50 | 50 | . Potential 88 | 87 | 85 | 91 | 89 | 90 | 86 | 83 | 82 | 88 | ... | 62 | 51 | 70 | 60 | 68 | 61 | 64 | 56 | 65 | 61 | . Club FC Bayern München | Manchester United | Sevilla FC | Manchester City | Inter | FC Bayern München | Real Madrid CF | Al Ahli | Borussia Dortmund | Manchester City | ... | Örebro SK | Wuhan Three Towns | Gaz Metan Mediaş | Crewe Alexandra | RB Leipzig | Meizhou Hakka | Jeju United FC | Ümraniyespor | Fleetwood Town | IFK Norrköping | . Club Logo https://cdn.sofifa.net/teams/21/30.png | https://cdn.sofifa.net/teams/11/30.png | https://cdn.sofifa.net/teams/481/30.png | https://cdn.sofifa.net/teams/10/30.png | https://cdn.sofifa.net/teams/44/30.png | https://cdn.sofifa.net/teams/21/30.png | https://cdn.sofifa.net/teams/243/30.png | https://cdn.sofifa.net/teams/112387/30.png | https://cdn.sofifa.net/teams/22/30.png | https://cdn.sofifa.net/teams/10/30.png | ... | https://cdn.sofifa.net/teams/705/30.png | https://cdn.sofifa.net/teams/116361/30.png | https://cdn.sofifa.net/teams/112637/30.png | https://cdn.sofifa.net/teams/121/30.png | https://cdn.sofifa.net/teams/112172/30.png | https://cdn.sofifa.net/teams/114628/30.png | https://cdn.sofifa.net/teams/1478/30.png | https://cdn.sofifa.net/teams/113796/30.png | https://cdn.sofifa.net/teams/112260/30.png | https://cdn.sofifa.net/teams/702/30.png | . Value €91M | €78.5M | €46.5M | €107.5M | €89.5M | €105.5M | €55.5M | €28.5M | €30.5M | €82.5M | ... | €150K | €30K | €180K | €110K | €210K | €100K | €100K | €70K | €90K | €90K | . Wage €115K | €190K | €46K | €350K | €110K | €130K | €220K | €61K | €63K | €250K | ... | €500 | €2K | €500 | €850 | €500 | €500 | €500 | €2K | €500 | €500 | . Special 2312 | 2305 | 2303 | 2303 | 2296 | 2283 | 2277 | 2273 | 2271 | 2262 | ... | 779 | 777 | 775 | 768 | 767 | 762 | 761 | 759 | 758 | 749 | . Preferred Foot Right | Right | Left | Right | Right | Right | Left | Right | Right | Right | ... | Right | Right | Right | Right | Right | Right | Right | Right | Right | Left | . International Reputation 4.0 | 3.0 | 2.0 | 4.0 | 3.0 | 4.0 | 4.0 | 3.0 | 3.0 | 3.0 | ... | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | . Weak Foot 4.0 | 3.0 | 3.0 | 5.0 | 3.0 | 4.0 | 4.0 | 4.0 | 4.0 | 4.0 | ... | 3.0 | 2.0 | 2.0 | 2.0 | 3.0 | 3.0 | 2.0 | 2.0 | 2.0 | 2.0 | . Skill Moves 3.0 | 4.0 | 3.0 | 4.0 | 3.0 | 3.0 | 3.0 | 4.0 | 3.0 | 4.0 | ... | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | . Work Rate High/ Medium | High/ High | High/ High | High/ High | High/ High | High/ Medium | Medium/ Medium | High/ High | Medium/ High | High/ Medium | ... | Medium/ Medium | Medium/ Medium | Medium/ Medium | Medium/ Medium | Medium/ Medium | Medium/ Medium | Medium/ Medium | Medium/ Medium | Medium/ Medium | Medium/ Medium | . Body Type Unique | Unique | Stocky (170-185) | Unique | Normal (170-) | Normal (170-185) | Normal (170-185) | Normal (170-185) | Stocky (185+) | Unique | ... | Normal (185+) | Normal (185+) | Lean (185+) | Lean (185+) | Lean (185+) | Normal (185+) | Lean (185+) | Lean (185+) | Normal (185+) | Normal (185+) | . Real Face Yes | Yes | No | Yes | Yes | Yes | Yes | Yes | Yes | Yes | ... | No | No | No | No | No | No | No | No | No | No | . Position &lt;span class=&quot;pos pos28&quot;&gt;SUB | &lt;span class=&quot;pos pos15&quot;&gt;LCM | &lt;span class=&quot;pos pos7&quot;&gt;LB | &lt;span class=&quot;pos pos13&quot;&gt;RCM | &lt;span class=&quot;pos pos13&quot;&gt;RCM | &lt;span class=&quot;pos pos9&quot;&gt;RDM | &lt;span class=&quot;pos pos6&quot;&gt;LCB | &lt;span class=&quot;pos pos15&quot;&gt;LCM | &lt;span class=&quot;pos pos28&quot;&gt;SUB | &lt;span class=&quot;pos pos7&quot;&gt;LB | ... | &lt;span class=&quot;pos pos28&quot;&gt;SUB | &lt;span class=&quot;pos pos28&quot;&gt;SUB | &lt;span class=&quot;pos pos28&quot;&gt;SUB | &lt;span class=&quot;pos pos29&quot;&gt;RES | &lt;span class=&quot;pos pos29&quot;&gt;RES | &lt;span class=&quot;pos pos29&quot;&gt;RES | &lt;span class=&quot;pos pos29&quot;&gt;RES | &lt;span class=&quot;pos pos29&quot;&gt;RES | &lt;span class=&quot;pos pos29&quot;&gt;RES | &lt;span class=&quot;pos pos29&quot;&gt;RES | . Joined Jul 1, 2018 | Jan 30, 2020 | Sep 14, 2020 | Aug 30, 2015 | Sep 1, 2020 | Jul 1, 2015 | Jul 1, 2021 | Jul 22, 2021 | Feb 18, 2020 | Aug 7, 2019 | ... | Jun 14, 2020 | Feb 15, 2019 | Jul 1, 2020 | Jul 1, 2019 | Feb 7, 2022 | Apr 11, 2022 | Jan 1, 2022 | Jun 6, 2021 | Jan 1, 2020 | Jan 8, 2020 | . Loaned From NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . Contract Valid Until 2026 | 2026 | 2024 | 2025 | 2026 | 2025 | 2026 | 2024 | 2024 | 2027 | ... | 2022 | 2022 | 2022 | 2022 | 2023 | 2027 | 2026 | 2023 | 2021 | 2021 | . Height 189cm | 179cm | 172cm | 181cm | 172cm | 177cm | 180cm | 183cm | 186cm | 182cm | ... | 188cm | 186cm | 190cm | 195cm | 186cm | 190cm | 195cm | 190cm | 187cm | 186cm | . Weight 82kg | 69kg | 69kg | 70kg | 68kg | 75kg | 78kg | 80kg | 86kg | 74kg | ... | 81kg | 78kg | 70kg | 80kg | 78kg | 78kg | 84kg | 82kg | 79kg | 78kg | . Release Clause €157M | €155M | €97.7M | €198.9M | €154.4M | €182M | €113.8M | €48.5M | €51.9M | €152.6M | ... | €218K | €47K | €356K | €215K | €488K | €218K | €188K | €142K | €214K | €131K | . Kit Number 8.0 | 8.0 | 19.0 | 17.0 | 23.0 | 6.0 | 4.0 | 15.0 | 23.0 | 7.0 | ... | 33.0 | 1.0 | 99.0 | 27.0 | 43.0 | 35.0 | 21.0 | 12.0 | 40.0 | 30.0 | . Best Overall Rating NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 29 rows × 17660 columns . - column이름조사 . df.keys() . Index([&#39;ID&#39;, &#39;Name&#39;, &#39;Age&#39;, &#39;Photo&#39;, &#39;Nationality&#39;, &#39;Flag&#39;, &#39;Overall&#39;, &#39;Potential&#39;, &#39;Club&#39;, &#39;Club Logo&#39;, &#39;Value&#39;, &#39;Wage&#39;, &#39;Special&#39;, &#39;Preferred Foot&#39;, &#39;International Reputation&#39;, &#39;Weak Foot&#39;, &#39;Skill Moves&#39;, &#39;Work Rate&#39;, &#39;Body Type&#39;, &#39;Real Face&#39;, &#39;Position&#39;, &#39;Joined&#39;, &#39;Loaned From&#39;, &#39;Contract Valid Until&#39;, &#39;Height&#39;, &#39;Weight&#39;, &#39;Release Clause&#39;, &#39;Kit Number&#39;, &#39;Best Overall Rating&#39;], dtype=&#39;object&#39;) . 이름에 space가 있어서 좀 거슬림 | . - 각 column 별로 자료형조사 . pd.DataFrame({&#39;colname&#39;:df.keys(), &#39;dtype&#39;:[df[key].dtype for key in df.keys()]}) . colname dtype . 0 ID | int64 | . 1 Name | object | . 2 Age | int64 | . 3 Photo | object | . 4 Nationality | object | . 5 Flag | object | . 6 Overall | int64 | . 7 Potential | int64 | . 8 Club | object | . 9 Club Logo | object | . 10 Value | object | . 11 Wage | object | . 12 Special | int64 | . 13 Preferred Foot | object | . 14 International Reputation | float64 | . 15 Weak Foot | float64 | . 16 Skill Moves | float64 | . 17 Work Rate | object | . 18 Body Type | object | . 19 Real Face | object | . 20 Position | object | . 21 Joined | object | . 22 Loaned From | object | . 23 Contract Valid Until | object | . 24 Height | object | . 25 Weight | object | . 26 Release Clause | object | . 27 Kit Number | float64 | . 28 Best Overall Rating | object | . - 결측치조사 . pd.DataFrame({&#39;colname&#39;:df.keys(), &#39;dtype&#39;:[df[key].dtype for key in df.keys()], &#39;na&#39;:[df[key].isna().sum() for key in df.keys()] }) . colname dtype na . 0 ID | int64 | 0 | . 1 Name | object | 0 | . 2 Age | int64 | 0 | . 3 Photo | object | 0 | . 4 Nationality | object | 0 | . 5 Flag | object | 0 | . 6 Overall | int64 | 0 | . 7 Potential | int64 | 0 | . 8 Club | object | 211 | . 9 Club Logo | object | 0 | . 10 Value | object | 0 | . 11 Wage | object | 0 | . 12 Special | int64 | 0 | . 13 Preferred Foot | object | 0 | . 14 International Reputation | float64 | 0 | . 15 Weak Foot | float64 | 0 | . 16 Skill Moves | float64 | 0 | . 17 Work Rate | object | 0 | . 18 Body Type | object | 38 | . 19 Real Face | object | 38 | . 20 Position | object | 35 | . 21 Joined | object | 1098 | . 22 Loaned From | object | 16966 | . 23 Contract Valid Until | object | 361 | . 24 Height | object | 0 | . 25 Weight | object | 0 | . 26 Release Clause | object | 1151 | . 27 Kit Number | float64 | 35 | . 28 Best Overall Rating | object | 17639 | . (퀴즈) 열의선택: 결측치가 10000개 이상인 열을 보고싶다면? . df.loc[:,[df[key].isna().sum()&gt;10000 for key in df.keys()]] . Loaned From Best Overall Rating . 0 NaN | NaN | . 1 NaN | NaN | . 2 NaN | NaN | . 3 NaN | NaN | . 4 NaN | NaN | . ... ... | ... | . 17655 NaN | NaN | . 17656 NaN | NaN | . 17657 NaN | NaN | . 17658 NaN | NaN | . 17659 NaN | NaN | . 17660 rows × 2 columns . - .info() . df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 17660 entries, 0 to 17659 Data columns (total 29 columns): # Column Non-Null Count Dtype -- -- 0 ID 17660 non-null int64 1 Name 17660 non-null object 2 Age 17660 non-null int64 3 Photo 17660 non-null object 4 Nationality 17660 non-null object 5 Flag 17660 non-null object 6 Overall 17660 non-null int64 7 Potential 17660 non-null int64 8 Club 17449 non-null object 9 Club Logo 17660 non-null object 10 Value 17660 non-null object 11 Wage 17660 non-null object 12 Special 17660 non-null int64 13 Preferred Foot 17660 non-null object 14 International Reputation 17660 non-null float64 15 Weak Foot 17660 non-null float64 16 Skill Moves 17660 non-null float64 17 Work Rate 17660 non-null object 18 Body Type 17622 non-null object 19 Real Face 17622 non-null object 20 Position 17625 non-null object 21 Joined 16562 non-null object 22 Loaned From 694 non-null object 23 Contract Valid Until 17299 non-null object 24 Height 17660 non-null object 25 Weight 17660 non-null object 26 Release Clause 16509 non-null object 27 Kit Number 17625 non-null float64 28 Best Overall Rating 21 non-null object dtypes: float64(4), int64(5), object(20) memory usage: 3.9+ MB . - .describe(): 숫자들이 저장된 column에 대하여 기본통계량 조사 . df.describe() . ID Age Overall Potential Special International Reputation Weak Foot Skill Moves Kit Number . count 17660.000000 | 17660.000000 | 17660.000000 | 17660.000000 | 17660.000000 | 17660.000000 | 17660.000000 | 17660.000000 | 17625.000000 | . mean 246319.424462 | 23.127746 | 63.369592 | 70.981200 | 1537.915855 | 1.106285 | 2.900340 | 2.297169 | 25.037957 | . std 31487.892861 | 4.639821 | 8.036268 | 6.529836 | 285.893809 | 0.407021 | 0.663523 | 0.754264 | 19.154116 | . min 16.000000 | 15.000000 | 43.000000 | 42.000000 | 749.000000 | 1.000000 | 1.000000 | 1.000000 | 1.000000 | . 25% 240732.500000 | 20.000000 | 58.000000 | 67.000000 | 1387.000000 | 1.000000 | 3.000000 | 2.000000 | 11.000000 | . 50% 257041.000000 | 22.000000 | 63.000000 | 71.000000 | 1548.000000 | 1.000000 | 3.000000 | 2.000000 | 22.000000 | . 75% 263027.500000 | 26.000000 | 69.000000 | 75.000000 | 1727.000000 | 1.000000 | 3.000000 | 3.000000 | 32.000000 | . max 271340.000000 | 54.000000 | 91.000000 | 95.000000 | 2312.000000 | 5.000000 | 5.000000 | 5.000000 | 99.000000 | . - pandas_profiling.ProfileReport()을 이용한 전체적인 조사 . pandas_profiling.ProfileReport(df).to_file(&#39;fifa2023_reprot.html&#39;) . /home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/pandas_profiling/model/correlations.py:73: UserWarning: There was an attempt to calculate the auto correlation, but this failed. To hide this warning, disable the calculation (using `df.profile_report(correlations={&#34;auto&#34;: {&#34;calculate&#34;: False}})` If this is problematic for your use case, please report this as an issue: https://github.com/ydataai/pandas-profiling/issues (include the error message: &#39;No data; `observed` has size 0.&#39;) . - 특정열을 중심으로 정렬하여 보기 . df.sort_values(by=&#39;Overall&#39;,ascending=False).reset_index() . index ID Name Age Photo Nationality Flag Overall Potential Club ... Real Face Position Joined Loaned From Contract Valid Until Height Weight Release Clause Kit Number Best Overall Rating . 0 41 | 188545 | R. Lewandowski | 33 | https://cdn.sofifa.net/players/188/545/23_60.png | Poland | https://cdn.sofifa.net/flags/pl.png | 91 | 91 | FC Barcelona | ... | Yes | &lt;span class=&quot;pos pos25&quot;&gt;ST | Jul 18, 2022 | NaN | 2025 | 185cm | 81kg | €172.2M | 9.0 | NaN | . 1 124 | 165153 | K. Benzema | 34 | https://cdn.sofifa.net/players/165/153/23_60.png | France | https://cdn.sofifa.net/flags/fr.png | 91 | 91 | Real Madrid CF | ... | Yes | &lt;span class=&quot;pos pos21&quot;&gt;CF | Jul 9, 2009 | NaN | 2023 | 185cm | 81kg | €131.2M | 9.0 | NaN | . 2 3 | 192985 | K. De Bruyne | 31 | https://cdn.sofifa.net/players/192/985/23_60.png | Belgium | https://cdn.sofifa.net/flags/be.png | 91 | 91 | Manchester City | ... | Yes | &lt;span class=&quot;pos pos13&quot;&gt;RCM | Aug 30, 2015 | NaN | 2025 | 181cm | 70kg | €198.9M | 17.0 | NaN | . 3 56 | 158023 | L. Messi | 35 | https://cdn.sofifa.net/players/158/023/23_60.png | Argentina | https://cdn.sofifa.net/flags/ar.png | 91 | 91 | Paris Saint-Germain | ... | Yes | &lt;span class=&quot;pos pos23&quot;&gt;RW | Aug 10, 2021 | NaN | 2023 | 169cm | 67kg | €99.9M | 30.0 | NaN | . 4 75 | 231747 | K. Mbappé | 23 | https://cdn.sofifa.net/players/231/747/23_60.png | France | https://cdn.sofifa.net/flags/fr.png | 91 | 95 | Paris Saint-Germain | ... | Yes | &lt;span class=&quot;pos pos25&quot;&gt;ST | Jul 1, 2018 | NaN | 2025 | 182cm | 73kg | €366.7M | 7.0 | NaN | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 17655 15513 | 266751 | 22 Jung Ho Yeon | 20 | https://cdn.sofifa.net/players/266/751/22_60.png | Korea Republic | https://cdn.sofifa.net/flags/kr.png | 45 | 53 | GwangJu FC | ... | No | &lt;span class=&quot;pos pos29&quot;&gt;RES | Jan 20, 2022 | NaN | 2026 | 180cm | 73kg | €145K | 23.0 | NaN | . 17656 16215 | 268279 | 22 J. Looschen | 24 | https://cdn.sofifa.net/players/268/279/22_60.png | Germany | https://cdn.sofifa.net/flags/de.png | 44 | 47 | SV Meppen | ... | No | &lt;span class=&quot;pos pos29&quot;&gt;RES | Mar 19, 2022 | NaN | 2026 | 178cm | 78kg | €92K | 42.0 | NaN | . 17657 16042 | 255283 | 20 Kim Yeong Geun | 22 | https://cdn.sofifa.net/players/255/283/20_60.png | Korea Republic | https://cdn.sofifa.net/flags/kr.png | 44 | 49 | Gyeongnam FC | ... | No | &lt;span class=&quot;pos pos29&quot;&gt;RES | Jan 9, 2020 | NaN | 2020 | 174cm | 71kg | €53K | 43.0 | NaN | . 17658 14634 | 269038 | 22 Zhang Wenxuan | 16 | https://cdn.sofifa.net/players/269/038/22_60.png | China PR | https://cdn.sofifa.net/flags/cn.png | 44 | 59 | Guangzhou FC | ... | No | &lt;span class=&quot;pos pos29&quot;&gt;RES | May 1, 2022 | NaN | 2022 | 175cm | 70kg | €239K | 29.0 | NaN | . 17659 17618 | 168933 | 07 I. Paskov | 33 | https://cdn.sofifa.net/players/168/933/07_60.png | Bulgaria | https://cdn.sofifa.net/flags/bg.png | 43 | 42 | NaN | ... | NaN | &lt;span class=&quot;pos pos28&quot;&gt;SUB | NaN | NaN | NaN | 184cm | 79kg | NaN | 24.0 | NaN | . 17660 rows × 30 columns . - 특정열을 중심으로 그룹화하여 보기 ($ star$) . df.Nationality.unique() # 데이터셋에 포함된 나라들 출력 . array([&#39;Germany&#39;, &#39;Portugal&#39;, &#39;Argentina&#39;, &#39;Belgium&#39;, &#39;Italy&#39;, &#39;Austria&#39;, &#39;Brazil&#39;, &#39;Croatia&#39;, &#39;Serbia&#39;, &#39;Spain&#39;, &#39;Netherlands&#39;, &#39;France&#39;, &#39;Colombia&#39;, &#39;England&#39;, &#39;Uruguay&#39;, &#39;Morocco&#39;, &#39;Egypt&#39;, &#39;Algeria&#39;, &#39;Ukraine&#39;, &#39;United States&#39;, &#34;Côte d&#39;Ivoire&#34;, &#39;Poland&#39;, &#39;Chile&#39;, &#39;Senegal&#39;, &#39;Central African Republic&#39;, &#39;Denmark&#39;, &#39;Nigeria&#39;, &#39;Mexico&#39;, &#39;Turkey&#39;, &#39;Canada&#39;, &#39;Wales&#39;, &#39;Scotland&#39;, &#39;Romania&#39;, &#39;Czech Republic&#39;, &#39;Ghana&#39;, &#39;Korea Republic&#39;, &#39;Bosnia and Herzegovina&#39;, &#39;Mali&#39;, &#39;Slovakia&#39;, &#39;Armenia&#39;, &#39;Norway&#39;, &#39;Switzerland&#39;, &#39;Cameroon&#39;, &#39;Peru&#39;, &#39;Jamaica&#39;, &#39;Zambia&#39;, &#39;Guinea&#39;, &#39;Sweden&#39;, &#39;North Macedonia&#39;, &#39;Russia&#39;, &#39;Tunisia&#39;, &#39;Malta&#39;, &#39;Angola&#39;, &#39;Republic of Ireland&#39;, &#39;Ecuador&#39;, &#39;Benin&#39;, &#39;Paraguay&#39;, &#39;Montenegro&#39;, &#39;Australia&#39;, &#39;Comoros&#39;, &#39;Gabon&#39;, &#39;Iceland&#39;, &#39;Slovenia&#39;, &#39;Japan&#39;, &#39;Israel&#39;, &#39;China PR&#39;, &#39;Venezuela&#39;, &#39;Liberia&#39;, &#39;Greece&#39;, &#39;Bulgaria&#39;, &#39;Honduras&#39;, &#39;Saudi Arabia&#39;, &#39;Curacao&#39;, &#39;Northern Ireland&#39;, &#39;Guinea Bissau&#39;, &#39;Kosovo&#39;, &#39;Hungary&#39;, &#39;Finland&#39;, &#39;Costa Rica&#39;, &#39;Albania&#39;, &#39;Congo DR&#39;, &#39;Iran&#39;, &#39;Mozambique&#39;, &#39;Suriname&#39;, &#39;Cape Verde Islands&#39;, &#39;Bolivia&#39;, &#39;Madagascar&#39;, &#39;New Zealand&#39;, &#39;Burkina Faso&#39;, &#39;Dominican Republic&#39;, &#39;Kazakhstan&#39;, &#39;Syria&#39;, &#39;Luxembourg&#39;, &#39;Kenya&#39;, &#39;Zimbabwe&#39;, &#39;Haiti&#39;, &#39;Uzbekistan&#39;, &#39;South Africa&#39;, &#39;Cyprus&#39;, &#39;Qatar&#39;, &#39;Equatorial Guinea&#39;, &#39;Libya&#39;, &#39;Thailand&#39;, &#39;Togo&#39;, &#39;Trinidad and Tobago&#39;, &#39;Liechtenstein&#39;, &#39;Gambia&#39;, &#39;Georgia&#39;, &#39;Philippines&#39;, &#39;Burundi&#39;, &#39;United Arab Emirates&#39;, &#39;Grenada&#39;, &#39;Iraq&#39;, &#39;Panama&#39;, &#39;Malaysia&#39;, &#39;Moldova&#39;, &#39;Congo&#39;, &#39;India&#39;, &#39;Jordan&#39;, &#39;Kuwait&#39;, &#39;Antigua and Barbuda&#39;, &#39;Cuba&#39;, &#39;Vietnam&#39;, &#39;Korea DPR&#39;, &#39;Uganda&#39;, &#39;Lithuania&#39;, &#39;Estonia&#39;, &#39;Montserrat&#39;, &#39;Sierra Leone&#39;, &#39;Afghanistan&#39;, &#39;New Caledonia&#39;, &#39;Belarus&#39;, &#39;Laos&#39;, &#39;Saint Lucia&#39;, &#39;Bhutan&#39;, &#39;Guyana&#39;, &#39;Mauritania&#39;, &#39;Faroe Islands&#39;, &#39;Namibia&#39;, &#39;Niger&#39;, &#39;Palestine&#39;, &#39;Sudan&#39;, &#39;Azerbaijan&#39;, &#39;Hong Kong&#39;, &#39;Gibraltar&#39;, &#39;Tanzania&#39;, &#39;Latvia&#39;, &#39;Chinese Taipei&#39;, &#39;Singapore&#39;, &#39;Lebanon&#39;, &#39;El Salvador&#39;, &#39;Indonesia&#39;, &#39;Guatemala&#39;, &#39;Papua New Guinea&#39;, &#39;Puerto Rico&#39;, &#39;Malawi&#39;, &#39;South Sudan&#39;, &#39;Ethiopia&#39;, &#39;San Marino&#39;, &#39;Andorra&#39;, &#39;Saint Kitts and Nevis&#39;], dtype=object) . df.groupby(by=&#39;Nationality&#39;)[[&#39;Overall&#39;]].agg({np.mean,len}).sort_values((&#39;Overall&#39;, &#39;mean&#39;),ascending=False) . Overall . mean len . Nationality . Philippines 74.000000 | 1 | . Namibia 72.000000 | 1 | . Mozambique 72.000000 | 2 | . Kuwait 71.000000 | 1 | . Brazil 70.556586 | 539 | . ... ... | ... | . San Marino 53.000000 | 1 | . China PR 52.230769 | 325 | . South Sudan 52.000000 | 5 | . India 51.994681 | 188 | . Saint Kitts and Nevis 51.000000 | 1 | . 161 rows × 2 columns . groupby는 나중에 다시 설명 합니다. | . &#45936;&#51060;&#53552;&#51221;&#47532;&#54616;&#44592; . - 칼럼이름변경 . df.set_axis(pd.Index(map(lambda x: x.replace(&#39; &#39;,&#39;_&#39;), df.columns)), axis=1) . ID Name Age Photo Nationality Flag Overall Potential Club Club_Logo ... Real_Face Position Joined Loaned_From Contract_Valid_Until Height Weight Release_Clause Kit_Number Best_Overall_Rating . 0 209658 | L. Goretzka | 27 | https://cdn.sofifa.net/players/209/658/23_60.png | Germany | https://cdn.sofifa.net/flags/de.png | 87 | 88 | FC Bayern München | https://cdn.sofifa.net/teams/21/30.png | ... | Yes | &lt;span class=&quot;pos pos28&quot;&gt;SUB | Jul 1, 2018 | NaN | 2026 | 189cm | 82kg | €157M | 8.0 | NaN | . 1 212198 | Bruno Fernandes | 27 | https://cdn.sofifa.net/players/212/198/23_60.png | Portugal | https://cdn.sofifa.net/flags/pt.png | 86 | 87 | Manchester United | https://cdn.sofifa.net/teams/11/30.png | ... | Yes | &lt;span class=&quot;pos pos15&quot;&gt;LCM | Jan 30, 2020 | NaN | 2026 | 179cm | 69kg | €155M | 8.0 | NaN | . 2 224334 | M. Acuña | 30 | https://cdn.sofifa.net/players/224/334/23_60.png | Argentina | https://cdn.sofifa.net/flags/ar.png | 85 | 85 | Sevilla FC | https://cdn.sofifa.net/teams/481/30.png | ... | No | &lt;span class=&quot;pos pos7&quot;&gt;LB | Sep 14, 2020 | NaN | 2024 | 172cm | 69kg | €97.7M | 19.0 | NaN | . 3 192985 | K. De Bruyne | 31 | https://cdn.sofifa.net/players/192/985/23_60.png | Belgium | https://cdn.sofifa.net/flags/be.png | 91 | 91 | Manchester City | https://cdn.sofifa.net/teams/10/30.png | ... | Yes | &lt;span class=&quot;pos pos13&quot;&gt;RCM | Aug 30, 2015 | NaN | 2025 | 181cm | 70kg | €198.9M | 17.0 | NaN | . 4 224232 | N. Barella | 25 | https://cdn.sofifa.net/players/224/232/23_60.png | Italy | https://cdn.sofifa.net/flags/it.png | 86 | 89 | Inter | https://cdn.sofifa.net/teams/44/30.png | ... | Yes | &lt;span class=&quot;pos pos13&quot;&gt;RCM | Sep 1, 2020 | NaN | 2026 | 172cm | 68kg | €154.4M | 23.0 | NaN | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 17655 269526 | Deng Xiongtao | 19 | https://cdn.sofifa.net/players/269/526/23_60.png | China PR | https://cdn.sofifa.net/flags/cn.png | 48 | 61 | Meizhou Hakka | https://cdn.sofifa.net/teams/114628/30.png | ... | No | &lt;span class=&quot;pos pos29&quot;&gt;RES | Apr 11, 2022 | NaN | 2027 | 190cm | 78kg | €218K | 35.0 | NaN | . 17656 267946 | 22 Lim Jun Sub | 17 | https://cdn.sofifa.net/players/267/946/22_60.png | Korea Republic | https://cdn.sofifa.net/flags/kr.png | 48 | 64 | Jeju United FC | https://cdn.sofifa.net/teams/1478/30.png | ... | No | &lt;span class=&quot;pos pos29&quot;&gt;RES | Jan 1, 2022 | NaN | 2026 | 195cm | 84kg | €188K | 21.0 | NaN | . 17657 270567 | A. Demir | 25 | https://cdn.sofifa.net/players/270/567/23_60.png | Turkey | https://cdn.sofifa.net/flags/tr.png | 51 | 56 | Ümraniyespor | https://cdn.sofifa.net/teams/113796/30.png | ... | No | &lt;span class=&quot;pos pos29&quot;&gt;RES | Jun 6, 2021 | NaN | 2023 | 190cm | 82kg | €142K | 12.0 | NaN | . 17658 256624 | 21 S. Czajor | 18 | https://cdn.sofifa.net/players/256/624/21_60.png | Poland | https://cdn.sofifa.net/flags/pl.png | 50 | 65 | Fleetwood Town | https://cdn.sofifa.net/teams/112260/30.png | ... | No | &lt;span class=&quot;pos pos29&quot;&gt;RES | Jan 1, 2020 | NaN | 2021 | 187cm | 79kg | €214K | 40.0 | NaN | . 17659 256376 | 21 F. Jakobsson | 20 | https://cdn.sofifa.net/players/256/376/21_60.png | Sweden | https://cdn.sofifa.net/flags/se.png | 50 | 61 | IFK Norrköping | https://cdn.sofifa.net/teams/702/30.png | ... | No | &lt;span class=&quot;pos pos29&quot;&gt;RES | Jan 8, 2020 | NaN | 2021 | 186cm | 78kg | €131K | 30.0 | NaN | . 17660 rows × 29 columns . - 결측치제거 . df.drop(columns=[&#39;Loaned From&#39;, &#39;Best Overall Rating&#39;]).dropna() . ID Name Age Photo Nationality Flag Overall Potential Club Club Logo ... Work Rate Body Type Real Face Position Joined Contract Valid Until Height Weight Release Clause Kit Number . 0 209658 | L. Goretzka | 27 | https://cdn.sofifa.net/players/209/658/23_60.png | Germany | https://cdn.sofifa.net/flags/de.png | 87 | 88 | FC Bayern München | https://cdn.sofifa.net/teams/21/30.png | ... | High/ Medium | Unique | Yes | &lt;span class=&quot;pos pos28&quot;&gt;SUB | Jul 1, 2018 | 2026 | 189cm | 82kg | €157M | 8.0 | . 1 212198 | Bruno Fernandes | 27 | https://cdn.sofifa.net/players/212/198/23_60.png | Portugal | https://cdn.sofifa.net/flags/pt.png | 86 | 87 | Manchester United | https://cdn.sofifa.net/teams/11/30.png | ... | High/ High | Unique | Yes | &lt;span class=&quot;pos pos15&quot;&gt;LCM | Jan 30, 2020 | 2026 | 179cm | 69kg | €155M | 8.0 | . 2 224334 | M. Acuña | 30 | https://cdn.sofifa.net/players/224/334/23_60.png | Argentina | https://cdn.sofifa.net/flags/ar.png | 85 | 85 | Sevilla FC | https://cdn.sofifa.net/teams/481/30.png | ... | High/ High | Stocky (170-185) | No | &lt;span class=&quot;pos pos7&quot;&gt;LB | Sep 14, 2020 | 2024 | 172cm | 69kg | €97.7M | 19.0 | . 3 192985 | K. De Bruyne | 31 | https://cdn.sofifa.net/players/192/985/23_60.png | Belgium | https://cdn.sofifa.net/flags/be.png | 91 | 91 | Manchester City | https://cdn.sofifa.net/teams/10/30.png | ... | High/ High | Unique | Yes | &lt;span class=&quot;pos pos13&quot;&gt;RCM | Aug 30, 2015 | 2025 | 181cm | 70kg | €198.9M | 17.0 | . 4 224232 | N. Barella | 25 | https://cdn.sofifa.net/players/224/232/23_60.png | Italy | https://cdn.sofifa.net/flags/it.png | 86 | 89 | Inter | https://cdn.sofifa.net/teams/44/30.png | ... | High/ High | Normal (170-) | Yes | &lt;span class=&quot;pos pos13&quot;&gt;RCM | Sep 1, 2020 | 2026 | 172cm | 68kg | €154.4M | 23.0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 17655 269526 | Deng Xiongtao | 19 | https://cdn.sofifa.net/players/269/526/23_60.png | China PR | https://cdn.sofifa.net/flags/cn.png | 48 | 61 | Meizhou Hakka | https://cdn.sofifa.net/teams/114628/30.png | ... | Medium/ Medium | Normal (185+) | No | &lt;span class=&quot;pos pos29&quot;&gt;RES | Apr 11, 2022 | 2027 | 190cm | 78kg | €218K | 35.0 | . 17656 267946 | 22 Lim Jun Sub | 17 | https://cdn.sofifa.net/players/267/946/22_60.png | Korea Republic | https://cdn.sofifa.net/flags/kr.png | 48 | 64 | Jeju United FC | https://cdn.sofifa.net/teams/1478/30.png | ... | Medium/ Medium | Lean (185+) | No | &lt;span class=&quot;pos pos29&quot;&gt;RES | Jan 1, 2022 | 2026 | 195cm | 84kg | €188K | 21.0 | . 17657 270567 | A. Demir | 25 | https://cdn.sofifa.net/players/270/567/23_60.png | Turkey | https://cdn.sofifa.net/flags/tr.png | 51 | 56 | Ümraniyespor | https://cdn.sofifa.net/teams/113796/30.png | ... | Medium/ Medium | Lean (185+) | No | &lt;span class=&quot;pos pos29&quot;&gt;RES | Jun 6, 2021 | 2023 | 190cm | 82kg | €142K | 12.0 | . 17658 256624 | 21 S. Czajor | 18 | https://cdn.sofifa.net/players/256/624/21_60.png | Poland | https://cdn.sofifa.net/flags/pl.png | 50 | 65 | Fleetwood Town | https://cdn.sofifa.net/teams/112260/30.png | ... | Medium/ Medium | Normal (185+) | No | &lt;span class=&quot;pos pos29&quot;&gt;RES | Jan 1, 2020 | 2021 | 187cm | 79kg | €214K | 40.0 | . 17659 256376 | 21 F. Jakobsson | 20 | https://cdn.sofifa.net/players/256/376/21_60.png | Sweden | https://cdn.sofifa.net/flags/se.png | 50 | 61 | IFK Norrköping | https://cdn.sofifa.net/teams/702/30.png | ... | Medium/ Medium | Normal (185+) | No | &lt;span class=&quot;pos pos29&quot;&gt;RES | Jan 8, 2020 | 2021 | 186cm | 78kg | €131K | 30.0 | . 16364 rows × 27 columns . - Height, Weight의 자료형을 float형으로 수정하기 . df.assign( Height= list(map(lambda x: float(x[:-2]), df.Height)), Weight= list(map(lambda x: float(x[:-2]), df.Weight)) ) . ID Name Age Photo Nationality Flag Overall Potential Club Club Logo ... Real Face Position Joined Loaned From Contract Valid Until Height Weight Release Clause Kit Number Best Overall Rating . 0 209658 | L. Goretzka | 27 | https://cdn.sofifa.net/players/209/658/23_60.png | Germany | https://cdn.sofifa.net/flags/de.png | 87 | 88 | FC Bayern München | https://cdn.sofifa.net/teams/21/30.png | ... | Yes | &lt;span class=&quot;pos pos28&quot;&gt;SUB | Jul 1, 2018 | NaN | 2026 | 189.0 | 82.0 | €157M | 8.0 | NaN | . 1 212198 | Bruno Fernandes | 27 | https://cdn.sofifa.net/players/212/198/23_60.png | Portugal | https://cdn.sofifa.net/flags/pt.png | 86 | 87 | Manchester United | https://cdn.sofifa.net/teams/11/30.png | ... | Yes | &lt;span class=&quot;pos pos15&quot;&gt;LCM | Jan 30, 2020 | NaN | 2026 | 179.0 | 69.0 | €155M | 8.0 | NaN | . 2 224334 | M. Acuña | 30 | https://cdn.sofifa.net/players/224/334/23_60.png | Argentina | https://cdn.sofifa.net/flags/ar.png | 85 | 85 | Sevilla FC | https://cdn.sofifa.net/teams/481/30.png | ... | No | &lt;span class=&quot;pos pos7&quot;&gt;LB | Sep 14, 2020 | NaN | 2024 | 172.0 | 69.0 | €97.7M | 19.0 | NaN | . 3 192985 | K. De Bruyne | 31 | https://cdn.sofifa.net/players/192/985/23_60.png | Belgium | https://cdn.sofifa.net/flags/be.png | 91 | 91 | Manchester City | https://cdn.sofifa.net/teams/10/30.png | ... | Yes | &lt;span class=&quot;pos pos13&quot;&gt;RCM | Aug 30, 2015 | NaN | 2025 | 181.0 | 70.0 | €198.9M | 17.0 | NaN | . 4 224232 | N. Barella | 25 | https://cdn.sofifa.net/players/224/232/23_60.png | Italy | https://cdn.sofifa.net/flags/it.png | 86 | 89 | Inter | https://cdn.sofifa.net/teams/44/30.png | ... | Yes | &lt;span class=&quot;pos pos13&quot;&gt;RCM | Sep 1, 2020 | NaN | 2026 | 172.0 | 68.0 | €154.4M | 23.0 | NaN | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 17655 269526 | Deng Xiongtao | 19 | https://cdn.sofifa.net/players/269/526/23_60.png | China PR | https://cdn.sofifa.net/flags/cn.png | 48 | 61 | Meizhou Hakka | https://cdn.sofifa.net/teams/114628/30.png | ... | No | &lt;span class=&quot;pos pos29&quot;&gt;RES | Apr 11, 2022 | NaN | 2027 | 190.0 | 78.0 | €218K | 35.0 | NaN | . 17656 267946 | 22 Lim Jun Sub | 17 | https://cdn.sofifa.net/players/267/946/22_60.png | Korea Republic | https://cdn.sofifa.net/flags/kr.png | 48 | 64 | Jeju United FC | https://cdn.sofifa.net/teams/1478/30.png | ... | No | &lt;span class=&quot;pos pos29&quot;&gt;RES | Jan 1, 2022 | NaN | 2026 | 195.0 | 84.0 | €188K | 21.0 | NaN | . 17657 270567 | A. Demir | 25 | https://cdn.sofifa.net/players/270/567/23_60.png | Turkey | https://cdn.sofifa.net/flags/tr.png | 51 | 56 | Ümraniyespor | https://cdn.sofifa.net/teams/113796/30.png | ... | No | &lt;span class=&quot;pos pos29&quot;&gt;RES | Jun 6, 2021 | NaN | 2023 | 190.0 | 82.0 | €142K | 12.0 | NaN | . 17658 256624 | 21 S. Czajor | 18 | https://cdn.sofifa.net/players/256/624/21_60.png | Poland | https://cdn.sofifa.net/flags/pl.png | 50 | 65 | Fleetwood Town | https://cdn.sofifa.net/teams/112260/30.png | ... | No | &lt;span class=&quot;pos pos29&quot;&gt;RES | Jan 1, 2020 | NaN | 2021 | 187.0 | 79.0 | €214K | 40.0 | NaN | . 17659 256376 | 21 F. Jakobsson | 20 | https://cdn.sofifa.net/players/256/376/21_60.png | Sweden | https://cdn.sofifa.net/flags/se.png | 50 | 61 | IFK Norrköping | https://cdn.sofifa.net/teams/702/30.png | ... | No | &lt;span class=&quot;pos pos29&quot;&gt;RES | Jan 8, 2020 | NaN | 2021 | 186.0 | 78.0 | €131K | 30.0 | NaN | . 17660 rows × 29 columns . - Release Clause의 자료형을 float으로 수정하기 . df[&#39;Release Clause&#39;] . 0 €157M 1 €155M 2 €97.7M 3 €198.9M 4 €154.4M ... 17655 €218K 17656 €188K 17657 €142K 17658 €214K 17659 €131K Name: Release Clause, Length: 17660, dtype: object . _f = lambda x: float(x[1:-1])*1000 if x[-1]==&#39;K&#39; else float(x[1:-1])*1000000 . _f(&#39;€157M&#39;) . 157000000.0 . _f(&#39;€131K&#39;) . 131000.0 . (시도1--실패) . list(map(_f,df[&#39;Release Clause&#39;])) . TypeError Traceback (most recent call last) /tmp/ipykernel_1924156/248151050.py in &lt;module&gt; -&gt; 1 list(map(_f,df[&#39;Release Clause&#39;])) /tmp/ipykernel_1924156/3187235584.py in &lt;lambda&gt;(x) -&gt; 1 _f = lambda x: float(x[1:-1])*1000 if x[-1]==&#39;K&#39; else float(x[1:-1])*1000000 TypeError: &#39;float&#39; object is not subscriptable . (시도1이 실패한 이유) . df[&#39;Release Clause&#39;].isna().sum() # 이 column에는 1151개의 결측치가 존재 . 1151 . (nan에 대한 예비학습) . df.loc[df[&#39;Release Clause&#39;].isna(), &#39;Release Clause&#39;] . 18 NaN 34 NaN 38 NaN 49 NaN 50 NaN ... 17378 NaN 17386 NaN 17535 NaN 17590 NaN 17618 NaN Name: Release Clause, Length: 1151, dtype: object . df.loc[18, &#39;Release Clause&#39;] . nan . pd.isna(df.loc[18, &#39;Release Clause&#39;]) . True . type(df.loc[18, &#39;Release Clause&#39;]) . float . df.loc[18, &#39;Release Clause&#39;][-1] . TypeError Traceback (most recent call last) /tmp/ipykernel_1924156/3375660472.py in &lt;module&gt; -&gt; 1 df.loc[18, &#39;Release Clause&#39;][-1] TypeError: &#39;float&#39; object is not subscriptable . (시도2--성공) . df.rename(columns={&#39;Release Clause&#39;:&#39;ReleaseClause&#39;}) .assign(ReleaseClause = list(map(lambda x: _f(x) if pd.isna(x)==False else x , df[&#39;Release Clause&#39;]))) .rename(columns={&#39;ReleaseClause&#39;:&#39;Release Clause&#39;}) . ID Name Age Photo Nationality Flag Overall Potential Club Club Logo ... Real Face Position Joined Loaned From Contract Valid Until Height Weight Release Clause Kit Number Best Overall Rating . 0 209658 | L. Goretzka | 27 | https://cdn.sofifa.net/players/209/658/23_60.png | Germany | https://cdn.sofifa.net/flags/de.png | 87 | 88 | FC Bayern München | https://cdn.sofifa.net/teams/21/30.png | ... | Yes | &lt;span class=&quot;pos pos28&quot;&gt;SUB | Jul 1, 2018 | NaN | 2026 | 189cm | 82kg | 157000000.0 | 8.0 | NaN | . 1 212198 | Bruno Fernandes | 27 | https://cdn.sofifa.net/players/212/198/23_60.png | Portugal | https://cdn.sofifa.net/flags/pt.png | 86 | 87 | Manchester United | https://cdn.sofifa.net/teams/11/30.png | ... | Yes | &lt;span class=&quot;pos pos15&quot;&gt;LCM | Jan 30, 2020 | NaN | 2026 | 179cm | 69kg | 155000000.0 | 8.0 | NaN | . 2 224334 | M. Acuña | 30 | https://cdn.sofifa.net/players/224/334/23_60.png | Argentina | https://cdn.sofifa.net/flags/ar.png | 85 | 85 | Sevilla FC | https://cdn.sofifa.net/teams/481/30.png | ... | No | &lt;span class=&quot;pos pos7&quot;&gt;LB | Sep 14, 2020 | NaN | 2024 | 172cm | 69kg | 97700000.0 | 19.0 | NaN | . 3 192985 | K. De Bruyne | 31 | https://cdn.sofifa.net/players/192/985/23_60.png | Belgium | https://cdn.sofifa.net/flags/be.png | 91 | 91 | Manchester City | https://cdn.sofifa.net/teams/10/30.png | ... | Yes | &lt;span class=&quot;pos pos13&quot;&gt;RCM | Aug 30, 2015 | NaN | 2025 | 181cm | 70kg | 198900000.0 | 17.0 | NaN | . 4 224232 | N. Barella | 25 | https://cdn.sofifa.net/players/224/232/23_60.png | Italy | https://cdn.sofifa.net/flags/it.png | 86 | 89 | Inter | https://cdn.sofifa.net/teams/44/30.png | ... | Yes | &lt;span class=&quot;pos pos13&quot;&gt;RCM | Sep 1, 2020 | NaN | 2026 | 172cm | 68kg | 154400000.0 | 23.0 | NaN | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 17655 269526 | Deng Xiongtao | 19 | https://cdn.sofifa.net/players/269/526/23_60.png | China PR | https://cdn.sofifa.net/flags/cn.png | 48 | 61 | Meizhou Hakka | https://cdn.sofifa.net/teams/114628/30.png | ... | No | &lt;span class=&quot;pos pos29&quot;&gt;RES | Apr 11, 2022 | NaN | 2027 | 190cm | 78kg | 218000.0 | 35.0 | NaN | . 17656 267946 | 22 Lim Jun Sub | 17 | https://cdn.sofifa.net/players/267/946/22_60.png | Korea Republic | https://cdn.sofifa.net/flags/kr.png | 48 | 64 | Jeju United FC | https://cdn.sofifa.net/teams/1478/30.png | ... | No | &lt;span class=&quot;pos pos29&quot;&gt;RES | Jan 1, 2022 | NaN | 2026 | 195cm | 84kg | 188000.0 | 21.0 | NaN | . 17657 270567 | A. Demir | 25 | https://cdn.sofifa.net/players/270/567/23_60.png | Turkey | https://cdn.sofifa.net/flags/tr.png | 51 | 56 | Ümraniyespor | https://cdn.sofifa.net/teams/113796/30.png | ... | No | &lt;span class=&quot;pos pos29&quot;&gt;RES | Jun 6, 2021 | NaN | 2023 | 190cm | 82kg | 142000.0 | 12.0 | NaN | . 17658 256624 | 21 S. Czajor | 18 | https://cdn.sofifa.net/players/256/624/21_60.png | Poland | https://cdn.sofifa.net/flags/pl.png | 50 | 65 | Fleetwood Town | https://cdn.sofifa.net/teams/112260/30.png | ... | No | &lt;span class=&quot;pos pos29&quot;&gt;RES | Jan 1, 2020 | NaN | 2021 | 187cm | 79kg | 214000.0 | 40.0 | NaN | . 17659 256376 | 21 F. Jakobsson | 20 | https://cdn.sofifa.net/players/256/376/21_60.png | Sweden | https://cdn.sofifa.net/flags/se.png | 50 | 61 | IFK Norrköping | https://cdn.sofifa.net/teams/702/30.png | ... | No | &lt;span class=&quot;pos pos29&quot;&gt;RES | Jan 8, 2020 | NaN | 2021 | 186cm | 78kg | 131000.0 | 30.0 | NaN | . 17660 rows × 29 columns . (시도3--성공) 그냥 결측치를 제거하고 변형해도 무방.. . df2 = df.drop(columns=[&#39;Loaned From&#39;, &#39;Best Overall Rating&#39;]).dropna() df2[&#39;Release Clause&#39;] = list(map(lambda x: _f(x) if pd.isna(x)==False else x , df2[&#39;Release Clause&#39;])) df2 . ID Name Age Photo Nationality Flag Overall Potential Club Club Logo ... Work Rate Body Type Real Face Position Joined Contract Valid Until Height Weight Release Clause Kit Number . 0 209658 | L. Goretzka | 27 | https://cdn.sofifa.net/players/209/658/23_60.png | Germany | https://cdn.sofifa.net/flags/de.png | 87 | 88 | FC Bayern München | https://cdn.sofifa.net/teams/21/30.png | ... | High/ Medium | Unique | Yes | &lt;span class=&quot;pos pos28&quot;&gt;SUB | Jul 1, 2018 | 2026 | 189cm | 82kg | 157000000.0 | 8.0 | . 1 212198 | Bruno Fernandes | 27 | https://cdn.sofifa.net/players/212/198/23_60.png | Portugal | https://cdn.sofifa.net/flags/pt.png | 86 | 87 | Manchester United | https://cdn.sofifa.net/teams/11/30.png | ... | High/ High | Unique | Yes | &lt;span class=&quot;pos pos15&quot;&gt;LCM | Jan 30, 2020 | 2026 | 179cm | 69kg | 155000000.0 | 8.0 | . 2 224334 | M. Acuña | 30 | https://cdn.sofifa.net/players/224/334/23_60.png | Argentina | https://cdn.sofifa.net/flags/ar.png | 85 | 85 | Sevilla FC | https://cdn.sofifa.net/teams/481/30.png | ... | High/ High | Stocky (170-185) | No | &lt;span class=&quot;pos pos7&quot;&gt;LB | Sep 14, 2020 | 2024 | 172cm | 69kg | 97700000.0 | 19.0 | . 3 192985 | K. De Bruyne | 31 | https://cdn.sofifa.net/players/192/985/23_60.png | Belgium | https://cdn.sofifa.net/flags/be.png | 91 | 91 | Manchester City | https://cdn.sofifa.net/teams/10/30.png | ... | High/ High | Unique | Yes | &lt;span class=&quot;pos pos13&quot;&gt;RCM | Aug 30, 2015 | 2025 | 181cm | 70kg | 198900000.0 | 17.0 | . 4 224232 | N. Barella | 25 | https://cdn.sofifa.net/players/224/232/23_60.png | Italy | https://cdn.sofifa.net/flags/it.png | 86 | 89 | Inter | https://cdn.sofifa.net/teams/44/30.png | ... | High/ High | Normal (170-) | Yes | &lt;span class=&quot;pos pos13&quot;&gt;RCM | Sep 1, 2020 | 2026 | 172cm | 68kg | 154400000.0 | 23.0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 17655 269526 | Deng Xiongtao | 19 | https://cdn.sofifa.net/players/269/526/23_60.png | China PR | https://cdn.sofifa.net/flags/cn.png | 48 | 61 | Meizhou Hakka | https://cdn.sofifa.net/teams/114628/30.png | ... | Medium/ Medium | Normal (185+) | No | &lt;span class=&quot;pos pos29&quot;&gt;RES | Apr 11, 2022 | 2027 | 190cm | 78kg | 218000.0 | 35.0 | . 17656 267946 | 22 Lim Jun Sub | 17 | https://cdn.sofifa.net/players/267/946/22_60.png | Korea Republic | https://cdn.sofifa.net/flags/kr.png | 48 | 64 | Jeju United FC | https://cdn.sofifa.net/teams/1478/30.png | ... | Medium/ Medium | Lean (185+) | No | &lt;span class=&quot;pos pos29&quot;&gt;RES | Jan 1, 2022 | 2026 | 195cm | 84kg | 188000.0 | 21.0 | . 17657 270567 | A. Demir | 25 | https://cdn.sofifa.net/players/270/567/23_60.png | Turkey | https://cdn.sofifa.net/flags/tr.png | 51 | 56 | Ümraniyespor | https://cdn.sofifa.net/teams/113796/30.png | ... | Medium/ Medium | Lean (185+) | No | &lt;span class=&quot;pos pos29&quot;&gt;RES | Jun 6, 2021 | 2023 | 190cm | 82kg | 142000.0 | 12.0 | . 17658 256624 | 21 S. Czajor | 18 | https://cdn.sofifa.net/players/256/624/21_60.png | Poland | https://cdn.sofifa.net/flags/pl.png | 50 | 65 | Fleetwood Town | https://cdn.sofifa.net/teams/112260/30.png | ... | Medium/ Medium | Normal (185+) | No | &lt;span class=&quot;pos pos29&quot;&gt;RES | Jan 1, 2020 | 2021 | 187cm | 79kg | 214000.0 | 40.0 | . 17659 256376 | 21 F. Jakobsson | 20 | https://cdn.sofifa.net/players/256/376/21_60.png | Sweden | https://cdn.sofifa.net/flags/se.png | 50 | 61 | IFK Norrköping | https://cdn.sofifa.net/teams/702/30.png | ... | Medium/ Medium | Normal (185+) | No | &lt;span class=&quot;pos pos29&quot;&gt;RES | Jan 8, 2020 | 2021 | 186cm | 78kg | 131000.0 | 30.0 | . 16364 rows × 27 columns . 분석의 편의를 위하여 (1) colnames를 변경하고 (2) 결측치를 제거하고 (3) 몇 가지 전 처리를 추가로 진행한 뒤 df2를 만들어서 분석하는게 좋음 . &#45936;&#51060;&#53552;&#48516;&#49437;+&#49884;&#44033;&#54868; . - Overall vs Potential . ggplot(data=df) + geom_point(aes(x=&#39;Overall&#39;,y=&#39;Potential&#39;)) . &lt;ggplot: (8782116232401)&gt; . 뭔가 Potential &gt; Overall 인 관계가 성립하는 듯 하다. $ to$ 우리가 생각하는 포텐셜의 의미는 사실 Potential2 = Potential - Overall 에 더 가깝다. $ to$ Potential2 = Potential - Overall 인 변수를 새로 만들고 시각화 해보자. | . - Potential2 = Potential - Overall 를 계산하여 새로운 열을 추가하자. . df.eval(&#39;Potential2 = Potential - Overall&#39;) . ID Name Age Photo Nationality Flag Overall Potential Club Club Logo ... Position Joined Loaned From Contract Valid Until Height Weight Release Clause Kit Number Best Overall Rating Potential2 . 0 209658 | L. Goretzka | 27 | https://cdn.sofifa.net/players/209/658/23_60.png | Germany | https://cdn.sofifa.net/flags/de.png | 87 | 88 | FC Bayern München | https://cdn.sofifa.net/teams/21/30.png | ... | &lt;span class=&quot;pos pos28&quot;&gt;SUB | Jul 1, 2018 | NaN | 2026 | 189cm | 82kg | €157M | 8.0 | NaN | 1 | . 1 212198 | Bruno Fernandes | 27 | https://cdn.sofifa.net/players/212/198/23_60.png | Portugal | https://cdn.sofifa.net/flags/pt.png | 86 | 87 | Manchester United | https://cdn.sofifa.net/teams/11/30.png | ... | &lt;span class=&quot;pos pos15&quot;&gt;LCM | Jan 30, 2020 | NaN | 2026 | 179cm | 69kg | €155M | 8.0 | NaN | 1 | . 2 224334 | M. Acuña | 30 | https://cdn.sofifa.net/players/224/334/23_60.png | Argentina | https://cdn.sofifa.net/flags/ar.png | 85 | 85 | Sevilla FC | https://cdn.sofifa.net/teams/481/30.png | ... | &lt;span class=&quot;pos pos7&quot;&gt;LB | Sep 14, 2020 | NaN | 2024 | 172cm | 69kg | €97.7M | 19.0 | NaN | 0 | . 3 192985 | K. De Bruyne | 31 | https://cdn.sofifa.net/players/192/985/23_60.png | Belgium | https://cdn.sofifa.net/flags/be.png | 91 | 91 | Manchester City | https://cdn.sofifa.net/teams/10/30.png | ... | &lt;span class=&quot;pos pos13&quot;&gt;RCM | Aug 30, 2015 | NaN | 2025 | 181cm | 70kg | €198.9M | 17.0 | NaN | 0 | . 4 224232 | N. Barella | 25 | https://cdn.sofifa.net/players/224/232/23_60.png | Italy | https://cdn.sofifa.net/flags/it.png | 86 | 89 | Inter | https://cdn.sofifa.net/teams/44/30.png | ... | &lt;span class=&quot;pos pos13&quot;&gt;RCM | Sep 1, 2020 | NaN | 2026 | 172cm | 68kg | €154.4M | 23.0 | NaN | 3 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 17655 269526 | Deng Xiongtao | 19 | https://cdn.sofifa.net/players/269/526/23_60.png | China PR | https://cdn.sofifa.net/flags/cn.png | 48 | 61 | Meizhou Hakka | https://cdn.sofifa.net/teams/114628/30.png | ... | &lt;span class=&quot;pos pos29&quot;&gt;RES | Apr 11, 2022 | NaN | 2027 | 190cm | 78kg | €218K | 35.0 | NaN | 13 | . 17656 267946 | 22 Lim Jun Sub | 17 | https://cdn.sofifa.net/players/267/946/22_60.png | Korea Republic | https://cdn.sofifa.net/flags/kr.png | 48 | 64 | Jeju United FC | https://cdn.sofifa.net/teams/1478/30.png | ... | &lt;span class=&quot;pos pos29&quot;&gt;RES | Jan 1, 2022 | NaN | 2026 | 195cm | 84kg | €188K | 21.0 | NaN | 16 | . 17657 270567 | A. Demir | 25 | https://cdn.sofifa.net/players/270/567/23_60.png | Turkey | https://cdn.sofifa.net/flags/tr.png | 51 | 56 | Ümraniyespor | https://cdn.sofifa.net/teams/113796/30.png | ... | &lt;span class=&quot;pos pos29&quot;&gt;RES | Jun 6, 2021 | NaN | 2023 | 190cm | 82kg | €142K | 12.0 | NaN | 5 | . 17658 256624 | 21 S. Czajor | 18 | https://cdn.sofifa.net/players/256/624/21_60.png | Poland | https://cdn.sofifa.net/flags/pl.png | 50 | 65 | Fleetwood Town | https://cdn.sofifa.net/teams/112260/30.png | ... | &lt;span class=&quot;pos pos29&quot;&gt;RES | Jan 1, 2020 | NaN | 2021 | 187cm | 79kg | €214K | 40.0 | NaN | 15 | . 17659 256376 | 21 F. Jakobsson | 20 | https://cdn.sofifa.net/players/256/376/21_60.png | Sweden | https://cdn.sofifa.net/flags/se.png | 50 | 61 | IFK Norrköping | https://cdn.sofifa.net/teams/702/30.png | ... | &lt;span class=&quot;pos pos29&quot;&gt;RES | Jan 8, 2020 | NaN | 2021 | 186cm | 78kg | €131K | 30.0 | NaN | 11 | . 17660 rows × 30 columns . - 수정된 데이터프레임으로 다시 시각화를 하자. . ggplot(data=df.eval(&#39;Potential2 = Potential - Overall&#39;)) + geom_point(aes(x=&#39;Overall&#39;,y=&#39;Potential2&#39;),alpha=0.01) . &lt;ggplot: (8782174347973)&gt; . - 일부점들이 겹치므로 position = &#39;jitter&#39;를 사용하여 점들을 흩뿌리자. . ggplot(data=df.eval(&#39;Potential2 = Potential - Overall&#39;)) + geom_point(aes(x=&#39;Overall&#39;,y=&#39;Potential2&#39;),alpha=0.05,position=&#39;jitter&#39;) . &lt;ggplot: (8782116264077)&gt; . - 해석 . 해석1: Overall, Potential2는 음의 상관관계가 있다. | 해석2: 0근처에 데이터가 많음 $ to$ 이미 은퇴한 선수들이 아닐까? | 해석3: Overall의 값이 작을수록 Potential2의 분산이 크다. | . - 은퇴한 선수들은 제외하고 시각화하자. . ggplot(data=df.eval(&#39;Potential2 = Potential - Overall&#39;).query(&#39;Potential2 &gt; 1&#39;)) + geom_point(aes(x=&#39;Overall&#39;,y=&#39;Potential2&#39;),alpha=0.05,position=&#39;jitter&#39;) . &lt;ggplot: (8782116963665)&gt; . - Overall에 따라서 구간을 나누고 그 구간에 대응하는 boxplot을 그리자. . df.eval(&#39;Potential2 = Potential - Overall&#39;).query(&#39;Potential2 &gt; 1&#39;) .Overall.describe() . count 13644.000000 mean 61.415347 std 7.247821 min 44.000000 25% 56.000000 50% 61.000000 75% 66.000000 max 91.000000 Name: Overall, dtype: float64 . def f(x): if x&gt;66: y=&#39;66&lt;&#39; elif x&gt;61: y=&#39;61~66&#39; elif x&gt;56: y=&#39;56~61&#39; else: y=&#39;&lt;56&#39; return y . ggplot(data=df.eval(&#39;Potential2 = Potential - Overall&#39;).query(&#39;Potential2 &gt; 1&#39;) .assign(Overall_grouped= lambda df: list(map(f,df.Overall)))) + geom_boxplot(aes(x=&#39;Overall_grouped&#39;,y=&#39;Potential2&#39;,color=&#39;Overall_grouped&#39;)) . &lt;ggplot: (8782210455637)&gt; . Overall_grouped = &quot;&lt;56&quot; 에 대응하는 점들을 모두 뽑아서 mean(Overall)를 계산하고 그 값을 Overall_grouped = &quot;&lt;56&quot; 에 대응하는 박스플랏의 x축위치로 설정 . | Overall_grouped = &quot;56~61&quot; 에 대응하는 점들을 모두 뽑아서 mean(Overall)를 계산하고 그 값을 Overall_grouped = &quot;56~61&quot; 에 대응하는 박스플랏의 x축위치로 설정 . | Overall_grouped = &quot;61~66&quot; 에 대응하는 점들을 모두 뽑아서 mean(Overall)를 계산하고 그 값을 Overall_grouped = &quot;61~66&quot; 에 대응하는 박스플랏의 x축위치로 설정 . | Overall_grouped = &quot;66&lt;&quot; 에 대응하는 점들을 모두 뽑아서 mean(Overall)를 계산하고 그 값을 Overall_grouped = &quot;66&lt;&quot; 에 대응하는 박스플랏의 x축위치로 설정 . | . df.eval(&#39;Potential2 = Potential - Overall&#39;).query(&#39;Potential2 &gt; 1&#39;) .assign(Overall_grouped= lambda df: list(map(f,df.Overall))) .query(&quot;Overall_grouped == &#39;66&lt;&#39;&quot;).Overall.mean() . 71.8127687727423 . (방법1) . def g(x): if x==&#39;66&lt;&#39;: y= 71.8127687727423 elif x==&#39;61~66&#39;: y= 63.773918342474104 elif x==&#39;56~61&#39;: y= 59.155840684309005 else: y= 52.87743190661479 return y . df.eval(&#39;Potential2 = Potential - Overall&#39;).query(&#39;Potential2 &gt; 1&#39;) .assign(Overall_grouped= lambda df: list(map(f,df.Overall))) .assign(Overall_x= lambda df: list(map(g,df.Overall_grouped))) . ID Name Age Photo Nationality Flag Overall Potential Club Club Logo ... Loaned From Contract Valid Until Height Weight Release Clause Kit Number Best Overall Rating Potential2 Overall_grouped Overall_x . 4 224232 | N. Barella | 25 | https://cdn.sofifa.net/players/224/232/23_60.png | Italy | https://cdn.sofifa.net/flags/it.png | 86 | 89 | Inter | https://cdn.sofifa.net/teams/44/30.png | ... | NaN | 2026 | 172cm | 68kg | €154.4M | 23.0 | NaN | 3 | 66&lt; | 71.812769 | . 10 228251 | L. Pellegrini | 26 | https://cdn.sofifa.net/players/228/251/23_60.png | Italy | https://cdn.sofifa.net/flags/it.png | 84 | 87 | Roma | https://cdn.sofifa.net/teams/52/30.png | ... | NaN | 2026 | 186cm | 77kg | €97.6M | 7.0 | NaN | 3 | 66&lt; | 71.812769 | . 13 225193 | Merino | 26 | https://cdn.sofifa.net/players/225/193/23_60.png | Spain | https://cdn.sofifa.net/flags/es.png | 83 | 86 | Real Sociedad | https://cdn.sofifa.net/teams/457/30.png | ... | NaN | 2025 | 189cm | 83kg | €102.2M | 8.0 | NaN | 3 | 66&lt; | 71.812769 | . 17 228702 | F. de Jong | 25 | https://cdn.sofifa.net/players/228/702/23_60.png | Netherlands | https://cdn.sofifa.net/flags/nl.png | 87 | 92 | FC Barcelona | https://cdn.sofifa.net/teams/241/30.png | ... | NaN | 2026 | 180cm | 74kg | €247.6M | 21.0 | NaN | 5 | 66&lt; | 71.812769 | . 21 231281 | T. Alexander-Arnold | 23 | https://cdn.sofifa.net/players/231/281/23_60.png | England | https://cdn.sofifa.net/flags/gb-eng.png | 87 | 90 | Liverpool | https://cdn.sofifa.net/teams/9/30.png | ... | NaN | 2025 | 180cm | 69kg | €193.5M | 66.0 | NaN | 3 | 66&lt; | 71.812769 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 17655 269526 | Deng Xiongtao | 19 | https://cdn.sofifa.net/players/269/526/23_60.png | China PR | https://cdn.sofifa.net/flags/cn.png | 48 | 61 | Meizhou Hakka | https://cdn.sofifa.net/teams/114628/30.png | ... | NaN | 2027 | 190cm | 78kg | €218K | 35.0 | NaN | 13 | &lt;56 | 52.877432 | . 17656 267946 | 22 Lim Jun Sub | 17 | https://cdn.sofifa.net/players/267/946/22_60.png | Korea Republic | https://cdn.sofifa.net/flags/kr.png | 48 | 64 | Jeju United FC | https://cdn.sofifa.net/teams/1478/30.png | ... | NaN | 2026 | 195cm | 84kg | €188K | 21.0 | NaN | 16 | &lt;56 | 52.877432 | . 17657 270567 | A. Demir | 25 | https://cdn.sofifa.net/players/270/567/23_60.png | Turkey | https://cdn.sofifa.net/flags/tr.png | 51 | 56 | Ümraniyespor | https://cdn.sofifa.net/teams/113796/30.png | ... | NaN | 2023 | 190cm | 82kg | €142K | 12.0 | NaN | 5 | &lt;56 | 52.877432 | . 17658 256624 | 21 S. Czajor | 18 | https://cdn.sofifa.net/players/256/624/21_60.png | Poland | https://cdn.sofifa.net/flags/pl.png | 50 | 65 | Fleetwood Town | https://cdn.sofifa.net/teams/112260/30.png | ... | NaN | 2021 | 187cm | 79kg | €214K | 40.0 | NaN | 15 | &lt;56 | 52.877432 | . 17659 256376 | 21 F. Jakobsson | 20 | https://cdn.sofifa.net/players/256/376/21_60.png | Sweden | https://cdn.sofifa.net/flags/se.png | 50 | 61 | IFK Norrköping | https://cdn.sofifa.net/teams/702/30.png | ... | NaN | 2021 | 186cm | 78kg | €131K | 30.0 | NaN | 11 | &lt;56 | 52.877432 | . 13644 rows × 32 columns . df2= df.eval(&#39;Potential2 = Potential - Overall&#39;).query(&#39;Potential2 &gt; 1&#39;) .assign(Overall_grouped= lambda df: list(map(f,df.Overall))) .assign(Overall_x= lambda df: list(map(g,df.Overall_grouped))) df2 . ID Name Age Photo Nationality Flag Overall Potential Club Club Logo ... Loaned From Contract Valid Until Height Weight Release Clause Kit Number Best Overall Rating Potential2 Overall_grouped Overall_x . 4 224232 | N. Barella | 25 | https://cdn.sofifa.net/players/224/232/23_60.png | Italy | https://cdn.sofifa.net/flags/it.png | 86 | 89 | Inter | https://cdn.sofifa.net/teams/44/30.png | ... | NaN | 2026 | 172cm | 68kg | €154.4M | 23.0 | NaN | 3 | 66&lt; | 71.812769 | . 10 228251 | L. Pellegrini | 26 | https://cdn.sofifa.net/players/228/251/23_60.png | Italy | https://cdn.sofifa.net/flags/it.png | 84 | 87 | Roma | https://cdn.sofifa.net/teams/52/30.png | ... | NaN | 2026 | 186cm | 77kg | €97.6M | 7.0 | NaN | 3 | 66&lt; | 71.812769 | . 13 225193 | Merino | 26 | https://cdn.sofifa.net/players/225/193/23_60.png | Spain | https://cdn.sofifa.net/flags/es.png | 83 | 86 | Real Sociedad | https://cdn.sofifa.net/teams/457/30.png | ... | NaN | 2025 | 189cm | 83kg | €102.2M | 8.0 | NaN | 3 | 66&lt; | 71.812769 | . 17 228702 | F. de Jong | 25 | https://cdn.sofifa.net/players/228/702/23_60.png | Netherlands | https://cdn.sofifa.net/flags/nl.png | 87 | 92 | FC Barcelona | https://cdn.sofifa.net/teams/241/30.png | ... | NaN | 2026 | 180cm | 74kg | €247.6M | 21.0 | NaN | 5 | 66&lt; | 71.812769 | . 21 231281 | T. Alexander-Arnold | 23 | https://cdn.sofifa.net/players/231/281/23_60.png | England | https://cdn.sofifa.net/flags/gb-eng.png | 87 | 90 | Liverpool | https://cdn.sofifa.net/teams/9/30.png | ... | NaN | 2025 | 180cm | 69kg | €193.5M | 66.0 | NaN | 3 | 66&lt; | 71.812769 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 17655 269526 | Deng Xiongtao | 19 | https://cdn.sofifa.net/players/269/526/23_60.png | China PR | https://cdn.sofifa.net/flags/cn.png | 48 | 61 | Meizhou Hakka | https://cdn.sofifa.net/teams/114628/30.png | ... | NaN | 2027 | 190cm | 78kg | €218K | 35.0 | NaN | 13 | &lt;56 | 52.877432 | . 17656 267946 | 22 Lim Jun Sub | 17 | https://cdn.sofifa.net/players/267/946/22_60.png | Korea Republic | https://cdn.sofifa.net/flags/kr.png | 48 | 64 | Jeju United FC | https://cdn.sofifa.net/teams/1478/30.png | ... | NaN | 2026 | 195cm | 84kg | €188K | 21.0 | NaN | 16 | &lt;56 | 52.877432 | . 17657 270567 | A. Demir | 25 | https://cdn.sofifa.net/players/270/567/23_60.png | Turkey | https://cdn.sofifa.net/flags/tr.png | 51 | 56 | Ümraniyespor | https://cdn.sofifa.net/teams/113796/30.png | ... | NaN | 2023 | 190cm | 82kg | €142K | 12.0 | NaN | 5 | &lt;56 | 52.877432 | . 17658 256624 | 21 S. Czajor | 18 | https://cdn.sofifa.net/players/256/624/21_60.png | Poland | https://cdn.sofifa.net/flags/pl.png | 50 | 65 | Fleetwood Town | https://cdn.sofifa.net/teams/112260/30.png | ... | NaN | 2021 | 187cm | 79kg | €214K | 40.0 | NaN | 15 | &lt;56 | 52.877432 | . 17659 256376 | 21 F. Jakobsson | 20 | https://cdn.sofifa.net/players/256/376/21_60.png | Sweden | https://cdn.sofifa.net/flags/se.png | 50 | 61 | IFK Norrköping | https://cdn.sofifa.net/teams/702/30.png | ... | NaN | 2021 | 186cm | 78kg | €131K | 30.0 | NaN | 11 | &lt;56 | 52.877432 | . 13644 rows × 32 columns . ggplot(data=df2) +geom_point(aes(x=&#39;Overall&#39;,y=&#39;Potential2&#39;,color=&#39;Overall_grouped&#39;),position=&#39;jitter&#39;,alpha=0.05) +geom_boxplot(aes(x=&#39;Overall_x&#39;,y=&#39;Potential2&#39;,color=&#39;Overall_grouped&#39;)) . &lt;ggplot: (8782213112521)&gt; . (방법2) . _df = df.eval(&#39;Potential2 = Potential - Overall&#39;).query(&#39;Potential2 &gt; 1&#39;) .assign(Overall_grouped= lambda df: list(map(f,df.Overall))) . df3=_df.groupby(by=&quot;Overall_grouped&quot;).agg({&#39;Overall&#39;:np.mean}).reset_index() .rename(columns={&#39;Overall&#39;:&#39;Overall_x&#39;}).merge(_df) . ggplot(data=df3) +geom_point(aes(x=&#39;Overall&#39;,y=&#39;Potential2&#39;,color=&#39;Overall_grouped&#39;),position=&#39;jitter&#39;,alpha=0.05) +geom_boxplot(aes(x=&#39;Overall_x&#39;,y=&#39;Potential2&#39;,color=&#39;Overall_grouped&#39;)) . &lt;ggplot: (8782176146221)&gt; . Groupby . flights data . df=pd.read_csv(&#39;https://raw.githubusercontent.com/PacktPublishing/Pandas-Cookbook/master/data/flights.csv&#39;) df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 58492 entries, 0 to 58491 Data columns (total 14 columns): # Column Non-Null Count Dtype -- -- 0 MONTH 58492 non-null int64 1 DAY 58492 non-null int64 2 WEEKDAY 58492 non-null int64 3 AIRLINE 58492 non-null object 4 ORG_AIR 58492 non-null object 5 DEST_AIR 58492 non-null object 6 SCHED_DEP 58492 non-null int64 7 DEP_DELAY 57659 non-null float64 8 AIR_TIME 57474 non-null float64 9 DIST 58492 non-null int64 10 SCHED_ARR 58492 non-null int64 11 ARR_DELAY 57474 non-null float64 12 DIVERTED 58492 non-null int64 13 CANCELLED 58492 non-null int64 dtypes: float64(3), int64(8), object(3) memory usage: 6.2+ MB . get_groups . - groupby . 데이터프레임을 여러개의 서브데이터프레임으로 나누는 기슨 | 단독으로 쓸 이유는 별로 없다. $ to$ 그룹을 나누고 each 그룹마다 어떠한 &quot;변수&quot;에 &quot;연산&quot;을 하기 위함. | . df.groupby(by=&quot;AIRLINE&quot;) . &lt;pandas.core.groupby.generic.DataFrameGroupBy object at 0x7fcbefa7c850&gt; . 지금 이것이 항공사별로 데이터프레임이 나누어진 상태임 | . - 진짜 sub dataframe 으로 나누어져 있는지 확인 . grouped = df.groupby(by=&quot;AIRLINE&quot;) grouped.groups.keys() . dict_keys([&#39;AA&#39;, &#39;AS&#39;, &#39;B6&#39;, &#39;DL&#39;, &#39;EV&#39;, &#39;F9&#39;, &#39;HA&#39;, &#39;MQ&#39;, &#39;NK&#39;, &#39;OO&#39;, &#39;UA&#39;, &#39;US&#39;, &#39;VX&#39;, &#39;WN&#39;]) . display(grouped.get_group(&#39;AS&#39;)) . MONTH DAY WEEKDAY AIRLINE ORG_AIR DEST_AIR SCHED_DEP DEP_DELAY AIR_TIME DIST SCHED_ARR ARR_DELAY DIVERTED CANCELLED . 38 1 | 1 | 4 | AS | PHX | SEA | 1505 | -2.0 | 155.0 | 1107 | 1702 | -3.0 | 0 | 0 | . 198 1 | 2 | 5 | AS | LAX | SEA | 2110 | 5.0 | 145.0 | 954 | 2352 | 8.0 | 0 | 0 | . 241 1 | 2 | 5 | AS | LAS | PDX | 650 | -5.0 | 117.0 | 763 | 906 | -3.0 | 0 | 0 | . 277 1 | 2 | 5 | AS | ORD | ANC | 935 | -1.0 | 402.0 | 2846 | 1339 | -6.0 | 0 | 0 | . 397 1 | 3 | 6 | AS | LAS | SEA | 1300 | 48.0 | 137.0 | 867 | 1535 | 47.0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 58305 12 | 30 | 3 | AS | LAX | SEA | 1325 | -2.0 | 134.0 | 954 | 1608 | -7.0 | 0 | 0 | . 58355 12 | 31 | 4 | AS | PHX | SEA | 1200 | -5.0 | 145.0 | 1107 | 1407 | -24.0 | 0 | 0 | . 58404 12 | 31 | 4 | AS | SFO | SLC | 2110 | -2.0 | 80.0 | 599 | 2358 | -4.0 | 0 | 0 | . 58407 12 | 31 | 4 | AS | SFO | PDX | 645 | -2.0 | 81.0 | 550 | 832 | -3.0 | 0 | 0 | . 58428 12 | 31 | 4 | AS | LAX | SEA | 1420 | -8.0 | 127.0 | 954 | 1709 | -25.0 | 0 | 0 | . 768 rows × 14 columns . for key in grouped.groups.keys(): display(grouped.get_group(key)) . MONTH DAY WEEKDAY AIRLINE ORG_AIR DEST_AIR SCHED_DEP DEP_DELAY AIR_TIME DIST SCHED_ARR ARR_DELAY DIVERTED CANCELLED . 3 1 | 1 | 4 | AA | DFW | DCA | 1555 | 7.0 | 126.0 | 1192 | 1935 | -7.0 | 0 | 0 | . 6 1 | 1 | 4 | AA | DFW | MSY | 1250 | 84.0 | 64.0 | 447 | 1410 | 83.0 | 0 | 0 | . 8 1 | 1 | 4 | AA | ORD | STL | 1845 | -5.0 | 44.0 | 258 | 1950 | -5.0 | 0 | 0 | . 15 1 | 1 | 4 | AA | DEN | DFW | 1445 | -6.0 | 93.0 | 641 | 1745 | 4.0 | 0 | 0 | . 26 1 | 1 | 4 | AA | LAX | AUS | 1430 | 33.0 | 157.0 | 1242 | 1925 | 41.0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 58470 12 | 31 | 4 | AA | DFW | FAT | 1020 | -3.0 | 196.0 | 1313 | 1156 | -2.0 | 0 | 0 | . 58475 12 | 31 | 4 | AA | IAH | CLT | 710 | 1.0 | 113.0 | 912 | 1037 | -12.0 | 0 | 0 | . 58476 12 | 31 | 4 | AA | DFW | TPA | 1020 | -3.0 | 121.0 | 929 | 1340 | -6.0 | 0 | 0 | . 58479 12 | 31 | 4 | AA | DFW | ELP | 1200 | 3.0 | 94.0 | 551 | 1250 | 13.0 | 0 | 0 | . 58487 12 | 31 | 4 | AA | SFO | DFW | 515 | 5.0 | 166.0 | 1464 | 1045 | -19.0 | 0 | 0 | . 8900 rows × 14 columns . MONTH DAY WEEKDAY AIRLINE ORG_AIR DEST_AIR SCHED_DEP DEP_DELAY AIR_TIME DIST SCHED_ARR ARR_DELAY DIVERTED CANCELLED . 38 1 | 1 | 4 | AS | PHX | SEA | 1505 | -2.0 | 155.0 | 1107 | 1702 | -3.0 | 0 | 0 | . 198 1 | 2 | 5 | AS | LAX | SEA | 2110 | 5.0 | 145.0 | 954 | 2352 | 8.0 | 0 | 0 | . 241 1 | 2 | 5 | AS | LAS | PDX | 650 | -5.0 | 117.0 | 763 | 906 | -3.0 | 0 | 0 | . 277 1 | 2 | 5 | AS | ORD | ANC | 935 | -1.0 | 402.0 | 2846 | 1339 | -6.0 | 0 | 0 | . 397 1 | 3 | 6 | AS | LAS | SEA | 1300 | 48.0 | 137.0 | 867 | 1535 | 47.0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 58305 12 | 30 | 3 | AS | LAX | SEA | 1325 | -2.0 | 134.0 | 954 | 1608 | -7.0 | 0 | 0 | . 58355 12 | 31 | 4 | AS | PHX | SEA | 1200 | -5.0 | 145.0 | 1107 | 1407 | -24.0 | 0 | 0 | . 58404 12 | 31 | 4 | AS | SFO | SLC | 2110 | -2.0 | 80.0 | 599 | 2358 | -4.0 | 0 | 0 | . 58407 12 | 31 | 4 | AS | SFO | PDX | 645 | -2.0 | 81.0 | 550 | 832 | -3.0 | 0 | 0 | . 58428 12 | 31 | 4 | AS | LAX | SEA | 1420 | -8.0 | 127.0 | 954 | 1709 | -25.0 | 0 | 0 | . 768 rows × 14 columns . MONTH DAY WEEKDAY AIRLINE ORG_AIR DEST_AIR SCHED_DEP DEP_DELAY AIR_TIME DIST SCHED_ARR ARR_DELAY DIVERTED CANCELLED . 123 1 | 1 | 4 | B6 | LAS | BOS | 1230 | 0.0 | 246.0 | 2381 | 2026 | -27.0 | 0 | 0 | . 127 1 | 1 | 4 | B6 | LAS | BOS | 2359 | 68.0 | 247.0 | 2381 | 749 | 46.0 | 0 | 0 | . 239 1 | 2 | 5 | B6 | ORD | BOS | 540 | -8.0 | 96.0 | 867 | 856 | -22.0 | 0 | 0 | . 333 1 | 3 | 6 | B6 | LAX | FLL | 2237 | 32.0 | 270.0 | 2342 | 619 | 42.0 | 0 | 0 | . 548 1 | 4 | 7 | B6 | SFO | FLL | 2307 | -4.0 | 298.0 | 2583 | 724 | -1.0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 58262 12 | 30 | 3 | B6 | SFO | LGB | 1921 | -6.0 | 57.0 | 354 | 2038 | -14.0 | 0 | 0 | . 58301 12 | 30 | 3 | B6 | LAX | JFK | 630 | 4.0 | 285.0 | 2475 | 1445 | -6.0 | 0 | 0 | . 58425 12 | 31 | 4 | B6 | ORD | SJU | 700 | 239.0 | 250.0 | 2072 | 1335 | 239.0 | 0 | 0 | . 58477 12 | 31 | 4 | B6 | DFW | BOS | 1145 | 12.0 | 161.0 | 1562 | 1608 | -14.0 | 0 | 0 | . 58483 12 | 31 | 4 | B6 | PHX | BOS | 2236 | -12.0 | 231.0 | 2300 | 515 | -45.0 | 0 | 0 | . 543 rows × 14 columns . MONTH DAY WEEKDAY AIRLINE ORG_AIR DEST_AIR SCHED_DEP DEP_DELAY AIR_TIME DIST SCHED_ARR ARR_DELAY DIVERTED CANCELLED . 53 1 | 1 | 4 | DL | LAS | MSP | 713 | -5.0 | 156.0 | 1299 | 1220 | -18.0 | 0 | 0 | . 57 1 | 1 | 4 | DL | MSP | RSW | 700 | -1.0 | 169.0 | 1416 | 1130 | -20.0 | 0 | 0 | . 77 1 | 1 | 4 | DL | LAX | ATL | 1130 | 24.0 | 217.0 | 1947 | 1840 | 16.0 | 0 | 0 | . 79 1 | 1 | 4 | DL | LAX | CMH | 2146 | -3.0 | 223.0 | 1995 | 459 | -13.0 | 0 | 0 | . 85 1 | 1 | 4 | DL | ATL | OKC | 2059 | -4.0 | 116.0 | 761 | 2227 | -12.0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 58440 12 | 31 | 4 | DL | ATL | CVG | 1611 | -4.0 | 61.0 | 373 | 1736 | -6.0 | 0 | 0 | . 58448 12 | 31 | 4 | DL | ATL | SRQ | 1610 | 0.0 | 61.0 | 444 | 1740 | -13.0 | 0 | 0 | . 58464 12 | 31 | 4 | DL | LAX | SFO | 700 | 108.0 | 54.0 | 337 | 825 | 105.0 | 0 | 0 | . 58467 12 | 31 | 4 | DL | ATL | IND | 1235 | -3.0 | 63.0 | 432 | 1407 | -13.0 | 0 | 0 | . 58485 12 | 31 | 4 | DL | ATL | CMH | 2206 | 2.0 | 64.0 | 447 | 2338 | -8.0 | 0 | 0 | . 10601 rows × 14 columns . MONTH DAY WEEKDAY AIRLINE ORG_AIR DEST_AIR SCHED_DEP DEP_DELAY AIR_TIME DIST SCHED_ARR ARR_DELAY DIVERTED CANCELLED . 11 1 | 1 | 4 | EV | ORD | JAN | 1155 | 6.0 | 113.0 | 677 | 1403 | 5.0 | 0 | 0 | . 13 1 | 1 | 4 | EV | ORD | CMH | 1010 | -2.0 | 46.0 | 296 | 1228 | -9.0 | 0 | 0 | . 29 1 | 1 | 4 | EV | ORD | IND | 1025 | -6.0 | 29.0 | 177 | 1228 | -19.0 | 0 | 0 | . 40 1 | 1 | 4 | EV | IAH | CLE | 1038 | -3.0 | 126.0 | 1091 | 1425 | -18.0 | 0 | 0 | . 69 1 | 1 | 4 | EV | ATL | RAP | 1930 | -5.0 | 181.0 | 1230 | 2104 | -15.0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 58445 12 | 31 | 4 | EV | DFW | TXK | 850 | -5.0 | 30.0 | 181 | 948 | -17.0 | 0 | 0 | . 58452 12 | 31 | 4 | EV | DFW | SHV | 1650 | -4.0 | 32.0 | 190 | 1746 | -12.0 | 0 | 0 | . 58459 12 | 31 | 4 | EV | MSP | ORD | 1435 | 18.0 | 61.0 | 334 | 1609 | 3.0 | 0 | 0 | . 58463 12 | 31 | 4 | EV | ORD | MSN | 1220 | 18.0 | 32.0 | 108 | 1319 | 27.0 | 0 | 0 | . 58486 12 | 31 | 4 | EV | DFW | LFT | 850 | 21.0 | 52.0 | 351 | 1012 | 14.0 | 0 | 0 | . 5858 rows × 14 columns . MONTH DAY WEEKDAY AIRLINE ORG_AIR DEST_AIR SCHED_DEP DEP_DELAY AIR_TIME DIST SCHED_ARR ARR_DELAY DIVERTED CANCELLED . 7 1 | 1 | 4 | F9 | SFO | PHX | 1020 | -7.0 | 91.0 | 651 | 1315 | -6.0 | 0 | 0 | . 93 1 | 1 | 4 | F9 | ATL | DEN | 859 | 16.0 | 181.0 | 1199 | 1026 | 10.0 | 0 | 0 | . 209 1 | 2 | 5 | F9 | MSP | DEN | 1025 | -6.0 | 97.0 | 680 | 1134 | -13.0 | 0 | 0 | . 232 1 | 2 | 5 | F9 | DEN | PHX | 2040 | -7.0 | 83.0 | 602 | 2228 | -18.0 | 0 | 0 | . 247 1 | 2 | 5 | F9 | ORD | ATL | 730 | 10.0 | 86.0 | 606 | 1020 | 23.0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 58288 12 | 30 | 3 | F9 | DEN | ORD | 625 | -4.0 | 136.0 | 888 | 1000 | 14.0 | 0 | 0 | . 58331 12 | 30 | 3 | F9 | ORD | PHX | 825 | 18.0 | 207.0 | 1440 | 1127 | 14.0 | 0 | 0 | . 58447 12 | 31 | 4 | F9 | DEN | LAS | 1245 | 13.0 | 94.0 | 628 | 1340 | 13.0 | 0 | 0 | . 58449 12 | 31 | 4 | F9 | DEN | MCO | 645 | 11.0 | 169.0 | 1546 | 1224 | -11.0 | 0 | 0 | . 58488 12 | 31 | 4 | F9 | LAS | SFO | 1910 | 13.0 | 71.0 | 414 | 2050 | 4.0 | 0 | 0 | . 1317 rows × 14 columns . MONTH DAY WEEKDAY AIRLINE ORG_AIR DEST_AIR SCHED_DEP DEP_DELAY AIR_TIME DIST SCHED_ARR ARR_DELAY DIVERTED CANCELLED . 582 1 | 4 | 7 | HA | LAX | OGG | 1115 | -11.0 | 310.0 | 2486 | 1500 | -27.0 | 0 | 0 | . 712 1 | 5 | 1 | HA | LAS | HNL | 900 | -5.0 | 357.0 | 2762 | 1315 | 5.0 | 0 | 0 | . 878 1 | 6 | 2 | HA | PHX | HNL | 800 | 1.0 | 374.0 | 2917 | 1140 | 3.0 | 0 | 0 | . 1053 1 | 7 | 3 | HA | LAX | HNL | 1705 | 0.0 | 332.0 | 2556 | 2055 | -2.0 | 0 | 0 | . 1269 1 | 8 | 4 | HA | LAX | HNL | 1000 | -1.0 | 335.0 | 2556 | 1350 | 0.0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 55883 12 | 16 | 3 | HA | LAX | HNL | 835 | 1.0 | 314.0 | 2556 | 1235 | -18.0 | 0 | 0 | . 56174 12 | 18 | 5 | HA | LAX | HNL | 835 | -5.0 | 342.0 | 2556 | 1235 | -4.0 | 0 | 0 | . 56350 12 | 19 | 6 | HA | PHX | HNL | 800 | -5.0 | 363.0 | 2917 | 1155 | -34.0 | 0 | 0 | . 56816 12 | 21 | 1 | HA | LAX | LIH | 740 | 20.0 | 303.0 | 2615 | 1145 | -11.0 | 0 | 0 | . 58391 12 | 31 | 4 | HA | LAX | HNL | 1000 | 0.0 | 324.0 | 2556 | 1350 | -9.0 | 0 | 0 | . 112 rows × 14 columns . MONTH DAY WEEKDAY AIRLINE ORG_AIR DEST_AIR SCHED_DEP DEP_DELAY AIR_TIME DIST SCHED_ARR ARR_DELAY DIVERTED CANCELLED . 2 1 | 1 | 4 | MQ | DFW | VPS | 1305 | 36.0 | 85.0 | 641 | 1453 | 35.0 | 0 | 0 | . 10 1 | 1 | 4 | MQ | DFW | DRO | 1335 | 28.0 | 104.0 | 674 | 1438 | 28.0 | 0 | 0 | . 18 1 | 1 | 4 | MQ | ORD | DAY | 2220 | 19.0 | 37.0 | 240 | 23 | 20.0 | 0 | 0 | . 24 1 | 1 | 4 | MQ | DFW | BTR | 730 | NaN | NaN | 383 | 853 | NaN | 0 | 1 | . 50 1 | 1 | 4 | MQ | ORD | CID | 1135 | -7.0 | 37.0 | 196 | 1238 | -15.0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 58415 12 | 31 | 4 | MQ | ORD | FWA | 845 | -2.0 | 37.0 | 157 | 1045 | -4.0 | 0 | 0 | . 58426 12 | 31 | 4 | MQ | DFW | FAR | 1154 | 4.0 | 124.0 | 968 | 1437 | -13.0 | 0 | 0 | . 58468 12 | 31 | 4 | MQ | DFW | OKC | 1720 | -3.0 | 31.0 | 175 | 1819 | -10.0 | 0 | 0 | . 58474 12 | 31 | 4 | MQ | ORD | FNT | 829 | 4.0 | 40.0 | 223 | 1034 | -4.0 | 0 | 0 | . 58484 12 | 31 | 4 | MQ | ORD | DSM | 1333 | 1.0 | 57.0 | 299 | 1455 | -7.0 | 0 | 0 | . 3471 rows × 14 columns . MONTH DAY WEEKDAY AIRLINE ORG_AIR DEST_AIR SCHED_DEP DEP_DELAY AIR_TIME DIST SCHED_ARR ARR_DELAY DIVERTED CANCELLED . 17 1 | 1 | 4 | NK | DEN | DTW | 1952 | 37.0 | 124.0 | 1123 | 31 | 54.0 | 0 | 0 | . 74 1 | 1 | 4 | NK | PHX | DFW | 159 | -1.0 | 103.0 | 868 | 502 | 1.0 | 0 | 0 | . 95 1 | 1 | 4 | NK | LAS | OAK | 1115 | 22.0 | 62.0 | 407 | 1246 | 10.0 | 0 | 0 | . 109 1 | 1 | 4 | NK | MSP | ORD | 616 | 2.0 | 49.0 | 334 | 745 | -19.0 | 0 | 0 | . 166 1 | 2 | 5 | NK | LAS | PDX | 1535 | -8.0 | 123.0 | 763 | 1754 | -4.0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 58160 12 | 29 | 2 | NK | MSP | MCO | 740 | 0.0 | 171.0 | 1310 | 1158 | 33.0 | 0 | 0 | . 58197 12 | 30 | 3 | NK | IAH | ORD | 755 | -8.0 | 136.0 | 925 | 1030 | -2.0 | 0 | 0 | . 58437 12 | 31 | 4 | NK | ORD | DFW | 1952 | 15.0 | 135.0 | 802 | 2225 | 23.0 | 0 | 0 | . 58461 12 | 31 | 4 | NK | ORD | LGA | 1801 | -5.0 | 84.0 | 733 | 2109 | -26.0 | 0 | 0 | . 58469 12 | 31 | 4 | NK | LAS | MSY | 1950 | 124.0 | 163.0 | 1500 | 112 | 101.0 | 0 | 0 | . 1516 rows × 14 columns . MONTH DAY WEEKDAY AIRLINE ORG_AIR DEST_AIR SCHED_DEP DEP_DELAY AIR_TIME DIST SCHED_ARR ARR_DELAY DIVERTED CANCELLED . 12 1 | 1 | 4 | OO | ORD | MSP | 1510 | 2.0 | 65.0 | 334 | 1646 | 4.0 | 0 | 0 | . 16 1 | 1 | 4 | OO | DEN | SGU | 1105 | 21.0 | 66.0 | 517 | 1249 | 20.0 | 0 | 0 | . 22 1 | 1 | 4 | OO | LAS | LAX | 1544 | -4.0 | 39.0 | 236 | 1655 | -12.0 | 0 | 0 | . 25 1 | 1 | 4 | OO | ORD | SPI | 2110 | -4.0 | 31.0 | 174 | 2205 | 5.0 | 0 | 0 | . 27 1 | 1 | 4 | OO | IAH | JAC | 1104 | -1.0 | 161.0 | 1265 | 1316 | -1.0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 58451 12 | 31 | 4 | OO | ATL | FWA | 1905 | -3.0 | 72.0 | 508 | 2051 | -14.0 | 0 | 0 | . 58480 12 | 31 | 4 | OO | MSP | BIS | 1310 | -2.0 | 65.0 | 386 | 1449 | -9.0 | 0 | 0 | . 58482 12 | 31 | 4 | OO | DEN | CPR | 1850 | -2.0 | 38.0 | 230 | 1956 | 1.0 | 0 | 0 | . 58489 12 | 31 | 4 | OO | SFO | SBA | 1846 | -6.0 | 46.0 | 262 | 1956 | -5.0 | 0 | 0 | . 58491 12 | 31 | 4 | OO | SFO | BOI | 859 | 5.0 | 73.0 | 522 | 1146 | -1.0 | 0 | 0 | . 6588 rows × 14 columns . MONTH DAY WEEKDAY AIRLINE ORG_AIR DEST_AIR SCHED_DEP DEP_DELAY AIR_TIME DIST SCHED_ARR ARR_DELAY DIVERTED CANCELLED . 1 1 | 1 | 4 | UA | DEN | IAD | 823 | 7.0 | 154.0 | 1452 | 1333 | -13.0 | 0 | 0 | . 5 1 | 1 | 4 | UA | IAH | SAN | 1450 | 1.0 | 178.0 | 1303 | 1620 | -14.0 | 0 | 0 | . 9 1 | 1 | 4 | UA | IAH | SJC | 925 | 3.0 | 215.0 | 1608 | 1136 | -14.0 | 0 | 0 | . 14 1 | 1 | 4 | UA | IAH | IND | 1426 | -1.0 | 102.0 | 844 | 1742 | -20.0 | 0 | 0 | . 21 1 | 1 | 4 | UA | ORD | CLE | 2102 | 48.0 | 47.0 | 315 | 2320 | 41.0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 58422 12 | 31 | 4 | UA | DEN | SAN | 1535 | 0.0 | 124.0 | 853 | 1704 | -13.0 | 0 | 0 | . 58432 12 | 31 | 4 | UA | ORD | SAN | 1915 | 7.0 | 238.0 | 1723 | 2143 | -3.0 | 0 | 0 | . 58457 12 | 31 | 4 | UA | ORD | LAX | 659 | -1.0 | 241.0 | 1744 | 946 | 0.0 | 0 | 0 | . 58460 12 | 31 | 4 | UA | SFO | PHL | 2235 | -6.0 | 265.0 | 2521 | 700 | -42.0 | 0 | 0 | . 58481 12 | 31 | 4 | UA | IAH | LAX | 1433 | 1.0 | 197.0 | 1379 | 1625 | -13.0 | 0 | 0 | . 7792 rows × 14 columns . MONTH DAY WEEKDAY AIRLINE ORG_AIR DEST_AIR SCHED_DEP DEP_DELAY AIR_TIME DIST SCHED_ARR ARR_DELAY DIVERTED CANCELLED . 31 1 | 1 | 4 | US | PHX | DEN | 1810 | 29.0 | 94.0 | 602 | 1954 | 49.0 | 0 | 0 | . 35 1 | 1 | 4 | US | ORD | PHL | 1600 | -2.0 | 80.0 | 678 | 1857 | -9.0 | 0 | 0 | . 49 1 | 1 | 4 | US | IAH | PHX | 1445 | -1.0 | 147.0 | 1009 | 1638 | -7.0 | 0 | 0 | . 96 1 | 1 | 4 | US | ATL | PHL | 1445 | -4.0 | 90.0 | 666 | 1644 | -11.0 | 0 | 0 | . 104 1 | 1 | 4 | US | MSP | PHX | 730 | -3.0 | 174.0 | 1276 | 1010 | -20.0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 31514 6 | 30 | 2 | US | DEN | PHL | 705 | -4.0 | 188.0 | 1558 | 1240 | 1.0 | 0 | 0 | . 31523 6 | 30 | 2 | US | PHX | DEN | 1451 | 6.0 | 85.0 | 602 | 1738 | 7.0 | 0 | 0 | . 31535 6 | 30 | 2 | US | PHX | AUS | 840 | -3.0 | 116.0 | 872 | 1304 | -11.0 | 0 | 0 | . 31561 6 | 30 | 2 | US | ORD | PHX | 710 | -5.0 | 170.0 | 1440 | 901 | -50.0 | 0 | 0 | . 31582 6 | 30 | 2 | US | PHX | OGG | 800 | -4.0 | 356.0 | 2845 | 1127 | -13.0 | 0 | 0 | . 1615 rows × 14 columns . MONTH DAY WEEKDAY AIRLINE ORG_AIR DEST_AIR SCHED_DEP DEP_DELAY AIR_TIME DIST SCHED_ARR ARR_DELAY DIVERTED CANCELLED . 56 1 | 1 | 4 | VX | LAS | SFO | 900 | 23.0 | 65.0 | 414 | 1035 | 11.0 | 0 | 0 | . 227 1 | 2 | 5 | VX | SFO | LAS | 1220 | -5.0 | 68.0 | 414 | 1350 | -5.0 | 0 | 0 | . 243 1 | 2 | 5 | VX | SFO | SEA | 700 | -4.0 | 104.0 | 679 | 905 | -1.0 | 0 | 0 | . 417 1 | 3 | 6 | VX | SFO | LAS | 900 | -2.0 | 62.0 | 414 | 1030 | -11.0 | 0 | 0 | . 432 1 | 3 | 6 | VX | SFO | SEA | 2035 | -2.0 | 106.0 | 679 | 2240 | -2.0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 58332 12 | 30 | 3 | VX | SFO | LAS | 1950 | -3.0 | 58.0 | 414 | 2120 | -4.0 | 0 | 0 | . 58383 12 | 31 | 4 | VX | SFO | PSP | 1630 | -7.0 | 65.0 | 421 | 1755 | -12.0 | 0 | 0 | . 58400 12 | 31 | 4 | VX | SFO | LAX | 1125 | -4.0 | 54.0 | 337 | 1245 | -10.0 | 0 | 0 | . 58471 12 | 31 | 4 | VX | SFO | LAX | 700 | 6.0 | 51.0 | 337 | 820 | 3.0 | 0 | 0 | . 58478 12 | 31 | 4 | VX | SFO | LAX | 1530 | 29.0 | 52.0 | 337 | 1650 | 22.0 | 0 | 0 | . 993 rows × 14 columns . MONTH DAY WEEKDAY AIRLINE ORG_AIR DEST_AIR SCHED_DEP DEP_DELAY AIR_TIME DIST SCHED_ARR ARR_DELAY DIVERTED CANCELLED . 0 1 | 1 | 4 | WN | LAX | SLC | 1625 | 58.0 | 94.0 | 590 | 1905 | 65.0 | 0 | 0 | . 4 1 | 1 | 4 | WN | LAX | MCI | 1720 | 48.0 | 166.0 | 1363 | 2225 | 39.0 | 0 | 0 | . 19 1 | 1 | 4 | WN | PHX | LAX | 1640 | 51.0 | 58.0 | 370 | 1700 | 59.0 | 0 | 0 | . 20 1 | 1 | 4 | WN | ATL | BWI | 1115 | 1.0 | 76.0 | 577 | 1305 | -15.0 | 0 | 0 | . 23 1 | 1 | 4 | WN | ATL | HOU | 1555 | 30.0 | 113.0 | 696 | 1720 | 18.0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 58455 12 | 31 | 4 | WN | LAX | SMF | 1420 | -2.0 | 64.0 | 373 | 1540 | -7.0 | 0 | 0 | . 58458 12 | 31 | 4 | WN | LAS | SFO | 1825 | 25.0 | 67.0 | 414 | 1955 | 17.0 | 0 | 0 | . 58472 12 | 31 | 4 | WN | PHX | HOU | 845 | 5.0 | 119.0 | 1020 | 1210 | 7.0 | 0 | 0 | . 58473 12 | 31 | 4 | WN | DEN | PDX | 1205 | 4.0 | 130.0 | 991 | 1400 | -13.0 | 0 | 0 | . 58490 12 | 31 | 4 | WN | MSP | ATL | 525 | 39.0 | 124.0 | 907 | 855 | 34.0 | 0 | 0 | . 8418 rows × 14 columns . &#48276;&#51452;&#54805;&#48320;&#49688;&#47484; &#44592;&#51456;&#51004;&#47196; groupby -&gt; agg . # EX1: [AIRLINE] $ to$ {ARR_DELAY:mean} . - 방법1: grouby() $ to$ .agg({colname: function}) . (예시1) . df.groupby(by=&quot;AIRLINE&quot;).agg({&#39;ARR_DELAY&#39;:np.mean}) . ARR_DELAY . AIRLINE . AA 5.542661 | . AS -0.833333 | . B6 8.692593 | . DL 0.339691 | . EV 7.034580 | . F9 13.630651 | . HA 4.972973 | . MQ 6.860591 | . NK 18.436070 | . OO 7.593463 | . UA 7.765755 | . US 1.681105 | . VX 5.348884 | . WN 6.397353 | . (예시2) . df.groupby(by=&quot;AIRLINE&quot;).agg({&#39;ARR_DELAY&#39;:&#39;mean&#39;}) . ARR_DELAY . AIRLINE . AA 5.542661 | . AS -0.833333 | . B6 8.692593 | . DL 0.339691 | . EV 7.034580 | . F9 13.630651 | . HA 4.972973 | . MQ 6.860591 | . NK 18.436070 | . OO 7.593463 | . UA 7.765755 | . US 1.681105 | . VX 5.348884 | . WN 6.397353 | . - 방법2: grouby() $ to$ key로 column선택 $ to$ .agg(f) or .f() . (예시1) . df.groupby(by=&#39;AIRLINE&#39;)[&#39;ARR_DELAY&#39;].agg(np.mean) . AIRLINE AA 5.542661 AS -0.833333 B6 8.692593 DL 0.339691 EV 7.034580 F9 13.630651 HA 4.972973 MQ 6.860591 NK 18.436070 OO 7.593463 UA 7.765755 US 1.681105 VX 5.348884 WN 6.397353 Name: ARR_DELAY, dtype: float64 . (예시2) . df.groupby(by=&#39;AIRLINE&#39;)[&#39;ARR_DELAY&#39;].agg(&quot;mean&quot;) . AIRLINE AA 5.542661 AS -0.833333 B6 8.692593 DL 0.339691 EV 7.034580 F9 13.630651 HA 4.972973 MQ 6.860591 NK 18.436070 OO 7.593463 UA 7.765755 US 1.681105 VX 5.348884 WN 6.397353 Name: ARR_DELAY, dtype: float64 . (예시3) . df.groupby(by=&#39;AIRLINE&#39;)[&#39;ARR_DELAY&#39;].mean() . AIRLINE AA 5.542661 AS -0.833333 B6 8.692593 DL 0.339691 EV 7.034580 F9 13.630651 HA 4.972973 MQ 6.860591 NK 18.436070 OO 7.593463 UA 7.765755 US 1.681105 VX 5.348884 WN 6.397353 Name: ARR_DELAY, dtype: float64 . # EX2: [AIRLINE,WEEKDAY] $ to$ {CANCELLED:sum} . - 방법1 . (예시1) . df.groupby(by=[&quot;AIRLINE&quot;,&quot;WEEKDAY&quot;]).agg({&quot;CANCELLED&quot;:np.sum}) . CANCELLED . AIRLINE WEEKDAY . AA 1 41 | . 2 9 | . 3 16 | . 4 20 | . 5 18 | . ... ... ... | . WN 3 18 | . 4 10 | . 5 7 | . 6 10 | . 7 7 | . 98 rows × 1 columns . (예시2) . df.groupby(by=[&quot;AIRLINE&quot;,&quot;WEEKDAY&quot;]).agg({&quot;CANCELLED&quot;:&quot;sum&quot;}) . CANCELLED . AIRLINE WEEKDAY . AA 1 41 | . 2 9 | . 3 16 | . 4 20 | . 5 18 | . ... ... ... | . WN 3 18 | . 4 10 | . 5 7 | . 6 10 | . 7 7 | . 98 rows × 1 columns . - 방법2 . (예시1) . df.groupby(by=[&quot;AIRLINE&quot;,&quot;WEEKDAY&quot;])[[&quot;CANCELLED&quot;]].agg(np.sum) . CANCELLED . AIRLINE WEEKDAY . AA 1 41 | . 2 9 | . 3 16 | . 4 20 | . 5 18 | . ... ... ... | . WN 3 18 | . 4 10 | . 5 7 | . 6 10 | . 7 7 | . 98 rows × 1 columns . (예시2) . df.groupby(by=[&quot;AIRLINE&quot;,&quot;WEEKDAY&quot;])[&quot;CANCELLED&quot;].agg(&quot;sum&quot;) . AIRLINE WEEKDAY AA 1 41 2 9 3 16 4 20 5 18 .. WN 3 18 4 10 5 7 6 10 7 7 Name: CANCELLED, Length: 98, dtype: int64 . (예시3) . df.groupby(by=[&quot;AIRLINE&quot;,&quot;WEEKDAY&quot;])[&quot;CANCELLED&quot;].sum() . AIRLINE WEEKDAY AA 1 41 2 9 3 16 4 20 5 18 .. WN 3 18 4 10 5 7 6 10 7 7 Name: CANCELLED, Length: 98, dtype: int64 . df.DIVERTED . 0 0 1 0 2 0 3 0 4 0 .. 58487 0 58488 0 58489 0 58490 0 58491 0 Name: DIVERTED, Length: 58492, dtype: int64 . # EX3: [AIRLINE,WEEKDAY] $ to$ {CANCELLED:sum,mean}, {DIVERTED: sum,mean} . - 방법1 . (예시1) . df.groupby([&quot;AIRLINE&quot;,&quot;WEEKDAY&quot;]) .agg({&quot;CANCELLED&quot;:[np.sum,np.mean],&quot;DIVERTED&quot;:[np.sum,np.mean]}) . CANCELLED DIVERTED . sum mean sum mean . AIRLINE WEEKDAY . AA 1 41 | 0.032106 | 6 | 0.004699 | . 2 9 | 0.007341 | 2 | 0.001631 | . 3 16 | 0.011949 | 2 | 0.001494 | . 4 20 | 0.015004 | 5 | 0.003751 | . 5 18 | 0.014151 | 1 | 0.000786 | . ... ... ... | ... | ... | ... | . WN 3 18 | 0.014118 | 2 | 0.001569 | . 4 10 | 0.007911 | 4 | 0.003165 | . 5 7 | 0.005828 | 0 | 0.000000 | . 6 10 | 0.010132 | 3 | 0.003040 | . 7 7 | 0.006066 | 3 | 0.002600 | . 98 rows × 4 columns . (예시2) . df.groupby([&quot;AIRLINE&quot;,&quot;WEEKDAY&quot;]) .agg({&quot;CANCELLED&quot;:[&quot;sum&quot;,&quot;mean&quot;],&quot;DIVERTED&quot;:[&quot;sum&quot;,&quot;mean&quot;]}) . CANCELLED DIVERTED . sum mean sum mean . AIRLINE WEEKDAY . AA 1 41 | 0.032106 | 6 | 0.004699 | . 2 9 | 0.007341 | 2 | 0.001631 | . 3 16 | 0.011949 | 2 | 0.001494 | . 4 20 | 0.015004 | 5 | 0.003751 | . 5 18 | 0.014151 | 1 | 0.000786 | . ... ... ... | ... | ... | ... | . WN 3 18 | 0.014118 | 2 | 0.001569 | . 4 10 | 0.007911 | 4 | 0.003165 | . 5 7 | 0.005828 | 0 | 0.000000 | . 6 10 | 0.010132 | 3 | 0.003040 | . 7 7 | 0.006066 | 3 | 0.002600 | . 98 rows × 4 columns . - 방법2 . (예시1) . df.groupby([&quot;AIRLINE&quot;,&quot;WEEKDAY&quot;])[[&quot;CANCELLED&quot;,&quot;DIVERTED&quot;]] .agg([np.sum,np.mean]) . CANCELLED DIVERTED . sum mean sum mean . AIRLINE WEEKDAY . AA 1 41 | 0.032106 | 6 | 0.004699 | . 2 9 | 0.007341 | 2 | 0.001631 | . 3 16 | 0.011949 | 2 | 0.001494 | . 4 20 | 0.015004 | 5 | 0.003751 | . 5 18 | 0.014151 | 1 | 0.000786 | . ... ... ... | ... | ... | ... | . WN 3 18 | 0.014118 | 2 | 0.001569 | . 4 10 | 0.007911 | 4 | 0.003165 | . 5 7 | 0.005828 | 0 | 0.000000 | . 6 10 | 0.010132 | 3 | 0.003040 | . 7 7 | 0.006066 | 3 | 0.002600 | . 98 rows × 4 columns . (예시2) . df.groupby([&quot;AIRLINE&quot;,&quot;WEEKDAY&quot;])[[&quot;CANCELLED&quot;,&quot;DIVERTED&quot;]] .agg([&quot;sum&quot;,&quot;mean&quot;]) . CANCELLED DIVERTED . sum mean sum mean . AIRLINE WEEKDAY . AA 1 41 | 0.032106 | 6 | 0.004699 | . 2 9 | 0.007341 | 2 | 0.001631 | . 3 16 | 0.011949 | 2 | 0.001494 | . 4 20 | 0.015004 | 5 | 0.003751 | . 5 18 | 0.014151 | 1 | 0.000786 | . ... ... ... | ... | ... | ... | . WN 3 18 | 0.014118 | 2 | 0.001569 | . 4 10 | 0.007911 | 4 | 0.003165 | . 5 7 | 0.005828 | 0 | 0.000000 | . 6 10 | 0.010132 | 3 | 0.003040 | . 7 7 | 0.006066 | 3 | 0.002600 | . 98 rows × 4 columns . (예시3) -- 사용불가능 . # EX4: [AIRLINE,WEEKDAY] $ to$ {CANCELLED:sum,mean,size}, {AIR_TIME: mean,var} . - 방법1 . (예시1) . df.groupby([&quot;AIRLINE&quot;,&quot;WEEKDAY&quot;]) .agg({&#39;CANCELLED&#39;:[np.sum,np.mean,len],&#39;AIR_TIME&#39;:[np.mean,np.var]}) . CANCELLED AIR_TIME . sum mean len mean var . AIRLINE WEEKDAY . AA 1 41 | 0.032106 | 1277 | 147.610569 | 5393.806723 | . 2 9 | 0.007341 | 1226 | 143.851852 | 5359.890719 | . 3 16 | 0.011949 | 1339 | 144.514005 | 5378.854539 | . 4 20 | 0.015004 | 1333 | 141.124618 | 4791.524627 | . 5 18 | 0.014151 | 1272 | 145.430966 | 5884.592076 | . ... ... ... | ... | ... | ... | ... | . WN 3 18 | 0.014118 | 1275 | 104.219920 | 2901.873447 | . 4 10 | 0.007911 | 1264 | 107.200800 | 2966.568935 | . 5 7 | 0.005828 | 1201 | 107.893635 | 3268.717093 | . 6 10 | 0.010132 | 987 | 109.247433 | 3152.753719 | . 7 7 | 0.006066 | 1154 | 107.602273 | 3183.126889 | . 98 rows × 5 columns . (예시2) . df.groupby([&quot;AIRLINE&quot;,&quot;WEEKDAY&quot;]) .agg({&#39;CANCELLED&#39;:[&quot;sum&quot;,&quot;mean&quot;,&quot;size&quot;],&#39;AIR_TIME&#39;:[&quot;mean&quot;,&quot;var&quot;]}) . CANCELLED AIR_TIME . sum mean size mean var . AIRLINE WEEKDAY . AA 1 41 | 0.032106 | 1277 | 147.610569 | 5393.806723 | . 2 9 | 0.007341 | 1226 | 143.851852 | 5359.890719 | . 3 16 | 0.011949 | 1339 | 144.514005 | 5378.854539 | . 4 20 | 0.015004 | 1333 | 141.124618 | 4791.524627 | . 5 18 | 0.014151 | 1272 | 145.430966 | 5884.592076 | . ... ... ... | ... | ... | ... | ... | . WN 3 18 | 0.014118 | 1275 | 104.219920 | 2901.873447 | . 4 10 | 0.007911 | 1264 | 107.200800 | 2966.568935 | . 5 7 | 0.005828 | 1201 | 107.893635 | 3268.717093 | . 6 10 | 0.010132 | 987 | 109.247433 | 3152.753719 | . 7 7 | 0.006066 | 1154 | 107.602273 | 3183.126889 | . 98 rows × 5 columns . (사용자정의함수) . df.groupby([&quot;AIRLINE&quot;,&quot;WEEKDAY&quot;]) .agg({&#39;CANCELLED&#39;:[np.sum,np.mean,len], &#39;AIR_TIME&#39;:[np.mean,lambda x: np.std(x,ddof=1)**2]}) . CANCELLED AIR_TIME . sum mean len mean &lt;lambda_0&gt; . AIRLINE WEEKDAY . AA 1 41 | 0.032106 | 1277 | 147.610569 | 5393.806723 | . 2 9 | 0.007341 | 1226 | 143.851852 | 5359.890719 | . 3 16 | 0.011949 | 1339 | 144.514005 | 5378.854539 | . 4 20 | 0.015004 | 1333 | 141.124618 | 4791.524627 | . 5 18 | 0.014151 | 1272 | 145.430966 | 5884.592076 | . ... ... ... | ... | ... | ... | ... | . WN 3 18 | 0.014118 | 1275 | 104.219920 | 2901.873447 | . 4 10 | 0.007911 | 1264 | 107.200800 | 2966.568935 | . 5 7 | 0.005828 | 1201 | 107.893635 | 3268.717093 | . 6 10 | 0.010132 | 987 | 109.247433 | 3152.753719 | . 7 7 | 0.006066 | 1154 | 107.602273 | 3183.126889 | . 98 rows × 5 columns . &#50672;&#49549;&#54805;&#48320;&#49688;&#47484; &#44592;&#51456;&#51004;&#47196; groupby -&gt; agg . df.T . 0 1 2 3 4 5 6 7 8 9 ... 58482 58483 58484 58485 58486 58487 58488 58489 58490 58491 . MONTH 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | ... | 12 | 12 | 12 | 12 | 12 | 12 | 12 | 12 | 12 | 12 | . DAY 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | ... | 31 | 31 | 31 | 31 | 31 | 31 | 31 | 31 | 31 | 31 | . WEEKDAY 4 | 4 | 4 | 4 | 4 | 4 | 4 | 4 | 4 | 4 | ... | 4 | 4 | 4 | 4 | 4 | 4 | 4 | 4 | 4 | 4 | . AIRLINE WN | UA | MQ | AA | WN | UA | AA | F9 | AA | UA | ... | OO | B6 | MQ | DL | EV | AA | F9 | OO | WN | OO | . ORG_AIR LAX | DEN | DFW | DFW | LAX | IAH | DFW | SFO | ORD | IAH | ... | DEN | PHX | ORD | ATL | DFW | SFO | LAS | SFO | MSP | SFO | . DEST_AIR SLC | IAD | VPS | DCA | MCI | SAN | MSY | PHX | STL | SJC | ... | CPR | BOS | DSM | CMH | LFT | DFW | SFO | SBA | ATL | BOI | . SCHED_DEP 1625 | 823 | 1305 | 1555 | 1720 | 1450 | 1250 | 1020 | 1845 | 925 | ... | 1850 | 2236 | 1333 | 2206 | 850 | 515 | 1910 | 1846 | 525 | 859 | . DEP_DELAY 58.0 | 7.0 | 36.0 | 7.0 | 48.0 | 1.0 | 84.0 | -7.0 | -5.0 | 3.0 | ... | -2.0 | -12.0 | 1.0 | 2.0 | 21.0 | 5.0 | 13.0 | -6.0 | 39.0 | 5.0 | . AIR_TIME 94.0 | 154.0 | 85.0 | 126.0 | 166.0 | 178.0 | 64.0 | 91.0 | 44.0 | 215.0 | ... | 38.0 | 231.0 | 57.0 | 64.0 | 52.0 | 166.0 | 71.0 | 46.0 | 124.0 | 73.0 | . DIST 590 | 1452 | 641 | 1192 | 1363 | 1303 | 447 | 651 | 258 | 1608 | ... | 230 | 2300 | 299 | 447 | 351 | 1464 | 414 | 262 | 907 | 522 | . SCHED_ARR 1905 | 1333 | 1453 | 1935 | 2225 | 1620 | 1410 | 1315 | 1950 | 1136 | ... | 1956 | 515 | 1455 | 2338 | 1012 | 1045 | 2050 | 1956 | 855 | 1146 | . ARR_DELAY 65.0 | -13.0 | 35.0 | -7.0 | 39.0 | -14.0 | 83.0 | -6.0 | -5.0 | -14.0 | ... | 1.0 | -45.0 | -7.0 | -8.0 | 14.0 | -19.0 | 4.0 | -5.0 | 34.0 | -1.0 | . DIVERTED 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . CANCELLED 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 14 rows × 58492 columns . df.DIST.describe() . count 58492.000000 mean 872.900072 std 624.996805 min 67.000000 25% 391.000000 50% 690.000000 75% 1199.000000 max 4502.000000 Name: DIST, dtype: float64 . df.assign(DIST2 = pd.cut(df.DIST,[-np.inf,391,690,1199,np.inf])) .groupby([&quot;AIRLINE&quot;,&quot;DIST2&quot;]).agg({&#39;CANCELLED&#39;:[&quot;sum&quot;,&quot;mean&quot;,&quot;size&quot;]}) . CANCELLED . sum mean size . AIRLINE DIST2 . AA (-inf, 391.0] 18 | 0.015986 | 1126 | . (391.0, 690.0] 17 | 0.013589 | 1251 | . (690.0, 1199.0] 69 | 0.022066 | 3127 | . (1199.0, inf] 50 | 0.014723 | 3396 | . AS (-inf, 391.0] 0 | NaN | 0 | . (391.0, 690.0] 0 | 0.000000 | 145 | . (690.0, 1199.0] 0 | 0.000000 | 462 | . (1199.0, inf] 0 | 0.000000 | 161 | . B6 (-inf, 391.0] 0 | 0.000000 | 71 | . (391.0, 690.0] 0 | 0.000000 | 38 | . (690.0, 1199.0] 0 | 0.000000 | 61 | . (1199.0, inf] 1 | 0.002681 | 373 | . DL (-inf, 391.0] 7 | 0.003086 | 2268 | . (391.0, 690.0] 8 | 0.002421 | 3304 | . (690.0, 1199.0] 16 | 0.006405 | 2498 | . (1199.0, inf] 7 | 0.002766 | 2531 | . EV (-inf, 391.0] 77 | 0.028785 | 2675 | . (391.0, 690.0] 47 | 0.022793 | 2062 | . (690.0, 1199.0] 22 | 0.019982 | 1101 | . (1199.0, inf] 0 | 0.000000 | 20 | . F9 (-inf, 391.0] 0 | 0.000000 | 27 | . (391.0, 690.0] 6 | 0.013825 | 434 | . (690.0, 1199.0] 4 | 0.007105 | 563 | . (1199.0, inf] 0 | 0.000000 | 293 | . HA (-inf, 391.0] 0 | NaN | 0 | . (391.0, 690.0] 0 | NaN | 0 | . (690.0, 1199.0] 0 | NaN | 0 | . (1199.0, inf] 0 | 0.000000 | 112 | . MQ (-inf, 391.0] 90 | 0.047120 | 1910 | . (391.0, 690.0] 39 | 0.037356 | 1044 | . (690.0, 1199.0] 22 | 0.044266 | 497 | . (1199.0, inf] 1 | 0.050000 | 20 | . NK (-inf, 391.0] 5 | 0.036496 | 137 | . (391.0, 690.0] 4 | 0.013201 | 303 | . (690.0, 1199.0] 6 | 0.011029 | 544 | . (1199.0, inf] 10 | 0.018797 | 532 | . OO (-inf, 391.0] 75 | 0.024826 | 3021 | . (391.0, 690.0] 39 | 0.019364 | 2014 | . (690.0, 1199.0] 19 | 0.016351 | 1162 | . (1199.0, inf] 9 | 0.023018 | 391 | . UA (-inf, 391.0] 5 | 0.007143 | 700 | . (391.0, 690.0] 14 | 0.011824 | 1184 | . (690.0, 1199.0] 26 | 0.010924 | 2380 | . (1199.0, inf] 48 | 0.013605 | 3528 | . US (-inf, 391.0] 0 | 0.000000 | 254 | . (391.0, 690.0] 7 | 0.021944 | 319 | . (690.0, 1199.0] 2 | 0.006329 | 316 | . (1199.0, inf] 12 | 0.016529 | 726 | . VX (-inf, 391.0] 2 | 0.008299 | 241 | . (391.0, 690.0] 1 | 0.003861 | 259 | . (690.0, 1199.0] 0 | 0.000000 | 22 | . (1199.0, inf] 3 | 0.006369 | 471 | . WN (-inf, 391.0] 55 | 0.023810 | 2310 | . (391.0, 690.0] 14 | 0.006487 | 2158 | . (690.0, 1199.0] 17 | 0.007896 | 2153 | . (1199.0, inf] 7 | 0.003895 | 1797 | . pd.cut(df.DIST,[-np.inf,400,700,1200,np.inf],labels=[&#39;~400&#39;,&#39;400~700&#39;,&#39;700~1200&#39;,&#39;1200~&#39;]) . 0 400~700 1 1200~ 2 400~700 3 700~1200 4 1200~ ... 58487 1200~ 58488 400~700 58489 ~400 58490 700~1200 58491 400~700 Name: DIST, Length: 58492, dtype: category Categories (4, object): [&#39;~400&#39; &lt; &#39;400~700&#39; &lt; &#39;700~1200&#39; &lt; &#39;1200~&#39;] . df.assign(DIST2 = pd.cut(df.DIST,[-np.inf,400,700,1200,np.inf],labels=[&#39;~400&#39;,&#39;400~700&#39;,&#39;700~1200&#39;,&#39;1200~&#39;])) .groupby([&quot;AIRLINE&quot;,&quot;DIST2&quot;]).agg({&#39;CANCELLED&#39;:[&quot;sum&quot;,&quot;mean&quot;,&quot;size&quot;]}) . CANCELLED . sum mean size . AIRLINE DIST2 . AA ~400 18 | 0.015986 | 1126 | . 400~700 17 | 0.013589 | 1251 | . 700~1200 69 | 0.022066 | 3127 | . 1200~ 50 | 0.014723 | 3396 | . AS ~400 0 | NaN | 0 | . 400~700 0 | 0.000000 | 145 | . 700~1200 0 | 0.000000 | 462 | . 1200~ 0 | 0.000000 | 161 | . B6 ~400 0 | 0.000000 | 71 | . 400~700 0 | 0.000000 | 38 | . 700~1200 0 | 0.000000 | 61 | . 1200~ 1 | 0.002681 | 373 | . DL ~400 7 | 0.003040 | 2303 | . 400~700 8 | 0.002352 | 3402 | . 700~1200 16 | 0.006765 | 2365 | . 1200~ 7 | 0.002766 | 2531 | . EV ~400 77 | 0.027838 | 2766 | . 400~700 48 | 0.023312 | 2059 | . 700~1200 21 | 0.020731 | 1013 | . 1200~ 0 | 0.000000 | 20 | . F9 ~400 0 | 0.000000 | 27 | . 400~700 7 | 0.015837 | 442 | . 700~1200 3 | 0.005405 | 555 | . 1200~ 0 | 0.000000 | 293 | . HA ~400 0 | NaN | 0 | . 400~700 0 | NaN | 0 | . 700~1200 0 | NaN | 0 | . 1200~ 0 | 0.000000 | 112 | . MQ ~400 92 | 0.047472 | 1938 | . 400~700 39 | 0.035682 | 1093 | . 700~1200 20 | 0.047619 | 420 | . 1200~ 1 | 0.050000 | 20 | . NK ~400 5 | 0.036496 | 137 | . 400~700 4 | 0.013201 | 303 | . 700~1200 6 | 0.011029 | 544 | . 1200~ 10 | 0.018797 | 532 | . OO ~400 76 | 0.024837 | 3060 | . 400~700 38 | 0.018673 | 2035 | . 700~1200 19 | 0.017241 | 1102 | . 1200~ 9 | 0.023018 | 391 | . UA ~400 5 | 0.006993 | 715 | . 400~700 14 | 0.011966 | 1170 | . 700~1200 26 | 0.010929 | 2379 | . 1200~ 48 | 0.013605 | 3528 | . US ~400 0 | 0.000000 | 254 | . 400~700 7 | 0.021944 | 319 | . 700~1200 2 | 0.006329 | 316 | . 1200~ 12 | 0.016529 | 726 | . VX ~400 2 | 0.008299 | 241 | . 400~700 1 | 0.003861 | 259 | . 700~1200 0 | 0.000000 | 22 | . 1200~ 3 | 0.006369 | 471 | . WN ~400 55 | 0.023022 | 2389 | . 400~700 17 | 0.007795 | 2181 | . 700~1200 14 | 0.006826 | 2051 | . 1200~ 7 | 0.003895 | 1797 | .",
            "url": "https://guebin.github.io/DV2022/2022/10/24/(8%EC%A3%BC%EC%B0%A8)-10%EC%9B%9424%EC%9D%BC.html",
            "relUrl": "/2022/10/24/(8%EC%A3%BC%EC%B0%A8)-10%EC%9B%9424%EC%9D%BC.html",
            "date": " • Oct 24, 2022"
        }
        
    
  
    
        ,"post5": {
            "title": "(7주차) 10월19일",
            "content": "&#44053;&#51032;&#50689;&#49345; . . imports . import pandas as pd import numpy as np import matplotlib.pyplot as plt from plotnine import * . &#50500;&#51060;&#49828;&#53356;&#47548;&#51012; &#47566;&#51060; &#47673;&#51004;&#47732; &#44152;&#47532;&#45716; &#48337; (2) . &#51088;&#47308;&#49373;&#49457;: &#51328; &#45908; &#44536;&#47092;&#46319;&#54620; &#51088;&#47308; (&#47564;&#46308;&#44592;) . - 지난 시간의 toy example은 데이터가 너무 작아서 억지스러움 $ to$ 기상자료개방포털, 회원가입해야 자료받을 수 있음. . _df=pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/DV2022/master/_notebooks/temp.csv&#39;) _df . 지점번호 지점명 일시 평균기온(℃) 최고기온(℃) 최고기온시각 최저기온(℃) . 0 146 | 전주 | 2020-01-01 | -0.5 | 4.3 | 15:09 | -6.4 | . 1 146 | 전주 | 2020-01-02 | 1.4 | 6.5 | 14:12 | -3.0 | . 2 146 | 전주 | 2020-01-03 | 2.6 | 7.6 | 13:32 | -0.5 | . 3 146 | 전주 | 2020-01-04 | 2.0 | 7.7 | 13:51 | -2.6 | . 4 146 | 전주 | 2020-01-05 | 2.5 | 8.6 | 14:05 | -3.2 | . ... ... | ... | ... | ... | ... | ... | ... | . 651 146 | 전주 | 2021-10-13 | 19.9 | 25.5 | 14:29 | 15.6 | . 652 146 | 전주 | 2021-10-14 | 20.4 | 25.5 | 13:36 | 17.0 | . 653 146 | 전주 | 2021-10-15 | 18.3 | 22.0 | 13:47 | 15.7 | . 654 146 | 전주 | 2021-10-16 | 12.8 | 17.4 | 0:01 | 6.5 | . 655 146 | 전주 | 2021-10-17 | 6.7 | 12.4 | 15:18 | 2.2 | . 656 rows × 7 columns . - 평균기온만 선택 . pd.Series(_df.columns) . 0 지점번호 1 지점명 2 일시 3 평균기온(℃) 4 최고기온(℃) 5 최고기온시각 6 최저기온(℃) dtype: object . temp = np.array(_df.iloc[:,3]) temp[:5] . array([-0.5, 1.4, 2.6, 2. , 2.5]) . # &#49704;&#51008;&#51652;&#51676;&#49345;&#54889;1: &#50728;&#46020; $ to$ &#50500;&#51060;&#49828;&#53356;&#47548; &#54032;&#47588;&#47049; . - 아래와 같은 관계가 있다고 하자. . $$ text{아이스크림 판매량} = 20 + 2 times text{온도} + epsilon$$ . np.random.seed(1) eps = np.random.normal(size=len(temp), scale=10) icecream = 20 + 2*temp + eps . plt.plot(temp,icecream,&#39;o&#39;,alpha=0.3) plt.xlabel(&quot;temp&quot;,size=15) plt.ylabel(&quot;icecream&quot;,size=15) . Text(0, 0.5, &#39;icecream&#39;) . # &#49704;&#51008;&#51652;&#51676;&#49345;&#54889;1: &#50728;&#46020; $ to$ &#50500;&#51060;&#49828;&#53356;&#47548; &#54032;&#47588;&#47049; . - 아래와 같은 관계가 있다고 하자. . $$ text{소아마비 반응수치} = 30 + 0.5 times text{온도} + epsilon$$ . np.random.seed(2) eps=np.random.normal(size=len(temp),scale=1) disease= 30 + 0.5 * temp + eps . plt.plot(temp,disease,&#39;o&#39;,alpha=0.3) plt.xlabel(&quot;temp&quot;,size=15) plt.ylabel(&quot;disease&quot;,size=15) . Text(0, 0.5, &#39;disease&#39;) . # &#50864;&#47532;&#44032; &#44288;&#52769;&#54620; &#49345;&#54889; (&#50728;&#46020;&#45716; &#51008;&#45769;&#46104;&#50612;&#51080;&#51020;) . plt.plot(icecream,disease,&#39;o&#39;,alpha=0.3) plt.xlabel(&quot;icecream&quot;,size=15) plt.ylabel(&quot;disease&quot;,size=15) . Text(0, 0.5, &#39;disease&#39;) . np.corrcoef(icecream,disease) . array([[1. , 0.86298975], [0.86298975, 1. ]]) . 0.86정도.. | . &#51649;&#44288;: &#50668;&#47492;&#47564; &#48977;&#50500;&#49436; plot &#54644;&#48372;&#51088;. . - temp&gt;25 (여름으로 간주) 인 관측치만 플랏 . plt.plot(icecream[temp&gt;25],disease[temp&gt;25], &#39;o&#39;, color=&#39;C1&#39;) ## 평균기온이 25도가 넘어가면 여름이라 생각 . [&lt;matplotlib.lines.Line2D at 0x7fb7893325d0&gt;] . - 전체적인 산점도 . fig , ((ax1,ax2), (ax3,ax4)) = plt.subplots(2,2,figsize=(8,6)) ax1.plot(temp,icecream,&#39;o&#39;,alpha=0.2); ax1.set_xlabel(&#39;temp&#39;); ax1.set_ylabel(&#39;icecream&#39;); ax1.set_title(&quot;hidden1&quot;) ax2.plot(temp,disease,&#39;o&#39;,alpha=0.2); ax2.set_xlabel(&#39;temp&#39;); ax2.set_ylabel(&#39;disease&#39;); ax2.set_title(&quot;hidden2&quot;) ax3.plot(icecream,disease,&#39;o&#39;,alpha=0.2); ax3.set_xlabel(&#39;icecream&#39;); ax3.set_ylabel(&#39;disease&#39;); ax3.set_title(&quot;observed&quot;) ax4.plot(icecream,disease,&#39;o&#39;,alpha=0.2); ax4.set_xlabel(&#39;icecream&#39;); ax4.set_ylabel(&#39;disease&#39;); ax4.set_title(&quot;observed&quot;) ax4.plot(icecream[temp&gt;25],disease[temp&gt;25],&#39;o&#39;,label=&#39;temp&gt;25&#39;) ax4.legend() fig.tight_layout() . ggplot: &#50728;&#46020;&#44396;&#44036;&#51012; &#49464;&#48516;&#54868; &#54616;&#50668; &#49884;&#44033;&#54868; . - 목표: 모든 온도구간에 대하여 각각 색을 다르게 하여 그려보자. . 사실 지금 변수는 온도, 아이스크림판매량, 소아마비 | 온도가 유사한 지역을 색으로 묶으면 3차원 플랏이 가능함 | . # df&#47196; &#51088;&#47308;&#51221;&#47532; . - 일단 데이터 프레임을 정리하자. . df = pd.DataFrame({&#39;temp&#39;:temp,&#39;icecream&#39;:icecream,&#39;disease&#39;:disease}) df . temp icecream disease . 0 -0.5 | 35.243454 | 29.333242 | . 1 1.4 | 16.682436 | 30.643733 | . 2 2.6 | 19.918282 | 29.163804 | . 3 2.0 | 13.270314 | 32.640271 | . 4 2.5 | 33.654076 | 29.456564 | . ... ... | ... | ... | . 651 19.9 | 68.839992 | 39.633906 | . 652 20.4 | 76.554679 | 38.920443 | . 653 18.3 | 68.666079 | 39.882650 | . 654 12.8 | 42.771364 | 36.613159 | . 655 6.7 | 30.736731 | 34.902513 | . 656 rows × 3 columns . # &#44396;&#44036;&#49464;&#48516;&#54868; . - 온도를 카테고리화 하자 $ to$ 적당한 구긴을 설정하기 위해서 히스토그램을 그려보자. . df.temp.hist() # ? 이거 14주차쯤 배우는데 미리 스포합니다.. 엄청 편해요 . &lt;AxesSubplot:&gt; . plt.hist(df.temp) # 원래는 이걸 배웠죠 . (array([ 3., 9., 29., 60., 92., 86., 65., 93., 139., 80.]), array([-12.4 , -8.16, -3.92, 0.32, 4.56, 8.8 , 13.04, 17.28, 21.52, 25.76, 30. ]), &lt;BarContainer object of 10 artists&gt;) . - 구간은 5정도로 하면 적당할 것 같다. . def cut(x): # 이거보다 더 좋은 방법이 있을 것 같긴 한데요.. if x&lt;0: y=&#39;Temp: &lt;0&#39; elif x&lt;5: y=&#39;Temp: 0~5&#39; elif x&lt;10: y=&#39;Temp: 5~10&#39; elif x&lt;15: y=&#39;Temp: 10~15&#39; elif x&lt;20: y=&#39;Temp: 15~20&#39; elif x&lt;25: y=&#39;Temp: 20~25&#39; else: y=&#39;Temp: &gt;30&#39; return y . df.assign(temp2 = list(map(cut,df.temp))) . temp icecream disease temp2 . 0 -0.5 | 35.243454 | 29.333242 | Temp: &lt;0 | . 1 1.4 | 16.682436 | 30.643733 | Temp: 0~5 | . 2 2.6 | 19.918282 | 29.163804 | Temp: 0~5 | . 3 2.0 | 13.270314 | 32.640271 | Temp: 0~5 | . 4 2.5 | 33.654076 | 29.456564 | Temp: 0~5 | . ... ... | ... | ... | ... | . 651 19.9 | 68.839992 | 39.633906 | Temp: 15~20 | . 652 20.4 | 76.554679 | 38.920443 | Temp: 20~25 | . 653 18.3 | 68.666079 | 39.882650 | Temp: 15~20 | . 654 12.8 | 42.771364 | 36.613159 | Temp: 10~15 | . 655 6.7 | 30.736731 | 34.902513 | Temp: 5~10 | . 656 rows × 4 columns . # ggplot . - 온도를 색으로 구분하면 . fig = ggplot(data=df.assign(temp2 = list(map(cut,df.temp)))) p1 = geom_point(aes(x=&#39;icecream&#39;,y=&#39;disease&#39;,colour=&#39;temp2&#39;),alpha=0.5) fig + p1 . &lt;ggplot: (8776635057125)&gt; . - 추세선을 추가하면 . l1 = geom_smooth(aes(x=&#39;icecream&#39;,y=&#39;disease&#39;,colour=&#39;temp2&#39;)) . fig+p1+l1 . /home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. . &lt;ggplot: (8776635003033)&gt; . 각 온도별로 추세선은 거의 기울기가 0이다. $ to$ 온도가 비슷한 구간별로 묶어서 보니까 상관관계가 없다는 거! | 아이스크림 판매량과 소아마비의 corr은 유의미해보이지만, 온도를 통제하였을 경우 아이스크림 판매량과 소아마비의 partial corr은 유의미해보이지 않음. | . # &#54644;&#49437; . - 해피앤딩: 온도를 통제하니까 아이스크림과 질병은 관련이 없어보인다. $ to$ 아이스크림을 먹으면 소아마비를 유발한다는 이상한 결론이 나올뻔 했지만 우리는 온도라는 흑막을 잘 찾았고 결과적으로 &quot;온도-&gt;아이스크림판매량,소아마비&quot; 이라는 합리적인 진리를 얻을 수 있었다. . 온도와 같은 변수를 은닉변수라고 한다. | . - 또 다른 흑막? 고려할 흑막이 온도뿐이라는 보장이 어디있지? 사실 흑막2, 흑막3이 있어서 그런 흑막들을 고려하다보니까 아이스크림과 소아마비사이의 상관관계가 다시 보이면 어떡하지? . 이러한 이유 때문에 상관계수로 인과성을 유추하는건 사실상 불가능. | 그런데 이론적으로는 &quot;세상의 모든 은닉변수를 통제하였을 경우에도 corr(X,Y)의 값이 1에 가깝다면 그때는 인과성이 있다고 봐도 무방함, (물론 이 경우에도 무엇이 원인인지는 통계적으로 따지는것이 불가)&quot; 이라고 주장할 수 있다. 즉 모든 흑막을 제거한다면 &quot;상관성=인과성&quot;이다. | . - 실험계획법, 인과추론: 세상의 모든 흑막을 제거하는건 상식적으로 불가능 . 피셔의주장(실험계획법): 그런데 실험계획을 잘하면 흑막을 제거한 효과가 있음 (무작위로 사람뽑아서 담배를 피우게 한다든가) | 인과추론: 실험계획이 사실상 불가능한 경우가 있음 $ to$ 모인 데이터에서 최대한 흑막2,3,4,.. 등이 비슷한 그룹끼리 &quot;매칭&quot;을 시킨다! | . &#44536;&#45285; &#44417;&#44552;&#54644;&#49436;: &#51652;&#51676; &#47564;&#50557;&#50640; &#50500;&#51060;&#49828;&#53356;&#47548;&#44284; &#49548;&#50500;&#47560;&#48708;&#44032; &#44288;&#47144;&#51080;&#45716; &#44221;&#50864;&#46972;&#47732;? . - 온도는 아이스크림 판매에 여전히 영향을 주지만 . $$ text{아이스크림 판매량} = 20 + 2 times text{온도} + epsilon$$ . np.random.seed(1) eps=np.random.normal(size=len(temp), scale=10) icecream = 20 + 2 * temp + eps . - 수영장이 원인이 아니라 진짜 아이스크림을 먹고 소아마비에 걸린상황이라면? . $$ text{소아마비 반응수치} = 30 + 0 times text{온도} + 0.15 times text{아이스크림 판매량} + epsilon$$ . np.random.seed(2) eps = np.random.normal(size=len(temp),scale=2) disease= 30+ 0*temp + 0.15*icecream + eps . df2=pd.DataFrame({&#39;temp&#39;:temp,&#39;icecream&#39;:icecream,&#39;disease&#39;:disease}) df2.assign(temp2=list(map(cut,df2.temp))) . temp icecream disease temp2 . 0 -0.5 | 35.243454 | 34.453002 | Temp: &lt;0 | . 1 1.4 | 16.682436 | 32.389832 | Temp: 0~5 | . 2 2.6 | 19.918282 | 28.715350 | Temp: 0~5 | . 3 2.0 | 13.270314 | 35.271089 | Temp: 0~5 | . 4 2.5 | 33.654076 | 31.461240 | Temp: 0~5 | . ... ... | ... | ... | ... | . 651 19.9 | 68.839992 | 39.693811 | Temp: 15~20 | . 652 20.4 | 76.554679 | 38.924088 | Temp: 20~25 | . 653 18.3 | 68.666079 | 41.765212 | Temp: 15~20 | . 654 12.8 | 42.771364 | 36.842022 | Temp: 10~15 | . 655 6.7 | 30.736731 | 37.715537 | Temp: 5~10 | . 656 rows × 4 columns . ggplot(data=df2.assign(temp2=list(map(cut,df2.temp))))+ geom_point(aes(x=&#39;icecream&#39;,y=&#39;disease&#39;,colour=&#39;temp2&#39;),alpha=0.2)+ geom_smooth(aes(x=&#39;icecream&#39;,y=&#39;disease&#39;,colour=&#39;temp2&#39;)) . /home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. . &lt;ggplot: (8776634893149)&gt; . 이번엔 partial corr도 유의미하게 나옴 | . - 단순 corr을 봐서는 &quot;온도-&gt;아이스크림,소아마비&quot; 인지, &quot;온도-&gt;아이스크림-&gt;소아마비&quot; 인지 알기 어렵다. . df.corr() . temp icecream disease . temp 1.000000 | 0.884366 | 0.975609 | . icecream 0.884366 | 1.000000 | 0.862990 | . disease 0.975609 | 0.862990 | 1.000000 | . df2.corr() . temp icecream disease . temp 1.000000 | 0.884366 | 0.725505 | . icecream 0.884366 | 1.000000 | 0.830539 | . disease 0.725505 | 0.830539 | 1.000000 | . &#49689;&#51228; . - 없습니다.. .",
            "url": "https://guebin.github.io/DV2022/2022/10/19/(7%EC%A3%BC%EC%B0%A8)-10%EC%9B%9419%EC%9D%BC.html",
            "relUrl": "/2022/10/19/(7%EC%A3%BC%EC%B0%A8)-10%EC%9B%9419%EC%9D%BC.html",
            "date": " • Oct 19, 2022"
        }
        
    
  
    
        ,"post6": {
            "title": "(7주차) 10월17일",
            "content": "&#44053;&#51032;&#50689;&#49345; . . imports . import numpy as np import pandas as pd import matplotlib.pyplot as plt . df: &#51064;&#45937;&#49905; 3&#45800;&#44228;-- column&#51032; &#49440;&#53469; (with &#49892;&#51204;&#50696;&#51228;) . - 지금까지 정리 . . [] .iloc .loc . row/단일레이블 | X | X | O | O | . col/단일레이블 | O | O | O | O | . row/레이블리스트 | X | X | O | O | . col/레이블리스트 | X | O | O | O | . row/슬라이싱 | X | O | O | O | . col/슬라이싱 | X | X | O | O | . row/bool,list | X | O | O | O | . row/bool,ser | X | O | X | O | . row/bool,map | X | X | O | O | . col/bool,list | X | ? | ? | ? | . col/bool,ser | X | ? | ? | ? | . col/bool,map | X | ? | ? | ? | . - 채워보세요 (숙제입니다) --&gt; 그냥 제가 채웠어요 . . [] .iloc .loc commnets . row/단일레이블 | X | X | O | O | | . col/단일레이블 | O | O | O | O | | . row/레이블리스트 | X | X | O | O | | . col/레이블리스트 | X | O | O | O | | . row/슬라이싱 | X | O | O | O | | . col/슬라이싱 | X | X | O | O | | . row/bool,list | X | O | O | O | | . row/bool,ser | X | O | X | O | | . row/bool,map | X | X | O | O | | . col/bool,list | X | X | O | O | | . col/bool,ser | X | X | X | X | 쓸일이없음 | . col/bool,map | X | X | O | O | | . &#45936;&#51060;&#53552; . df=pd.read_csv(&#39;https://raw.githubusercontent.com/PacktPublishing/Pandas-Cookbook/master/data/movie.csv&#39;) df . color director_name num_critic_for_reviews duration director_facebook_likes actor_3_facebook_likes actor_2_name actor_1_facebook_likes gross genres ... num_user_for_reviews language country content_rating budget title_year actor_2_facebook_likes imdb_score aspect_ratio movie_facebook_likes . 0 Color | James Cameron | 723.0 | 178.0 | 0.0 | 855.0 | Joel David Moore | 1000.0 | 760505847.0 | Action|Adventure|Fantasy|Sci-Fi | ... | 3054.0 | English | USA | PG-13 | 237000000.0 | 2009.0 | 936.0 | 7.9 | 1.78 | 33000 | . 1 Color | Gore Verbinski | 302.0 | 169.0 | 563.0 | 1000.0 | Orlando Bloom | 40000.0 | 309404152.0 | Action|Adventure|Fantasy | ... | 1238.0 | English | USA | PG-13 | 300000000.0 | 2007.0 | 5000.0 | 7.1 | 2.35 | 0 | . 2 Color | Sam Mendes | 602.0 | 148.0 | 0.0 | 161.0 | Rory Kinnear | 11000.0 | 200074175.0 | Action|Adventure|Thriller | ... | 994.0 | English | UK | PG-13 | 245000000.0 | 2015.0 | 393.0 | 6.8 | 2.35 | 85000 | . 3 Color | Christopher Nolan | 813.0 | 164.0 | 22000.0 | 23000.0 | Christian Bale | 27000.0 | 448130642.0 | Action|Thriller | ... | 2701.0 | English | USA | PG-13 | 250000000.0 | 2012.0 | 23000.0 | 8.5 | 2.35 | 164000 | . 4 NaN | Doug Walker | NaN | NaN | 131.0 | NaN | Rob Walker | 131.0 | NaN | Documentary | ... | NaN | NaN | NaN | NaN | NaN | NaN | 12.0 | 7.1 | NaN | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 4911 Color | Scott Smith | 1.0 | 87.0 | 2.0 | 318.0 | Daphne Zuniga | 637.0 | NaN | Comedy|Drama | ... | 6.0 | English | Canada | NaN | NaN | 2013.0 | 470.0 | 7.7 | NaN | 84 | . 4912 Color | NaN | 43.0 | 43.0 | NaN | 319.0 | Valorie Curry | 841.0 | NaN | Crime|Drama|Mystery|Thriller | ... | 359.0 | English | USA | TV-14 | NaN | NaN | 593.0 | 7.5 | 16.00 | 32000 | . 4913 Color | Benjamin Roberds | 13.0 | 76.0 | 0.0 | 0.0 | Maxwell Moody | 0.0 | NaN | Drama|Horror|Thriller | ... | 3.0 | English | USA | NaN | 1400.0 | 2013.0 | 0.0 | 6.3 | NaN | 16 | . 4914 Color | Daniel Hsia | 14.0 | 100.0 | 0.0 | 489.0 | Daniel Henney | 946.0 | 10443.0 | Comedy|Drama|Romance | ... | 9.0 | English | USA | PG-13 | NaN | 2012.0 | 719.0 | 6.3 | 2.35 | 660 | . 4915 Color | Jon Gunn | 43.0 | 90.0 | 16.0 | 16.0 | Brian Herzlinger | 86.0 | 85222.0 | Documentary | ... | 84.0 | English | USA | PG | 1100.0 | 2004.0 | 23.0 | 6.6 | 1.85 | 456 | . 4916 rows × 28 columns . - 열의 이름을 출력하여 보자. . &#44592;&#48376;&#51064;&#45937;&#49905; (df &#51064;&#45937;&#49905;&#44277;&#48512; 1&#45800;&#44228; &#45236;&#50857;) . - color ~ num_voted_user 를 뽑고 + aspect_ratio 도 추가적으로 뽑고싶다. -&gt; loc으로는 못하겠어요.. . df.loc[:,[&#39;color&#39;:&#39;num_voted_users&#39;,&#39;aspect_ratio&#39;]] . File &#34;/tmp/ipykernel_1491369/1210972629.py&#34;, line 1 df.loc[:,[&#39;color&#39;:&#39;num_voted_users&#39;,&#39;aspect_ratio&#39;]] ^ SyntaxError: invalid syntax . - (팁) 복잡한 조건은 iloc으로 쓰는게 편할때가 있다. $ to$ 그런데 df.columns 변수들이 몇번인지 알아보기 힘듬 $ to$ 아래와 같이 하면 열의 이름을 인덱스와 함께 출력할 수 있음 . pd.Series(df.columns) . 0 color 1 director_name 2 num_critic_for_reviews 3 duration 4 director_facebook_likes 5 actor_3_facebook_likes 6 actor_2_name 7 actor_1_facebook_likes 8 gross 9 genres 10 actor_1_name 11 movie_title 12 num_voted_users 13 cast_total_facebook_likes 14 actor_3_name 15 facenumber_in_poster 16 plot_keywords 17 movie_imdb_link 18 num_user_for_reviews 19 language 20 country 21 content_rating 22 budget 23 title_year 24 actor_2_facebook_likes 25 imdb_score 26 aspect_ratio 27 movie_facebook_likes dtype: object . list(range(13))+[26] . [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 26] . df.iloc[:,list(range(13))+[26]] . color director_name num_critic_for_reviews duration director_facebook_likes actor_3_facebook_likes actor_2_name actor_1_facebook_likes gross genres actor_1_name movie_title num_voted_users aspect_ratio . 0 Color | James Cameron | 723.0 | 178.0 | 0.0 | 855.0 | Joel David Moore | 1000.0 | 760505847.0 | Action|Adventure|Fantasy|Sci-Fi | CCH Pounder | Avatar | 886204 | 1.78 | . 1 Color | Gore Verbinski | 302.0 | 169.0 | 563.0 | 1000.0 | Orlando Bloom | 40000.0 | 309404152.0 | Action|Adventure|Fantasy | Johnny Depp | Pirates of the Caribbean: At World&#39;s End | 471220 | 2.35 | . 2 Color | Sam Mendes | 602.0 | 148.0 | 0.0 | 161.0 | Rory Kinnear | 11000.0 | 200074175.0 | Action|Adventure|Thriller | Christoph Waltz | Spectre | 275868 | 2.35 | . 3 Color | Christopher Nolan | 813.0 | 164.0 | 22000.0 | 23000.0 | Christian Bale | 27000.0 | 448130642.0 | Action|Thriller | Tom Hardy | The Dark Knight Rises | 1144337 | 2.35 | . 4 NaN | Doug Walker | NaN | NaN | 131.0 | NaN | Rob Walker | 131.0 | NaN | Documentary | Doug Walker | Star Wars: Episode VII - The Force Awakens | 8 | NaN | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 4911 Color | Scott Smith | 1.0 | 87.0 | 2.0 | 318.0 | Daphne Zuniga | 637.0 | NaN | Comedy|Drama | Eric Mabius | Signed Sealed Delivered | 629 | NaN | . 4912 Color | NaN | 43.0 | 43.0 | NaN | 319.0 | Valorie Curry | 841.0 | NaN | Crime|Drama|Mystery|Thriller | Natalie Zea | The Following | 73839 | 16.00 | . 4913 Color | Benjamin Roberds | 13.0 | 76.0 | 0.0 | 0.0 | Maxwell Moody | 0.0 | NaN | Drama|Horror|Thriller | Eva Boehnke | A Plague So Pleasant | 38 | NaN | . 4914 Color | Daniel Hsia | 14.0 | 100.0 | 0.0 | 489.0 | Daniel Henney | 946.0 | 10443.0 | Comedy|Drama|Romance | Alan Ruck | Shanghai Calling | 1255 | 2.35 | . 4915 Color | Jon Gunn | 43.0 | 90.0 | 16.0 | 16.0 | Brian Herzlinger | 86.0 | 85222.0 | Documentary | John August | My Date with Drew | 4285 | 1.85 | . 4916 rows × 14 columns . actor&#46972;&#45716; &#45800;&#50612;&#44032; &#54252;&#54632;&#46108; column &#49440;&#53469; . - 다시 열의 이름들을 확인 . df.columns . Index([&#39;color&#39;, &#39;director_name&#39;, &#39;num_critic_for_reviews&#39;, &#39;duration&#39;, &#39;director_facebook_likes&#39;, &#39;actor_3_facebook_likes&#39;, &#39;actor_2_name&#39;, &#39;actor_1_facebook_likes&#39;, &#39;gross&#39;, &#39;genres&#39;, &#39;actor_1_name&#39;, &#39;movie_title&#39;, &#39;num_voted_users&#39;, &#39;cast_total_facebook_likes&#39;, &#39;actor_3_name&#39;, &#39;facenumber_in_poster&#39;, &#39;plot_keywords&#39;, &#39;movie_imdb_link&#39;, &#39;num_user_for_reviews&#39;, &#39;language&#39;, &#39;country&#39;, &#39;content_rating&#39;, &#39;budget&#39;, &#39;title_year&#39;, &#39;actor_2_facebook_likes&#39;, &#39;imdb_score&#39;, &#39;aspect_ratio&#39;, &#39;movie_facebook_likes&#39;], dtype=&#39;object&#39;) . - 방법1 . df.iloc[:,list(map(lambda x : &#39;actor&#39; in x, df.columns) )] . actor_3_facebook_likes actor_2_name actor_1_facebook_likes actor_1_name actor_3_name actor_2_facebook_likes . 0 855.0 | Joel David Moore | 1000.0 | CCH Pounder | Wes Studi | 936.0 | . 1 1000.0 | Orlando Bloom | 40000.0 | Johnny Depp | Jack Davenport | 5000.0 | . 2 161.0 | Rory Kinnear | 11000.0 | Christoph Waltz | Stephanie Sigman | 393.0 | . 3 23000.0 | Christian Bale | 27000.0 | Tom Hardy | Joseph Gordon-Levitt | 23000.0 | . 4 NaN | Rob Walker | 131.0 | Doug Walker | NaN | 12.0 | . ... ... | ... | ... | ... | ... | ... | . 4911 318.0 | Daphne Zuniga | 637.0 | Eric Mabius | Crystal Lowe | 470.0 | . 4912 319.0 | Valorie Curry | 841.0 | Natalie Zea | Sam Underwood | 593.0 | . 4913 0.0 | Maxwell Moody | 0.0 | Eva Boehnke | David Chandler | 0.0 | . 4914 489.0 | Daniel Henney | 946.0 | Alan Ruck | Eliza Coupe | 719.0 | . 4915 16.0 | Brian Herzlinger | 86.0 | John August | Jon Gunn | 23.0 | . 4916 rows × 6 columns . - 방법2 . df.loc[:,list(map(lambda x : &#39;actor&#39; in x, df.columns) )] . actor_3_facebook_likes actor_2_name actor_1_facebook_likes actor_1_name actor_3_name actor_2_facebook_likes . 0 855.0 | Joel David Moore | 1000.0 | CCH Pounder | Wes Studi | 936.0 | . 1 1000.0 | Orlando Bloom | 40000.0 | Johnny Depp | Jack Davenport | 5000.0 | . 2 161.0 | Rory Kinnear | 11000.0 | Christoph Waltz | Stephanie Sigman | 393.0 | . 3 23000.0 | Christian Bale | 27000.0 | Tom Hardy | Joseph Gordon-Levitt | 23000.0 | . 4 NaN | Rob Walker | 131.0 | Doug Walker | NaN | 12.0 | . ... ... | ... | ... | ... | ... | ... | . 4911 318.0 | Daphne Zuniga | 637.0 | Eric Mabius | Crystal Lowe | 470.0 | . 4912 319.0 | Valorie Curry | 841.0 | Natalie Zea | Sam Underwood | 593.0 | . 4913 0.0 | Maxwell Moody | 0.0 | Eva Boehnke | David Chandler | 0.0 | . 4914 489.0 | Daniel Henney | 946.0 | Alan Ruck | Eliza Coupe | 719.0 | . 4915 16.0 | Brian Herzlinger | 86.0 | John August | Jon Gunn | 23.0 | . 4916 rows × 6 columns . - 방법3 . df.iloc[:,map(lambda x : &#39;actor&#39; in x, df.columns)] . actor_3_facebook_likes actor_2_name actor_1_facebook_likes actor_1_name actor_3_name actor_2_facebook_likes . 0 855.0 | Joel David Moore | 1000.0 | CCH Pounder | Wes Studi | 936.0 | . 1 1000.0 | Orlando Bloom | 40000.0 | Johnny Depp | Jack Davenport | 5000.0 | . 2 161.0 | Rory Kinnear | 11000.0 | Christoph Waltz | Stephanie Sigman | 393.0 | . 3 23000.0 | Christian Bale | 27000.0 | Tom Hardy | Joseph Gordon-Levitt | 23000.0 | . 4 NaN | Rob Walker | 131.0 | Doug Walker | NaN | 12.0 | . ... ... | ... | ... | ... | ... | ... | . 4911 318.0 | Daphne Zuniga | 637.0 | Eric Mabius | Crystal Lowe | 470.0 | . 4912 319.0 | Valorie Curry | 841.0 | Natalie Zea | Sam Underwood | 593.0 | . 4913 0.0 | Maxwell Moody | 0.0 | Eva Boehnke | David Chandler | 0.0 | . 4914 489.0 | Daniel Henney | 946.0 | Alan Ruck | Eliza Coupe | 719.0 | . 4915 16.0 | Brian Herzlinger | 86.0 | John August | Jon Gunn | 23.0 | . 4916 rows × 6 columns . - 방법4 . df.loc[:,map(lambda x : &#39;actor&#39; in x, df.columns)] . actor_3_facebook_likes actor_2_name actor_1_facebook_likes actor_1_name actor_3_name actor_2_facebook_likes . 0 855.0 | Joel David Moore | 1000.0 | CCH Pounder | Wes Studi | 936.0 | . 1 1000.0 | Orlando Bloom | 40000.0 | Johnny Depp | Jack Davenport | 5000.0 | . 2 161.0 | Rory Kinnear | 11000.0 | Christoph Waltz | Stephanie Sigman | 393.0 | . 3 23000.0 | Christian Bale | 27000.0 | Tom Hardy | Joseph Gordon-Levitt | 23000.0 | . 4 NaN | Rob Walker | 131.0 | Doug Walker | NaN | 12.0 | . ... ... | ... | ... | ... | ... | ... | . 4911 318.0 | Daphne Zuniga | 637.0 | Eric Mabius | Crystal Lowe | 470.0 | . 4912 319.0 | Valorie Curry | 841.0 | Natalie Zea | Sam Underwood | 593.0 | . 4913 0.0 | Maxwell Moody | 0.0 | Eva Boehnke | David Chandler | 0.0 | . 4914 489.0 | Daniel Henney | 946.0 | Alan Ruck | Eliza Coupe | 719.0 | . 4915 16.0 | Brian Herzlinger | 86.0 | John August | Jon Gunn | 23.0 | . 4916 rows × 6 columns . s&#47196; &#45149;&#45208;&#45716; column &#49440;&#53469; . - 방법1 . df.iloc[:,map(lambda x: &#39;s&#39; == x[-1],df.columns )] . num_critic_for_reviews director_facebook_likes actor_3_facebook_likes actor_1_facebook_likes gross genres num_voted_users cast_total_facebook_likes plot_keywords num_user_for_reviews actor_2_facebook_likes movie_facebook_likes . 0 723.0 | 0.0 | 855.0 | 1000.0 | 760505847.0 | Action|Adventure|Fantasy|Sci-Fi | 886204 | 4834 | avatar|future|marine|native|paraplegic | 3054.0 | 936.0 | 33000 | . 1 302.0 | 563.0 | 1000.0 | 40000.0 | 309404152.0 | Action|Adventure|Fantasy | 471220 | 48350 | goddess|marriage ceremony|marriage proposal|pi... | 1238.0 | 5000.0 | 0 | . 2 602.0 | 0.0 | 161.0 | 11000.0 | 200074175.0 | Action|Adventure|Thriller | 275868 | 11700 | bomb|espionage|sequel|spy|terrorist | 994.0 | 393.0 | 85000 | . 3 813.0 | 22000.0 | 23000.0 | 27000.0 | 448130642.0 | Action|Thriller | 1144337 | 106759 | deception|imprisonment|lawlessness|police offi... | 2701.0 | 23000.0 | 164000 | . 4 NaN | 131.0 | NaN | 131.0 | NaN | Documentary | 8 | 143 | NaN | NaN | 12.0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 4911 1.0 | 2.0 | 318.0 | 637.0 | NaN | Comedy|Drama | 629 | 2283 | fraud|postal worker|prison|theft|trial | 6.0 | 470.0 | 84 | . 4912 43.0 | NaN | 319.0 | 841.0 | NaN | Crime|Drama|Mystery|Thriller | 73839 | 1753 | cult|fbi|hideout|prison escape|serial killer | 359.0 | 593.0 | 32000 | . 4913 13.0 | 0.0 | 0.0 | 0.0 | NaN | Drama|Horror|Thriller | 38 | 0 | NaN | 3.0 | 0.0 | 16 | . 4914 14.0 | 0.0 | 489.0 | 946.0 | 10443.0 | Comedy|Drama|Romance | 1255 | 2386 | NaN | 9.0 | 719.0 | 660 | . 4915 43.0 | 16.0 | 16.0 | 86.0 | 85222.0 | Documentary | 4285 | 163 | actress name in title|crush|date|four word tit... | 84.0 | 23.0 | 456 | . 4916 rows × 12 columns . - 방법2 . df.loc[:,map(lambda x: &#39;s&#39; == x[-1],df.columns )] . num_critic_for_reviews director_facebook_likes actor_3_facebook_likes actor_1_facebook_likes gross genres num_voted_users cast_total_facebook_likes plot_keywords num_user_for_reviews actor_2_facebook_likes movie_facebook_likes . 0 723.0 | 0.0 | 855.0 | 1000.0 | 760505847.0 | Action|Adventure|Fantasy|Sci-Fi | 886204 | 4834 | avatar|future|marine|native|paraplegic | 3054.0 | 936.0 | 33000 | . 1 302.0 | 563.0 | 1000.0 | 40000.0 | 309404152.0 | Action|Adventure|Fantasy | 471220 | 48350 | goddess|marriage ceremony|marriage proposal|pi... | 1238.0 | 5000.0 | 0 | . 2 602.0 | 0.0 | 161.0 | 11000.0 | 200074175.0 | Action|Adventure|Thriller | 275868 | 11700 | bomb|espionage|sequel|spy|terrorist | 994.0 | 393.0 | 85000 | . 3 813.0 | 22000.0 | 23000.0 | 27000.0 | 448130642.0 | Action|Thriller | 1144337 | 106759 | deception|imprisonment|lawlessness|police offi... | 2701.0 | 23000.0 | 164000 | . 4 NaN | 131.0 | NaN | 131.0 | NaN | Documentary | 8 | 143 | NaN | NaN | 12.0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 4911 1.0 | 2.0 | 318.0 | 637.0 | NaN | Comedy|Drama | 629 | 2283 | fraud|postal worker|prison|theft|trial | 6.0 | 470.0 | 84 | . 4912 43.0 | NaN | 319.0 | 841.0 | NaN | Crime|Drama|Mystery|Thriller | 73839 | 1753 | cult|fbi|hideout|prison escape|serial killer | 359.0 | 593.0 | 32000 | . 4913 13.0 | 0.0 | 0.0 | 0.0 | NaN | Drama|Horror|Thriller | 38 | 0 | NaN | 3.0 | 0.0 | 16 | . 4914 14.0 | 0.0 | 489.0 | 946.0 | 10443.0 | Comedy|Drama|Romance | 1255 | 2386 | NaN | 9.0 | 719.0 | 660 | . 4915 43.0 | 16.0 | 16.0 | 86.0 | 85222.0 | Documentary | 4285 | 163 | actress name in title|crush|date|four word tit... | 84.0 | 23.0 | 456 | . 4916 rows × 12 columns . c &#54841;&#51008; d&#47196; &#49884;&#51089;&#54616;&#45716; column &#49440;&#53469; . - 방법1 . df.iloc[:,map(lambda x: &#39;c&#39; == x[0] or &#39;d&#39; == x[0] ,df.columns )] . color director_name duration director_facebook_likes cast_total_facebook_likes country content_rating . 0 Color | James Cameron | 178.0 | 0.0 | 4834 | USA | PG-13 | . 1 Color | Gore Verbinski | 169.0 | 563.0 | 48350 | USA | PG-13 | . 2 Color | Sam Mendes | 148.0 | 0.0 | 11700 | UK | PG-13 | . 3 Color | Christopher Nolan | 164.0 | 22000.0 | 106759 | USA | PG-13 | . 4 NaN | Doug Walker | NaN | 131.0 | 143 | NaN | NaN | . ... ... | ... | ... | ... | ... | ... | ... | . 4911 Color | Scott Smith | 87.0 | 2.0 | 2283 | Canada | NaN | . 4912 Color | NaN | 43.0 | NaN | 1753 | USA | TV-14 | . 4913 Color | Benjamin Roberds | 76.0 | 0.0 | 0 | USA | NaN | . 4914 Color | Daniel Hsia | 100.0 | 0.0 | 2386 | USA | PG-13 | . 4915 Color | Jon Gunn | 90.0 | 16.0 | 163 | USA | PG | . 4916 rows × 7 columns . - 방법2 . df.loc[:,map(lambda x: &#39;c&#39; == x[0] or &#39;d&#39; == x[0] ,df.columns )] . color director_name duration director_facebook_likes cast_total_facebook_likes country content_rating . 0 Color | James Cameron | 178.0 | 0.0 | 4834 | USA | PG-13 | . 1 Color | Gore Verbinski | 169.0 | 563.0 | 48350 | USA | PG-13 | . 2 Color | Sam Mendes | 148.0 | 0.0 | 11700 | UK | PG-13 | . 3 Color | Christopher Nolan | 164.0 | 22000.0 | 106759 | USA | PG-13 | . 4 NaN | Doug Walker | NaN | 131.0 | 143 | NaN | NaN | . ... ... | ... | ... | ... | ... | ... | ... | . 4911 Color | Scott Smith | 87.0 | 2.0 | 2283 | Canada | NaN | . 4912 Color | NaN | 43.0 | NaN | 1753 | USA | TV-14 | . 4913 Color | Benjamin Roberds | 76.0 | 0.0 | 0 | USA | NaN | . 4914 Color | Daniel Hsia | 100.0 | 0.0 | 2386 | USA | PG-13 | . 4915 Color | Jon Gunn | 90.0 | 16.0 | 163 | USA | PG | . 4916 rows × 7 columns . df: &#49352;&#47196;&#50868; &#50676;&#51032; &#54624;&#45817; 1&#45800;&#44228; . &#48169;&#48277;1: concat . df = pd.DataFrame({&#39;a&#39;:[1,2,3],&#39;b&#39;:[2,3,4]}) df . a b . 0 1 | 2 | . 1 2 | 3 | . 2 3 | 4 | . _df = pd.DataFrame({&#39;c&#39;:[3,4,5]}) _df . c . 0 3 | . 1 4 | . 2 5 | . pd.concat([df,_df],axis=1) . a b c . 0 1 | 2 | 3 | . 1 2 | 3 | 4 | . 2 3 | 4 | 5 | . &#48169;&#48277;2: 4&#44032;&#51648; &#52968;&#49481;&#50640; &#46384;&#47480; &#54624;&#45817; . # &#52968;&#49481;1: &#48520;&#44032;&#45733; . df = pd.DataFrame({&#39;a&#39;:[1,2,3],&#39;b&#39;:[2,3,4]}) df . a b . 0 1 | 2 | . 1 2 | 3 | . 2 3 | 4 | . df.c = pd.Series([1,2,3]) df . /home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: Pandas doesn&#39;t allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access &#34;&#34;&#34;Entry point for launching an IPython kernel. . a b . 0 1 | 2 | . 1 2 | 3 | . 2 3 | 4 | . # &#52968;&#49481;2: &#44032;&#45733; . (예시1) . df = pd.DataFrame({&#39;a&#39;:[1,2,3],&#39;b&#39;:[2,3,4]}) df . a b . 0 1 | 2 | . 1 2 | 3 | . 2 3 | 4 | . df[&#39;c&#39;]=[3,4,5] df . a b c . 0 1 | 2 | 3 | . 1 2 | 3 | 4 | . 2 3 | 4 | 5 | . (예시2) . df = pd.DataFrame({&#39;a&#39;:[1,2,3],&#39;b&#39;:[2,3,4]}) df . a b . 0 1 | 2 | . 1 2 | 3 | . 2 3 | 4 | . df[[&#39;c&#39;,&#39;d&#39;]]=np.array([[3,4,5],[4,5,6]]).T # 굳이.. df . a b c d . 0 1 | 2 | 3 | 4 | . 1 2 | 3 | 4 | 5 | . 2 3 | 4 | 5 | 6 | . (예시3) . df = pd.DataFrame({&#39;a&#39;:[1,2,3],&#39;b&#39;:[2,3,4]}) df . a b . 0 1 | 2 | . 1 2 | 3 | . 2 3 | 4 | . df[&#39;c&#39;],df[&#39;d&#39;]=[3,4,5],[4,5,6] df . a b c d . 0 1 | 2 | 3 | 4 | . 1 2 | 3 | 4 | 5 | . 2 3 | 4 | 5 | 6 | . # &#52968;&#49481;3: &#48520;&#44032;&#45733; . (예시1) . df = pd.DataFrame({&#39;a&#39;:[1,2,3],&#39;b&#39;:[2,3,4]}) df . a b . 0 1 | 2 | . 1 2 | 3 | . 2 3 | 4 | . df.iloc[:,2] = [3,4,5] df . IndexError Traceback (most recent call last) /tmp/ipykernel_1491369/2293349637.py in &lt;module&gt; -&gt; 1 df.iloc[:,2] = [3,4,5] 2 df ~/anaconda3/envs/py37/lib/python3.7/site-packages/pandas/core/indexing.py in __setitem__(self, key, value) 718 key = com.apply_if_callable(key, self.obj) 719 indexer = self._get_setitem_indexer(key) --&gt; 720 self._has_valid_setitem_indexer(key) 721 722 iloc = self if self.name == &#34;iloc&#34; else self.obj.iloc ~/anaconda3/envs/py37/lib/python3.7/site-packages/pandas/core/indexing.py in _has_valid_setitem_indexer(self, indexer) 1459 elif is_integer(i): 1460 if i &gt;= len(ax): -&gt; 1461 raise IndexError(&#34;iloc cannot enlarge its target object&#34;) 1462 elif isinstance(i, dict): 1463 raise IndexError(&#34;iloc cannot enlarge its target object&#34;) IndexError: iloc cannot enlarge its target object . # &#52968;&#49481;4: &#44032;&#45733; . (예시1) . df = pd.DataFrame({&#39;a&#39;:[1,2,3],&#39;b&#39;:[2,3,4]}) df . a b . 0 1 | 2 | . 1 2 | 3 | . 2 3 | 4 | . df.loc[:,&#39;c&#39;] = [3,4,5] df . a b c . 0 1 | 2 | 3 | . 1 2 | 3 | 4 | . 2 3 | 4 | 5 | . (예시2) . df = pd.DataFrame({&#39;a&#39;:[1,2,3],&#39;b&#39;:[2,3,4]}) df . a b . 0 1 | 2 | . 1 2 | 3 | . 2 3 | 4 | . df.loc[:,[&#39;c&#39;,&#39;d&#39;]] = np.array([[3,4,5],[4,5,6]]).T # 이거 솔직히 되는지 몰랐어요.. df . a b c d . 0 1 | 2 | 3 | 4 | . 1 2 | 3 | 4 | 5 | . 2 3 | 4 | 5 | 6 | . (예시3) . df = pd.DataFrame({&#39;a&#39;:[1,2,3],&#39;b&#39;:[2,3,4]}) df . a b . 0 1 | 2 | . 1 2 | 3 | . 2 3 | 4 | . df.loc[:,&#39;c&#39;],df.loc[:,&#39;d&#39;] = [3,4,5],[4,5,6] df . a b c d . 0 1 | 2 | 3 | 4 | . 1 2 | 3 | 4 | 5 | . 2 3 | 4 | 5 | 6 | . &#48169;&#48277;3: .assign&#51004;&#47196; &#54624;&#45817; ($ star$) -- &#51228; &#52572;&#50528; . df = pd.DataFrame({&#39;a&#39;:[1,2,3],&#39;b&#39;:[2,3,4]}) df . a b . 0 1 | 2 | . 1 2 | 3 | . 2 3 | 4 | . df.assign(c=[3,4,5]) . a b c . 0 1 | 2 | 3 | . 1 2 | 3 | 4 | . 2 3 | 4 | 5 | . df.assign(c=[3,4,5],d=[4,5,6]) . a b c d . 0 1 | 2 | 3 | 4 | . 1 2 | 3 | 4 | 5 | . 2 3 | 4 | 5 | 6 | . df.assign(c=[3,4,5]).assign(d=[4,5,6]) . a b c d . 0 1 | 2 | 3 | 4 | . 1 2 | 3 | 4 | 5 | . 2 3 | 4 | 5 | 6 | . &#48169;&#48277;4: .eval&#51012; &#51060;&#50857;&#54620; &#54624;&#45817; . df = pd.DataFrame({&#39;a&#39;:[1,2,3],&#39;b&#39;:[2,3,4]}) df . a b . 0 1 | 2 | . 1 2 | 3 | . 2 3 | 4 | . df.eval(&#39;c=[3,4,5]&#39;) . a b c . 0 1 | 2 | 3 | . 1 2 | 3 | 4 | . 2 3 | 4 | 5 | . df.eval(&#39;c=[3,4,5]&#39;).eval(&#39;d=[4,5,6]&#39;) . a b c d . 0 1 | 2 | 3 | 4 | . 1 2 | 3 | 4 | 5 | . 2 3 | 4 | 5 | 6 | . &#50672;&#49845;&#54644;&#48372;&#44592; . # &#45936;&#51060;&#53552;&#54532;&#47112;&#51076; &#49373;&#49457; . df=pd.DataFrame({&#39;x&#39;:np.random.randn(1000),&#39;y&#39;:np.random.randn(1000)}) df . x y . 0 1.085469 | -1.427839 | . 1 -1.473272 | -1.527442 | . 2 -1.007274 | -1.312202 | . 3 1.220634 | -0.474995 | . 4 -0.101496 | 1.636326 | . ... ... | ... | . 995 -0.668557 | -0.435391 | . 996 0.455894 | 0.796826 | . 997 -1.004412 | 1.843344 | . 998 -2.115145 | -1.971965 | . 999 0.861141 | -0.193742 | . 1000 rows × 2 columns . # &#49352;&#47196;&#50868;&#50676; r&#51012; &#49373;&#49457;&#54616;&#44256; $r= sqrt{x^2 + y^2}$&#47484; &#44228;&#49328; . - 방법1: 브로드캐스팅 . df.assign(r=np.sqrt(df.x**2 + df.y**2)) . x y r . 0 1.085469 | -1.427839 | 1.793590 | . 1 -1.473272 | -1.527442 | 2.122171 | . 2 -1.007274 | -1.312202 | 1.654229 | . 3 1.220634 | -0.474995 | 1.309796 | . 4 -0.101496 | 1.636326 | 1.639470 | . ... ... | ... | ... | . 995 -0.668557 | -0.435391 | 0.797831 | . 996 0.455894 | 0.796826 | 0.918026 | . 997 -1.004412 | 1.843344 | 2.099229 | . 998 -2.115145 | -1.971965 | 2.891796 | . 999 0.861141 | -0.193742 | 0.882667 | . 1000 rows × 3 columns . - 방법2: lambda + map을 이용한 개별원소 계산 . df.assign(r=list(map(lambda x,y: np.sqrt(x**2+y**2), df.x,df.y))) . x y r . 0 1.085469 | -1.427839 | 1.793590 | . 1 -1.473272 | -1.527442 | 2.122171 | . 2 -1.007274 | -1.312202 | 1.654229 | . 3 1.220634 | -0.474995 | 1.309796 | . 4 -0.101496 | 1.636326 | 1.639470 | . ... ... | ... | ... | . 995 -0.668557 | -0.435391 | 0.797831 | . 996 0.455894 | 0.796826 | 0.918026 | . 997 -1.004412 | 1.843344 | 2.099229 | . 998 -2.115145 | -1.971965 | 2.891796 | . 999 0.861141 | -0.193742 | 0.882667 | . 1000 rows × 3 columns . - 방법3: eval . df.eval(&#39;r=sqrt(x**2+y**2)&#39;) . x y r . 0 1.085469 | -1.427839 | 1.793590 | . 1 -1.473272 | -1.527442 | 2.122171 | . 2 -1.007274 | -1.312202 | 1.654229 | . 3 1.220634 | -0.474995 | 1.309796 | . 4 -0.101496 | 1.636326 | 1.639470 | . ... ... | ... | ... | . 995 -0.668557 | -0.435391 | 0.797831 | . 996 0.455894 | 0.796826 | 0.918026 | . 997 -1.004412 | 1.843344 | 2.099229 | . 998 -2.115145 | -1.971965 | 2.891796 | . 999 0.861141 | -0.193742 | 0.882667 | . 1000 rows × 3 columns . &#50500;&#51060;&#49828;&#53356;&#47548;&#51012; &#47566;&#51060; &#47673;&#51004;&#47732; &#44152;&#47532;&#45716; &#48337; (1) . - ref- 데이터 과학자의 사고법: 더 나은 선택을 위한 통계학적 통찰의 힘 . 구매할만한 책입니다 | . - 내용요약 . 여름 $ to$ 수영장 $ to$ 소아마비 | 여름 $ to$ 아이스크림 | 아이스크림과 소아마비는 상관관계가 높다: 아이스크림 성분중에서 소아마비를 유발하는 유해물질이 있을 것이다 (?) | . - 아래와 같이 모형을 간단하게 하자. . 온도 $ to$ 소아마비 | 온도 $ to$ 아이스크림 | . Toy exam . - 교재의 예제상황은 예를들면 아래와 같다. . (숨은진짜상황1) . $$ text{아이스크림 판매량} = 20 + 2 times text{온도} + epsilon$$ . np.random.seed(1) temp= np.array([-10.2, -5.2, 0.1, 10.1, 12.2, 14.7, 25.4, 26.8, 28.9, 35.1, 32.2, 34.6]) eps= np.random.normal(size=12,scale=5) icecream= 20 + temp * 2 + eps . plt.plot(temp,icecream,&#39;.&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f92ea184790&gt;] . 온도와 아이스크림 판매량의 산점도 | . (숨은진짜상황2) . $$ text{소아마비 반응수치} = 30 + 0.5 times text{온도} + epsilon$$ . 좌변은 소아마비임을 나타내는 어떠한 반응수치라고 생각하자. | . np.random.seed(2) eps = np.random.normal(size=12,scale=5) disease = 30+ temp* 0.5 + eps . plt.plot(temp,disease,&#39;.&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f92e98bd6d0&gt;] . 온도와 소아마비의 산점도 | . (우리가 데이터로부터 관측한 상황) . - 아이스크림과 질병의 산점도를 그려보자. . plt.plot(icecream,disease,&#39;.&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f92e9849990&gt;] . 양의 상관관계에 있다. | . - 아이스크림 중 어떠한 물질이 소아마비를 일으키는것이 분명하므로 (인과성이 분명해보이니까) 아래와 같은 모형을 세우자. &lt;-- 여기서부터 틀렸음 . $${ tt disease}_i = beta_0 + beta_1 { tt icecream}_i + epsilon_i, quad textbf{for} ~~ i=1,2, dots, 12$$ . - 적절한 $ beta_0$와 $ beta_1$을 추정하면 우리는 아이스크림과 소아마비의 관계를 알 수 있다. &lt;-- 틀린주장 . 틀린 모형 | 도데체 우리가 뭘 잘못했는가? | . - 두 변수 사이에 상관관계가 있어도 실제 원인은 다른 변수에 숨겨져 있는 경우가 많다. . (ex1) . 온도 $ to$ 익사 | 온도 $ to$ 아이스크림 | 아이스크림과 익사자도 양의 상관관계에 있을것이다. | 아이스크림을 먹이면 물에 빠져 죽는다 $ to$ 틀린주장 | 사실 기온이 숨겨진 원인이다. 기온이 증가하면 아이스크림 판매량도 증가하고 폭염때문에 익사사고율도 높아지는 구조이다. | . (ex2) . 인구수 $ to$ 교회 | 인구수 $ to$ 범죄건수 | 지역별 교회와 범죄건수를 살펴보면 상관관계가 높게 나올것임 | 교회를 지으면 범죄건수도 증가한다? $ to$ 틀린주장 | 사실 인구가 숨겨진 요인임 | . - ex2, ex1에 대하여 바른 분석을 하려면? . ex2: 인구가 비슷한 도시끼리 묶어서 비교해보면 교회와 범죄의 건수는 양의 상관관계에 있지 않을것임 | ex1: 온도가 비슷한 그룹끼리 묶어보자. | . - 올바른 분석: 온도가 비슷한 그룹끼리 묶어서 그려보자. $ to$ 상관계수가 줄어들 것이다. . plt.plot(icecream[:6],disease[:6],&#39;.&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f92e97c91d0&gt;] . plt.plot(icecream[6:],disease[6:],&#39;.&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f92e973f5d0&gt;] . 진짜로 선형관계가 약해졌다.. | . &#49689;&#51228; (&#49688;&#50629;&#49884;&#44036;&#50640; &#54620; &#45236;&#50857; X) . df = pd.DataFrame({&#39;a&#39;:[1,2,3,4],&#39;b&#39;:[2,3,4,5],&#39;c&#39;:[3,4,5,6],&#39;d&#39;:[4,5,6,7]}) df . a b c d . 0 1 | 2 | 3 | 4 | . 1 2 | 3 | 4 | 5 | . 2 3 | 4 | 5 | 6 | . 3 4 | 5 | 6 | 7 | . 아래의 결과를 관찰하고 drop의 기능을 유추하라. . (예시1) . df.drop(columns=&#39;a&#39;) . b c d . 0 2 | 3 | 4 | . 1 3 | 4 | 5 | . 2 4 | 5 | 6 | . 3 5 | 6 | 7 | . (예시2) . df.drop(columns=[&#39;a&#39;,&#39;b&#39;]) . c d . 0 3 | 4 | . 1 4 | 5 | . 2 5 | 6 | . 3 6 | 7 | . (예시3) . df.drop(index=0) . a b c d . 1 2 | 3 | 4 | 5 | . 2 3 | 4 | 5 | 6 | . 3 4 | 5 | 6 | 7 | . (예시4) . df.drop(index=range(2,4)) . a b c d . 0 1 | 2 | 3 | 4 | . 1 2 | 3 | 4 | 5 | . 문제: df 에서 a,c열을 삭제하고 첫행을 삭제하라. . #출력결과는 아래와 같아야 한다. . b d . 1 3 | 5 | . 2 4 | 6 | . 3 5 | 7 | .",
            "url": "https://guebin.github.io/DV2022/2022/10/17/(7%EC%A3%BC%EC%B0%A8)-10%EC%9B%9417%EC%9D%BC.html",
            "relUrl": "/2022/10/17/(7%EC%A3%BC%EC%B0%A8)-10%EC%9B%9417%EC%9D%BC.html",
            "date": " • Oct 17, 2022"
        }
        
    
  
    
        ,"post7": {
            "title": "(6주차) 10월12일, 10월14일",
            "content": "&#44053;&#51032;&#50689;&#49345; . . imports . import numpy as np import pandas as pd import matplotlib.pyplot as plt . lambda, map ($ star$) . lambda . - 예제1: 람다표현식(lambda expression)자체가 하나의 오브젝트임 . lambda x: (x-2)**2 ### lambda x: (x-2)**2 가 실행되는 순간 메모리상에 함수 오브젝트가 저장됨 . &lt;function __main__.&lt;lambda&gt;(x)&gt; . &quot;lambda x: (x-2)**2&quot; 는 $lambda(x)=(x-2)^2$의 느낌으로 기억하면 쉬움 | . (사용방법) . (lambda x: (x-2)**2)(2) # 입력2 -&gt; 출력 (2-2)^2 =0 . 0 . (lambda x: (x-2)**2)(4) # 입력5 -&gt; 출력 (4-2)^2 =4 . 4 . (lambda x: (x-2)**2)(6) # 입력6 -&gt; 출력 (6-2)^2 =16 . 16 . (lambda x: (x-2)**2)(-2) # 입력-2 -&gt; 출력 (-2-2)^2 =16 . 16 . - 예제2: 람다표현식에 이름을 줄 수 있음. . f = lambda x: (x-2)**2 . f(2),f(4),f(6),f(-2) . (0, 4, 16, 16) . 위의 코드는 아래와 같다. . def f(x): return (x-2)**2 f(2),f(4),f(6),f(-2) . (0, 4, 16, 16) . - 예제3: 조건부 출력 . f = lambda x,y: x if x&gt;y else y # x,y가 입력 -&gt; x&gt;y 일때만 x를 리턴하고 그렇지않으면 y를 리턴 = 큰값을 리턴하라는 소리임 . f(1,20) . 20 . - 예제4: 람다표현식들의 리스트 . fl = [lambda x: x, lambda x: x**2, lambda x: x**3] . for f in fl: print(f(2)) . 2 4 8 . x = np.linspace(-1,1,100) for f in fl: plt.plot(x,f(x),&#39;--&#39;) . - 예제5: 람다표현식들의 딕셔너리 . fd = {&#39;f1&#39;:lambda x: x, &#39;f2&#39;:lambda x: x**2, &#39;f3&#39;:lambda x: x**3} fd . {&#39;f1&#39;: &lt;function __main__.&lt;lambda&gt;(x)&gt;, &#39;f2&#39;: &lt;function __main__.&lt;lambda&gt;(x)&gt;, &#39;f3&#39;: &lt;function __main__.&lt;lambda&gt;(x)&gt;} . for k in fd: plt.plot(x,fd[k](x),&#39;--&#39;) . - 예제6: 람다표현식을 리턴하는 함수 (함수를 리턴하는 함수) . (예비학습) 함수 $g(x)$가 정의되어 있을때 $ frac{d}{dx}g(x)$의 값을 계산해보기 . g = lambda x: x**2 . gg = lambda x : (g(x+0.001)-g(x))/0.001 . gg(4) . 8.0010000000037 . (목표) 도함수를 구해주는 derivate 함수를 정의하자. 이 함수는 임의의 함수 g를 입력으로 받으면, g의 도함수(gg)가 리턴되는 기능을 가진다. . def derivate(g): return lambda x: (g(x+0.001)-g(x))/0.001 . (사용1) . g = lambda x: np.sin(x) . gg = derivate(g) . x = np.linspace(0,6.28,1000) . plt.plot(x,g(x),label=r&#39;$f(x)=sin(x)$&#39;) plt.plot(x,gg(x),label=r&#39;$ frac{d}{dx}f(x)=cos(x)$&#39;) plt.legend(fontsize=15) . &lt;matplotlib.legend.Legend at 0x7fa54cde3a50&gt; . (사용2) . g0 = lambda x: (1/6)*x**3 g1 = derivate(g0) # (1/2)x^2 g2 = derivate(g1) # x . x = np.linspace(-1,1,100) plt.plot(x,g0(x),&#39;--&#39;,label=r&#39;$g_0(x)= frac{1}{6}x^3$&#39;) plt.plot(x,g1(x),&#39;--&#39;,label=r&#39;$g_1(x)= frac{1}{2}x^2$&#39;) plt.plot(x,g2(x),&#39;--&#39;,label=r&#39;$g_2(x)=x$&#39;) plt.legend(fontsize=15) . &lt;matplotlib.legend.Legend at 0x7fa54cccc2d0&gt; . - 예제7: 예제6의 다른표현 . derivate = lambda g: lambda x: (g(x+0.001)-g(x))/0.001 . (사용1) . g = lambda x: np.sin(x) . gg = derivate(g) . x = np.linspace(0,6.28,1000) . plt.plot(x,g(x),label=r&#39;$f(x)=sin(x)$&#39;) plt.plot(x,gg(x),label=r&#39;$ frac{d}{dx}f(x)=cos(x)$&#39;) plt.legend(fontsize=15) . &lt;matplotlib.legend.Legend at 0x7fa54cdb1b10&gt; . (사용2) . g0 = lambda x: (1/6)*x**3 g1 = derivate(g0) # (1/2)x^2 g2 = derivate(g1) # x . x = np.linspace(-1,1,100) plt.plot(x,g0(x),&#39;--&#39;,label=r&#39;$g_0(x)= frac{1}{6}x^3$&#39;) plt.plot(x,g1(x),&#39;--&#39;,label=r&#39;$g_1(x)= frac{1}{2}x^2$&#39;) plt.plot(x,g2(x),&#39;--&#39;,label=r&#39;$g_2(x)=x$&#39;) plt.legend(fontsize=15) . &lt;matplotlib.legend.Legend at 0x7fa54cee96d0&gt; . map . - 개념: $ text{map} left(f,[x_1,x_2, dots,x_n] right)= left[f(x_1),f(x_2), dots,f(x_n) right] $ . - 예제1: . x=[1,2,3] f = lambda x: x+1 y = list(map(f,x)) . (다른구현1) . list(map(lambda x: x+1,[1,2,3])) . [2, 3, 4] . (다른구현2) . f = lambda x: x+1 [f(xi) for xi in [1,2,3]] . [2, 3, 4] . (다른구현3) . [(lambda x: x+1)(xi) for xi in [1,2,3]] . [2, 3, 4] . (다른구현4)--최악 . y = [] x = [1,2,3] f = lambda x: x+1 for xi in x: y.append(f(xi)) . y . [2, 3, 4] . (다른구현5)--더 최악 . y = [] x = [1,2,3] f = lambda x: x+1 for i in range(len(x)): y.append(f(x[i])) . y . [2, 3, 4] . - 예제2: 문자열을 입력으로 받고 대문자이면 True, 소문자이면 False . 입력: A,B,C,a,b,c 출력: T,T,T,F,F,F . x= list(&#39;ABCabc&#39;) # x = [&#39;A&#39;,&#39;B&#39;,&#39;C&#39;,&#39;a&#39;,&#39;b&#39;,&#39;c&#39;] f = lambda s: s.isupper() y = list(map(f,x)) . x,y . ([&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;a&#39;, &#39;b&#39;, &#39;c&#39;], [True, True, True, False, False, False]) . - 예제3: 두개의 입력을 받는 함수 (map을 이용하는 것이 리스트 컴프리헨션보다 조금 편한것 같다) . list(map(lambda x,y: x+y, [1,2,3],[-1,-2,-3])) . [0, 0, 0] . (다른구현)-- 리스트컴프리헨션 . f = lambda x,y: x+y [f(x,y) for x,y in zip([1,2,3],[-1,-2,-3])] . [0, 0, 0] . - 예제4: map은 &quot;하나의 함수에 다양한 입력&quot;을 적용하는 경우에만 사용가능, 리스트컴프리헨션은 &quot;다양한 함수에 다양한 입력&quot; 지원 . flst = [lambda x: x+1, lambda x: x+2, lambda x:x+3] . map으로 구현시도 $ to$ 실패 . list(map(flst,[-1,-2,-3])) # 결과가 0,0,0 . TypeError Traceback (most recent call last) /tmp/ipykernel_1457577/3991505680.py in &lt;module&gt; -&gt; 1 list(map(flst,[-1,-2,-3])) # 결과가 0,0,0 TypeError: &#39;list&#39; object is not callable . 리스트컴프리헨션으로 구현시도 $ to$ 성공 . [f(x) for f,x in zip(flst,[-1,-2,-3])] . [0, 0, 0] . - 종합: map과 리스트컴프리헨션과 비교 . map은 for문을 위한 $i$등의 인덱스를 쓰지 않지만 리스트컴프리헨션은 필요함 | map은 좀더 리스트컴프리헨션보다 제약적으로 사용할 수 밖에 없음. | . df: &#51064;&#45937;&#49905; 1&#45800;&#44228;-- &#51064;&#45937;&#49905;&#51032; 4&#44032;&#51648; &#52968;&#49481; . &#45936;&#51060;&#53552;&#54532;&#47112;&#51076; &#51456;&#48708; . - 데이터준비 . df=pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/DV2022/master/_notebooks/dv2022.csv&#39;) df . att rep mid fin . 0 65 | 45 | 0 | 10 | . 1 95 | 30 | 60 | 10 | . 2 65 | 85 | 15 | 20 | . 3 55 | 35 | 35 | 5 | . 4 80 | 60 | 55 | 70 | . ... ... | ... | ... | ... | . 195 55 | 70 | 40 | 95 | . 196 65 | 85 | 25 | 85 | . 197 85 | 85 | 100 | 10 | . 198 80 | 65 | 35 | 60 | . 199 50 | 95 | 45 | 85 | . 200 rows × 4 columns . - 앞으로는 위와 같은 df형태를 가정할 것이다. 즉 column의 이름은 문자열, row의 이름은 0부터 시작하는 정수로 가정한다. . - 아래와 같은 형태는 일단 생각하지 않는다. . pd.DataFrame({&#39;att&#39;:[60,65,80,90],&#39;rep&#39;:[50,100,90,100]},index=[&#39;규빈&#39;,&#39;영미&#39;,&#39;성준&#39;,&#39;혜미&#39;]) . att rep . 규빈 60 | 50 | . 영미 65 | 100 | . 성준 80 | 90 | . 혜미 90 | 100 | . df&#51032; 4&#44032;&#51648; &#52968;&#49481; . - 원소에 접근하는 4가지 방법: ., [], .iloc[], .loc[] . &#52968;&#49481;1: &#53364;&#47000;&#49828;&#45712;&#45196; . - 컨셉1: df는 인스턴스이다. 그리고 df.att, df.rep,df.mid, df.fin 와 같이 col이름에 대응하는 속성이 있다. . df.head() . att rep mid fin . 0 65 | 45 | 0 | 10 | . 1 95 | 30 | 60 | 10 | . 2 65 | 85 | 15 | 20 | . 3 55 | 35 | 35 | 5 | . 4 80 | 60 | 55 | 70 | . df.fin . 0 10 1 10 2 20 3 5 4 70 .. 195 95 196 85 197 10 198 60 199 85 Name: fin, Length: 200, dtype: int64 . - 언제유용? col의 이름을 대충 알고 있을 경우 자동완성으로 쉽게 선택가능 . &#52968;&#49481;2: &#46357;&#49492;&#45320;&#47532; + $ alpha$ &#45712;&#45196; . - 컨셉2: df는 컬럼이름이 key, 컬럼의데이터가 value가 되는 dictionary로 이해할 수 있다. 즉 아래의 dct와 같은 딕셔너리로 이해할 수 있다. . dct = dict(df) #dct . (예시) .keys() 메소드를 이용하여 컬럼들의 이름을 살펴볼 수 있음. . dct.keys(), df.keys() . (dict_keys([&#39;att&#39;, &#39;rep&#39;, &#39;mid&#39;, &#39;fin&#39;]), Index([&#39;att&#39;, &#39;rep&#39;, &#39;mid&#39;, &#39;fin&#39;], dtype=&#39;object&#39;)) . # col indexing . - 예시1: dct가 가능하면 df도 가능하다. . df[&#39;att&#39;] #dct[&#39;att&#39;] . 0 65 1 95 2 65 3 55 4 80 .. 195 55 196 65 197 85 198 80 199 50 Name: att, Length: 200, dtype: int64 . - 예시2: dct가 가능하면 df도 가능하다. (2) . df.get(&#39;att&#39;) #dct.get(&#39;att&#39;) . 0 65 1 95 2 65 3 55 4 80 .. 195 55 196 65 197 85 198 80 199 50 Name: att, Length: 200, dtype: int64 . - 예시3: dct에서 불가능하지만 df에서 가능한것도 있다. . dct.get([&#39;att&#39;,&#39;rep&#39;]) . TypeError Traceback (most recent call last) /tmp/ipykernel_1457577/2570151095.py in &lt;module&gt; -&gt; 1 dct.get([&#39;att&#39;,&#39;rep&#39;]) TypeError: unhashable type: &#39;list&#39; . df.get([&#39;att&#39;,&#39;rep&#39;]) . att rep . 0 65 | 45 | . 1 95 | 30 | . 2 65 | 85 | . 3 55 | 35 | . 4 80 | 60 | . ... ... | ... | . 195 55 | 70 | . 196 65 | 85 | . 197 85 | 85 | . 198 80 | 65 | . 199 50 | 95 | . 200 rows × 2 columns . - 예시4: dct에서 불가능하지만 df에서 가능한것도 있다. (2) . dct[[&#39;att&#39;,&#39;rep&#39;]] . TypeError Traceback (most recent call last) /tmp/ipykernel_1457577/2053155993.py in &lt;module&gt; -&gt; 1 dct[[&#39;att&#39;,&#39;rep&#39;]] TypeError: unhashable type: &#39;list&#39; . df[[&#39;att&#39;,&#39;rep&#39;]] . att rep . 0 65 | 45 | . 1 95 | 30 | . 2 65 | 85 | . 3 55 | 35 | . 4 80 | 60 | . ... ... | ... | . 195 55 | 70 | . 196 65 | 85 | . 197 85 | 85 | . 198 80 | 65 | . 199 50 | 95 | . 200 rows × 2 columns . # row indexing . - 예시5: dct에서 불가능하지만 df에서 가능한것도 있다. (3) . dct[:5] . TypeError Traceback (most recent call last) /tmp/ipykernel_1457577/3946458840.py in &lt;module&gt; -&gt; 1 dct[:5] TypeError: unhashable type: &#39;slice&#39; . df[:5] . att rep mid fin . 0 65 | 45 | 0 | 10 | . 1 95 | 30 | 60 | 10 | . 2 65 | 85 | 15 | 20 | . 3 55 | 35 | 35 | 5 | . 4 80 | 60 | 55 | 70 | . &#52968;&#49481;3: &#45336;&#54028;&#51060;&#45712;&#45196; . - 컨셉3: df.iloc은 넘파이에러이처럼 생각가능하다. 즉 아래의 arr와 같은 넘파이어레이로 생각가능하다. . arr = np.array(df) #arr . # row indexing . - 예시1: 단일레이블 . arr[0,:] # first row arr[0,] arr[0] . array([65, 45, 0, 10]) . df.iloc[0,:] # first row df.iloc[0,] df.iloc[0] . att 65 rep 45 mid 0 fin 10 Name: 0, dtype: int64 . - 예시2: 레이블의 리스트 . arr[[0,1,2],:] # 처음 3개의 row 선택 arr[[0,1,2],] arr[[0,1,2]] . array([[65, 45, 0, 10], [95, 30, 60, 10], [65, 85, 15, 20]]) . df.iloc[[0,1,2],:] # 처음 3개의 row 선택 df.iloc[[0,1,2],] df.iloc[[0,1,2]] . att rep mid fin . 0 65 | 45 | 0 | 10 | . 1 95 | 30 | 60 | 10 | . 2 65 | 85 | 15 | 20 | . - 예시3: 슬랑이싱 . arr[0:3,:] # 처음 3개의 row선택, 끝점포함X arr[0:3,] arr[0:3] . array([[65, 45, 0, 10], [95, 30, 60, 10], [65, 85, 15, 20]]) . df.iloc[0:3,:] # 처음 3개의 row선택, 끝점포함X df.iloc[0:3,] df.iloc[0:3] . att rep mid fin . 0 65 | 45 | 0 | 10 | . 1 95 | 30 | 60 | 10 | . 2 65 | 85 | 15 | 20 | . # col indexing . - 예시1: 단일레이블 . df.iloc[:,0] # first column # arr[:,0] # first column . 0 65 1 95 2 65 3 55 4 80 .. 195 55 196 65 197 85 198 80 199 50 Name: att, Length: 200, dtype: int64 . - 예시2: 레이블의 리스트 . df.iloc[:,[0,2]] # col1, col3 을 선택 # arr[:,[0,2]] # col1, col3 을 선택 . att mid . 0 65 | 0 | . 1 95 | 60 | . 2 65 | 15 | . 3 55 | 35 | . 4 80 | 55 | . ... ... | ... | . 195 55 | 40 | . 196 65 | 25 | . 197 85 | 100 | . 198 80 | 35 | . 199 50 | 45 | . 200 rows × 2 columns . - 예시3: 슬랑이싱 . df.iloc[:,0:3] # 처음 3개의 col선택, 끝점포함X #arr[:,0:3] . att rep mid . 0 65 | 45 | 0 | . 1 95 | 30 | 60 | . 2 65 | 85 | 15 | . 3 55 | 35 | 35 | . 4 80 | 60 | 55 | . ... ... | ... | ... | . 195 55 | 70 | 40 | . 196 65 | 85 | 25 | . 197 85 | 85 | 100 | . 198 80 | 65 | 35 | . 199 50 | 95 | 45 | . 200 rows × 3 columns . # row + col indexing . df.iloc[::2,0:3] . att rep mid . 0 65 | 45 | 0 | . 2 65 | 85 | 15 | . 4 80 | 60 | 55 | . 6 65 | 70 | 60 | . 8 95 | 55 | 65 | . ... ... | ... | ... | . 190 95 | 35 | 40 | . 192 100 | 40 | 80 | . 194 65 | 40 | 65 | . 196 65 | 85 | 25 | . 198 80 | 65 | 35 | . 100 rows × 3 columns . &#52968;&#49481;4: &#45936;&#51060;&#53552;&#54532;&#47112;&#51076; &#45712;&#45196; . - 컨셉4: df.loc은 새로운 느낌.. (R에 익숙하면 df.loc이 dataframe 혹은 티블느낌이라고 보시면 됩니다) . import rpy2 %load_ext rpy2.ipython . %%R library(tidyverse) mpg[1:5,c(&#39;model&#39;,&#39;year&#39;)] . # A tibble: 5 × 2 model year &lt;chr&gt; &lt;int&gt; 1 a4 1999 2 a4 1999 3 a4 2008 4 a4 2008 5 a4 1999 . # row indexing . - 예시1: 단일레이블 . df.loc[0,:] # 첫번째 row를 선택 df.loc[0,] df.loc[0] . att 65 rep 45 mid 0 fin 10 Name: 0, dtype: int64 . - 예시2: 레이블의 리스트 . df.loc[[0,1,2],:] # 처음 3개의 row를 선택 df.loc[[0,1,2],] df.loc[[0,1,2]] . att rep mid fin . 0 65 | 45 | 0 | 10 | . 1 95 | 30 | 60 | 10 | . 2 65 | 85 | 15 | 20 | . - 예시3: 슬라이싱 (끝점포함 O) . df.loc[0:3,:] # 처음 4개의 row를 선택, 끝점포함 df.loc[0:3,] df.loc[0:3] . att rep mid fin . 0 65 | 45 | 0 | 10 | . 1 95 | 30 | 60 | 10 | . 2 65 | 85 | 15 | 20 | . 3 55 | 35 | 35 | 5 | . # col indexing . - 예시1: 단일레이블 . df.loc[:,&#39;att&#39;] . 0 65 1 95 2 65 3 55 4 80 .. 195 55 196 65 197 85 198 80 199 50 Name: att, Length: 200, dtype: int64 . - 예시2: 레이블의 리스트 . df.loc[:,[&#39;att&#39;,&#39;mid&#39;]] . att mid . 0 65 | 0 | . 1 95 | 60 | . 2 65 | 15 | . 3 55 | 35 | . 4 80 | 55 | . ... ... | ... | . 195 55 | 40 | . 196 65 | 25 | . 197 85 | 100 | . 198 80 | 35 | . 199 50 | 45 | . 200 rows × 2 columns . - 예시3: 슬라이싱 (끝점포함 O) . df.loc[:,&#39;att&#39;:&#39;mid&#39;] # 끝점포함 . att rep mid . 0 65 | 45 | 0 | . 1 95 | 30 | 60 | . 2 65 | 85 | 15 | . 3 55 | 35 | 35 | . 4 80 | 60 | 55 | . ... ... | ... | ... | . 195 55 | 70 | 40 | . 196 65 | 85 | 25 | . 197 85 | 85 | 100 | . 198 80 | 65 | 35 | . 199 50 | 95 | 45 | . 200 rows × 3 columns . # row + col indexing . df.loc[::-1,&#39;att&#39;:&#39;mid&#39;] # 끝점포함 . att rep mid . 199 50 | 95 | 45 | . 198 80 | 65 | 35 | . 197 85 | 85 | 100 | . 196 65 | 85 | 25 | . 195 55 | 70 | 40 | . ... ... | ... | ... | . 4 80 | 60 | 55 | . 3 55 | 35 | 35 | . 2 65 | 85 | 15 | . 1 95 | 30 | 60 | . 0 65 | 45 | 0 | . 200 rows × 3 columns . &#52968;&#49481;1~4 &#51221;&#47532; . . [] .iloc .loc . row/단일레이블 | X | X | O | O | . col/단일레이블 | O | O | O | O | . row/레이블리스트 | X | X | O | O | . col/레이블리스트 | X | O | O | O | . row/슬라이싱 | X | O | O | O | . col/슬라이싱 | X | X | O | O | . - col 이름을 알아야하는 부담감 . . : 앞글자만 대충 알아도 자동완성 가능 | []: 정확한 col 이름을 알아야 함 | .loc: 보통 정확한 col 이름을 알아야 하지만 슬라이싱 이용시 양 끝의 컬럼이름만 알면 무방 | .iloc: 정확한 col 이름을 몰라도 번호로 인덱싱 가능 | . - 자주하는 실수 . df[&#39;att&#39;] # 가능 # df.loc[&#39;att&#39;] # 불가능 df.loc[:,&#39;att&#39;] # 가능 . 0 65 1 95 2 65 3 55 4 80 .. 195 55 196 65 197 85 198 80 199 50 Name: att, Length: 200, dtype: int64 . df: &#51064;&#45937;&#49905; 2&#45800;&#44228;-- &#54596;&#53552;&#47553;(&#53945;&#51221;&#51312;&#44148;&#50640; &#47582;&#45716; row&#47484; &#49440;&#53469;) . att &gt; 90 and rep &lt; 50 . - 방법1: .query()를 이용 . df.query(&#39;att&gt;90 and rep&lt;50&#39;) . att rep mid fin . 1 95 | 30 | 60 | 10 | . 12 95 | 35 | 0 | 25 | . 48 95 | 45 | 35 | 80 | . 56 95 | 25 | 95 | 90 | . 78 95 | 45 | 90 | 35 | . 107 100 | 30 | 60 | 65 | . 112 100 | 35 | 70 | 0 | . 113 95 | 45 | 55 | 65 | . 163 100 | 25 | 10 | 20 | . 174 100 | 40 | 40 | 15 | . 176 100 | 30 | 70 | 70 | . 184 100 | 30 | 30 | 85 | . 190 95 | 35 | 40 | 95 | . 192 100 | 40 | 80 | 80 | . df.query(&#39;(att&gt;90)&amp;(rep&lt;50)&#39;) . att rep mid fin . 1 95 | 30 | 60 | 10 | . 12 95 | 35 | 0 | 25 | . 48 95 | 45 | 35 | 80 | . 56 95 | 25 | 95 | 90 | . 78 95 | 45 | 90 | 35 | . 107 100 | 30 | 60 | 65 | . 112 100 | 35 | 70 | 0 | . 113 95 | 45 | 55 | 65 | . 163 100 | 25 | 10 | 20 | . 174 100 | 40 | 40 | 15 | . 176 100 | 30 | 70 | 70 | . 184 100 | 30 | 30 | 85 | . 190 95 | 35 | 40 | 95 | . 192 100 | 40 | 80 | 80 | . df.query(&#39;att&gt;90 &amp; rep&lt;50&#39;) . att rep mid fin . 1 95 | 30 | 60 | 10 | . 12 95 | 35 | 0 | 25 | . 48 95 | 45 | 35 | 80 | . 56 95 | 25 | 95 | 90 | . 78 95 | 45 | 90 | 35 | . 107 100 | 30 | 60 | 65 | . 112 100 | 35 | 70 | 0 | . 113 95 | 45 | 55 | 65 | . 163 100 | 25 | 10 | 20 | . 174 100 | 40 | 40 | 15 | . 176 100 | 30 | 70 | 70 | . 184 100 | 30 | 30 | 85 | . 190 95 | 35 | 40 | 95 | . 192 100 | 40 | 80 | 80 | . - 방법2: [], .iloc, .loc . df[(df.att &gt; 90)&amp;(df.rep &lt; 50)] df.loc[(df.att &gt; 90)&amp;(df.rep &lt; 50)] df.iloc[list((df.att &gt; 90)&amp;(df.rep &lt; 50))] . att rep mid fin . 1 95 | 30 | 60 | 10 | . 12 95 | 35 | 0 | 25 | . 48 95 | 45 | 35 | 80 | . 56 95 | 25 | 95 | 90 | . 78 95 | 45 | 90 | 35 | . 107 100 | 30 | 60 | 65 | . 112 100 | 35 | 70 | 0 | . 113 95 | 45 | 55 | 65 | . 163 100 | 25 | 10 | 20 | . 174 100 | 40 | 40 | 15 | . 176 100 | 30 | 70 | 70 | . 184 100 | 30 | 30 | 85 | . 190 95 | 35 | 40 | 95 | . 192 100 | 40 | 80 | 80 | . - 방법3: [], .iloc, .loc // map, lambda . df[list(map(lambda x,y: (x&gt;90)&amp;(y&lt;50), df.att, df.rep))] # df[map(lambda x,y: (x&gt;90)&amp;(y&lt;50), df.att, df.rep)] # 이것은 불가능 . att rep mid fin . 1 95 | 30 | 60 | 10 | . 12 95 | 35 | 0 | 25 | . 48 95 | 45 | 35 | 80 | . 56 95 | 25 | 95 | 90 | . 78 95 | 45 | 90 | 35 | . 107 100 | 30 | 60 | 65 | . 112 100 | 35 | 70 | 0 | . 113 95 | 45 | 55 | 65 | . 163 100 | 25 | 10 | 20 | . 174 100 | 40 | 40 | 15 | . 176 100 | 30 | 70 | 70 | . 184 100 | 30 | 30 | 85 | . 190 95 | 35 | 40 | 95 | . 192 100 | 40 | 80 | 80 | . df.iloc[list(map(lambda x,y: (x&gt;90)&amp;(y&lt;50), df.att, df.rep))] df.iloc[map(lambda x,y: (x&gt;90)&amp;(y&lt;50), df.att, df.rep)] . att rep mid fin . 1 95 | 30 | 60 | 10 | . 12 95 | 35 | 0 | 25 | . 48 95 | 45 | 35 | 80 | . 56 95 | 25 | 95 | 90 | . 78 95 | 45 | 90 | 35 | . 107 100 | 30 | 60 | 65 | . 112 100 | 35 | 70 | 0 | . 113 95 | 45 | 55 | 65 | . 163 100 | 25 | 10 | 20 | . 174 100 | 40 | 40 | 15 | . 176 100 | 30 | 70 | 70 | . 184 100 | 30 | 30 | 85 | . 190 95 | 35 | 40 | 95 | . 192 100 | 40 | 80 | 80 | . df.loc[list(map(lambda x,y: (x&gt;90)&amp;(y&lt;50), df.att, df.rep))] df.loc[map(lambda x,y: (x&gt;90)&amp;(y&lt;50), df.att, df.rep)] . att rep mid fin . 1 95 | 30 | 60 | 10 | . 12 95 | 35 | 0 | 25 | . 48 95 | 45 | 35 | 80 | . 56 95 | 25 | 95 | 90 | . 78 95 | 45 | 90 | 35 | . 107 100 | 30 | 60 | 65 | . 112 100 | 35 | 70 | 0 | . 113 95 | 45 | 55 | 65 | . 163 100 | 25 | 10 | 20 | . 174 100 | 40 | 40 | 15 | . 176 100 | 30 | 70 | 70 | . 184 100 | 30 | 30 | 85 | . 190 95 | 35 | 40 | 95 | . 192 100 | 40 | 80 | 80 | . att &gt; mean(att) . - 방법1: .query()를 이용 . df.query(&#39;att&gt; att.mean()&#39;) . att rep mid fin . 1 95 | 30 | 60 | 10 | . 4 80 | 60 | 55 | 70 | . 8 95 | 55 | 65 | 90 | . 9 90 | 25 | 95 | 50 | . 11 95 | 60 | 25 | 55 | . ... ... | ... | ... | ... | . 184 100 | 30 | 30 | 85 | . 190 95 | 35 | 40 | 95 | . 192 100 | 40 | 80 | 80 | . 197 85 | 85 | 100 | 10 | . 198 80 | 65 | 35 | 60 | . 95 rows × 4 columns . - 방법2: [], .iloc, .loc . df[df.att &gt; df.att.mean()] df.loc[df.att &gt; df.att.mean()] df.iloc[list(df.att &gt; df.att.mean())] . att rep mid fin . 1 95 | 30 | 60 | 10 | . 4 80 | 60 | 55 | 70 | . 8 95 | 55 | 65 | 90 | . 9 90 | 25 | 95 | 50 | . 11 95 | 60 | 25 | 55 | . ... ... | ... | ... | ... | . 184 100 | 30 | 30 | 85 | . 190 95 | 35 | 40 | 95 | . 192 100 | 40 | 80 | 80 | . 197 85 | 85 | 100 | 10 | . 198 80 | 65 | 35 | 60 | . 95 rows × 4 columns . - 방법3: [], .iloc, .loc // map, lambda . df[list(map(lambda x: x&gt;df.att.mean() , df.att))] # df[map(lambda x: x&gt;df.att.mean() , df.att)] # 이것은 불가능 . att rep mid fin . 1 95 | 30 | 60 | 10 | . 4 80 | 60 | 55 | 70 | . 8 95 | 55 | 65 | 90 | . 9 90 | 25 | 95 | 50 | . 11 95 | 60 | 25 | 55 | . ... ... | ... | ... | ... | . 184 100 | 30 | 30 | 85 | . 190 95 | 35 | 40 | 95 | . 192 100 | 40 | 80 | 80 | . 197 85 | 85 | 100 | 10 | . 198 80 | 65 | 35 | 60 | . 95 rows × 4 columns . df.iloc[list(map(lambda x: x&gt;df.att.mean() , df.att))] df.iloc[map(lambda x: x&gt;df.att.mean() , df.att)] . att rep mid fin . 1 95 | 30 | 60 | 10 | . 4 80 | 60 | 55 | 70 | . 8 95 | 55 | 65 | 90 | . 9 90 | 25 | 95 | 50 | . 11 95 | 60 | 25 | 55 | . ... ... | ... | ... | ... | . 184 100 | 30 | 30 | 85 | . 190 95 | 35 | 40 | 95 | . 192 100 | 40 | 80 | 80 | . 197 85 | 85 | 100 | 10 | . 198 80 | 65 | 35 | 60 | . 95 rows × 4 columns . df.loc[list(map(lambda x: x&gt;df.att.mean() , df.att))] df.loc[map(lambda x: x&gt;df.att.mean() , df.att)] . att rep mid fin . 1 95 | 30 | 60 | 10 | . 4 80 | 60 | 55 | 70 | . 8 95 | 55 | 65 | 90 | . 9 90 | 25 | 95 | 50 | . 11 95 | 60 | 25 | 55 | . ... ... | ... | ... | ... | . 184 100 | 30 | 30 | 85 | . 190 95 | 35 | 40 | 95 | . 192 100 | 40 | 80 | 80 | . 197 85 | 85 | 100 | 10 | . 198 80 | 65 | 35 | 60 | . 95 rows × 4 columns . . [] .iloc .loc . row/단일레이블 | X | X | O | O | . col/단일레이블 | O | O | O | O | . row/레이블리스트 | X | X | O | O | . col/레이블리스트 | X | O | O | O | . row/슬라이싱 | X | O | O | O | . col/슬라이싱 | X | X | O | O | . row/bool,list | X | O | O | O | . row/bool,ser | X | O | X | O | . row/bool,map | X | X | O | O | . &#49689;&#51228; . 1. 10&#50900;12&#51068; &#49689;&#51228; . 아래와 같이 0~9까지 포함된 리스트를 만들어라 . x=list(range(10)) x . [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] . 아래와 동일한 기능을 수행하는 함수를 lambda expression으로 정의하라. . def f(xi): return &#39;짝&#39; if (xi % 2)==0 else &#39;홀&#39; . map과 lambda expression 을 이용하여 아래와 같은 결과를 만들어라. (리스트컴프리헨션, for문 사용금지) . # 구현예시 . [&#39;짝&#39;, &#39;홀&#39;, &#39;짝&#39;, &#39;홀&#39;, &#39;짝&#39;, &#39;홀&#39;, &#39;짝&#39;, &#39;홀&#39;, &#39;짝&#39;, &#39;홀&#39;] . 2. 10&#50900;14&#51068; &#49689;&#51228; . 다음과 같은 데이터프레임을 불러온 뒤 물음에 답하라 . df=pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/DV2022/master/_notebooks/dv2022.csv&#39;) df . att rep mid fin . 0 65 | 45 | 0 | 10 | . 1 95 | 30 | 60 | 10 | . 2 65 | 85 | 15 | 20 | . 3 55 | 35 | 35 | 5 | . 4 80 | 60 | 55 | 70 | . ... ... | ... | ... | ... | . 195 55 | 70 | 40 | 95 | . 196 65 | 85 | 25 | 85 | . 197 85 | 85 | 100 | 10 | . 198 80 | 65 | 35 | 60 | . 199 50 | 95 | 45 | 85 | . 200 rows × 4 columns . (1) 기말고사 성적이 중간고사 성적보다 향상된 학생들을 출력하라. 즉 mid &lt; fin 인 학생들을 출력하라. (다양한 방법으로 연습할 것, 제출은 한 가지 방법으로 구현해도 감점없음) . # 구현결과가 아래와 같아야 한다. . att rep mid fin . 0 65 | 45 | 0 | 10 | . 2 65 | 85 | 15 | 20 | . 4 80 | 60 | 55 | 70 | . 5 75 | 40 | 75 | 85 | . 6 65 | 70 | 60 | 75 | . ... ... | ... | ... | ... | . 194 65 | 40 | 65 | 70 | . 195 55 | 70 | 40 | 95 | . 196 65 | 85 | 25 | 85 | . 198 80 | 65 | 35 | 60 | . 199 50 | 95 | 45 | 85 | . 93 rows × 4 columns . (2) 기말고사 성적이 중간고사 성적보다 향상된 학생들의 출석과 레포트 점수를 출력하라. . # 구현결과가 아래와 같아야 한다. . att rep . 0 65 | 45 | . 2 65 | 85 | . 4 80 | 60 | . 5 75 | 40 | . 6 65 | 70 | . ... ... | ... | . 194 65 | 40 | . 195 55 | 70 | . 196 65 | 85 | . 198 80 | 65 | . 199 50 | 95 | . 93 rows × 2 columns .",
            "url": "https://guebin.github.io/DV2022/2022/10/12/(6%EC%A3%BC%EC%B0%A8)-10%EC%9B%9412%EC%9D%BC.html",
            "relUrl": "/2022/10/12/(6%EC%A3%BC%EC%B0%A8)-10%EC%9B%9412%EC%9D%BC.html",
            "date": " • Oct 12, 2022"
        }
        
    
  
    
        ,"post8": {
            "title": "(5주차) 10월6일 -- 10월3일 강의에 대한 보충",
            "content": "&#44053;&#51032;&#50689;&#49345; . . imports . import numpy as np import pandas as pd import matplotlib.pyplot as plt import seaborn as sns from plotnine import * . &#54988;&#47469;&#54620; &#49884;&#44033;&#54868;&#46976;? . &#50528;&#46300;&#50892;&#46300; &#53552;&#54532;&#54000; . - 데이터 시각화계의 거장 . - 터프티의 이론중 백미: 엄격한 미니멀리즘 . 최소한의 잉크로 많은 정보를 전달할 수 있다면 그것이 바로 좋은 그래프이다. | 작은 지면 내에서 잉크를 최대한 적게 써서 짧은 시간 안에 많은 영감을 주어야 한다. | . - 데이터-잉크비: 데이터를 표현하는데 들아가는 잉크의 양 / 그래픽을 인쇄하는데 들어가는 잉크의 총량 . - 차트정크 (나이젤홈즈의 그래프) . . “Lurking behind chartjunk is contempt both for information and for the audience. Chartjunk promoters imagine that numbers and details are boring, dull, and tedious, requiring ornament to enliven. Cosmetic decoration, which frequently distorts the data, will never salvage an underlying lack of content. If the numbers are boring, then you’ve got the wrong numbers (...) Worse is contempt for our audience, designing as if readers were obtuse and uncaring. In fact, consumers of graphics are often more intelligent about the information at hand than those who fabricate the data decoration (...) The operating moral premise of information design should be that our readers are alert and caring; they may be busy, eager to get on with it, but they are not stupid.” . 차트정크 = 대중을 멸시 + 데이터에 대한 모독 | 차트정크 옹호가는 숫자와 데이터가 지루하여 활기가 필요하다고 생각하는 모양이다.. | . - 별로인 그래프 (왼쪽) / 우수한 그래프 오른쪽 . . - 별로인 그래프 (왼쪽) / 우수한 그래프 오른쪽 . . - 별로인 그래프 (왼쪽) / 우수한 그래프 오른쪽 . . - 제 생각: 글쎄... . &#52272;&#49828;&#48120;&#45208;&#46300;&#51032; &#46020;&#54364; . 인류역사상 가장 훌륭한 시각화 | . . - 터프티의 평 . 지금까지 그려진 최고의 통계 그래픽일지도 모른다. | 여기에서는 군대의 크기, 2차원 평면상의 위치, 군대의 이동방향, 모스코바에서 퇴각하는 동안의 여러날짜, 온도 $ to$ 6차원의 변수 | 백만번에 한번 이런 그림을 그릴수는 있겠지만 이러한 멋진 그래픽을 만드는 방법에 대한 원칙은 없다. $ to$ 미니멀리즘.. | . - 왜 우수한 그래프일까? . 자료를 파악하는 기법은 최근까지도 산점도, 막대그래프, 라인플랏에 의존 | 이러한 플랏의 단점은 고차원의 자료를 분석하기 어렵다는 것임 | 미나드는 여러그램을 그리는 방법 대신에 한 그림에서 패널을 늘리는 방법을 선택함. | . &#48120;&#45208;&#46300;&#52376;&#47100; &#44536;&#47532;&#45716;&#44172; &#50780; &#50612;&#47140;&#50868;&#44032;? . - 몸무게, 키, 성별, 국적 . df1=pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/DV2022/master/_notebooks/male1.csv&#39;) df2=pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/DV2022/master/_notebooks/male2.csv&#39;) df3=pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/DV2022/master/_notebooks/female.csv&#39;) df4=pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/DV2022/master/_notebooks/foreign.csv&#39;) . - 미나드의 접근방법 . _df = pd.concat([pd.concat([df1,df2],axis=1).assign(g=&#39;m&#39;),df3.assign(g=&#39;f&#39;)]) df = pd.concat([_df.assign(g2=&#39;korea&#39;),df4.assign(g2=&#39;foreign&#39;)]).reset_index(drop=True) df . w h g g2 . 0 72.788217 | 183.486773 | m | korea | . 1 66.606430 | 173.599877 | m | korea | . 2 69.806324 | 173.237903 | m | korea | . 3 67.449439 | 173.223805 | m | korea | . 4 70.463183 | 174.931946 | m | korea | . ... ... | ... | ... | ... | . 1525 78.154632 | 188.324350 | m | foreign | . 1526 74.754308 | 183.017979 | f | foreign | . 1527 91.196208 | 190.100456 | m | foreign | . 1528 87.770394 | 187.987255 | m | foreign | . 1529 88.021995 | 193.456798 | m | foreign | . 1530 rows × 4 columns . sns.scatterplot(data=df,x=&#39;w&#39;,y=&#39;h&#39;,hue=&#39;g&#39;,style=&#39;g2&#39;) . &lt;AxesSubplot:xlabel=&#39;w&#39;, ylabel=&#39;h&#39;&gt; . - 어려운점: (1) 센스가 없어서 hue/style을 이용하여 그룹을 구분할 생각을 못함 (2) long df (=tidy data) 형태로 데이터를 정리할 생각을 못함 (3) long df 형태로 데이터를 변형하는 코드를 모름 . (1) 기획력부족 -&gt; 훌륭한 시각화를 많이 볼 것 | (2) 데이터프레임에 대한 이해부족 -&gt; tidydata에 대한 개념 | (3) 프로그래밍 능력 -&gt; 코딩공부열심히 (pandas를 엄청 잘해야함) | . read mpg data . - ref: https://r4ds.had.co.nz/index.html . &#48169;&#48277;1: rpy2 (&#53076;&#47017; &#50500;&#45772;&#44221;&#50864; &#49892;&#49845;&#44552;&#51648;) . import rpy2 %load_ext rpy2.ipython . %%R ### 여기는 R처럼 쓸 수 있다. a &lt;- c(1,2,3) a+1 . [1] 2 3 4 . a . NameError Traceback (most recent call last) /tmp/ipykernel_1214567/2167009006.py in &lt;module&gt; -&gt; 1 a NameError: name &#39;a&#39; is not defined . %%R library(tidyverse) mpg . # A tibble: 234 × 11 manufacturer model displ year cyl trans drv cty hwy fl class &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; 1 audi a4 1.8 1999 4 auto… f 18 29 p comp… 2 audi a4 1.8 1999 4 manu… f 21 29 p comp… 3 audi a4 2 2008 4 manu… f 20 31 p comp… 4 audi a4 2 2008 4 auto… f 21 30 p comp… 5 audi a4 2.8 1999 6 auto… f 16 26 p comp… 6 audi a4 2.8 1999 6 manu… f 18 26 p comp… 7 audi a4 3.1 2008 6 auto… f 18 27 p comp… 8 audi a4 quattro 1.8 1999 4 manu… 4 18 26 p comp… 9 audi a4 quattro 1.8 1999 4 auto… 4 16 25 p comp… 10 audi a4 quattro 2 2008 4 manu… 4 20 28 p comp… # … with 224 more rows # ℹ Use `print(n = ...)` to see more rows . mpg . NameError Traceback (most recent call last) /tmp/ipykernel_1214567/602803287.py in &lt;module&gt; -&gt; 1 mpg NameError: name &#39;mpg&#39; is not defined . %R -o mpg # R에 있는 자료가 파이썬으로 넘어옴 . mpg . manufacturer model displ year cyl trans drv cty hwy fl class . 1 audi | a4 | 1.8 | 1999 | 4 | auto(l5) | f | 18 | 29 | p | compact | . 2 audi | a4 | 1.8 | 1999 | 4 | manual(m5) | f | 21 | 29 | p | compact | . 3 audi | a4 | 2.0 | 2008 | 4 | manual(m6) | f | 20 | 31 | p | compact | . 4 audi | a4 | 2.0 | 2008 | 4 | auto(av) | f | 21 | 30 | p | compact | . 5 audi | a4 | 2.8 | 1999 | 6 | auto(l5) | f | 16 | 26 | p | compact | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 230 volkswagen | passat | 2.0 | 2008 | 4 | auto(s6) | f | 19 | 28 | p | midsize | . 231 volkswagen | passat | 2.0 | 2008 | 4 | manual(m6) | f | 21 | 29 | p | midsize | . 232 volkswagen | passat | 2.8 | 1999 | 6 | auto(l5) | f | 16 | 26 | p | midsize | . 233 volkswagen | passat | 2.8 | 1999 | 6 | manual(m5) | f | 18 | 26 | p | midsize | . 234 volkswagen | passat | 3.6 | 2008 | 6 | auto(s6) | f | 17 | 26 | p | midsize | . 234 rows × 11 columns . &#48169;&#48277;2: &#51200;&#51109;&#46108; csv&#54028;&#51068;&#51012; &#53685;&#54616;&#50668; &#45936;&#51060;&#53552;&#47484; &#54869;&#48372; . mpg.to_csv(&quot;mpg.csv&quot;,index=False) . pd.read_csv(&quot;mpg.csv&quot;) . manufacturer model displ year cyl trans drv cty hwy fl class . 0 audi | a4 | 1.8 | 1999 | 4 | auto(l5) | f | 18 | 29 | p | compact | . 1 audi | a4 | 1.8 | 1999 | 4 | manual(m5) | f | 21 | 29 | p | compact | . 2 audi | a4 | 2.0 | 2008 | 4 | manual(m6) | f | 20 | 31 | p | compact | . 3 audi | a4 | 2.0 | 2008 | 4 | auto(av) | f | 21 | 30 | p | compact | . 4 audi | a4 | 2.8 | 1999 | 6 | auto(l5) | f | 16 | 26 | p | compact | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 229 volkswagen | passat | 2.0 | 2008 | 4 | auto(s6) | f | 19 | 28 | p | midsize | . 230 volkswagen | passat | 2.0 | 2008 | 4 | manual(m6) | f | 21 | 29 | p | midsize | . 231 volkswagen | passat | 2.8 | 1999 | 6 | auto(l5) | f | 16 | 26 | p | midsize | . 232 volkswagen | passat | 2.8 | 1999 | 6 | manual(m5) | f | 18 | 26 | p | midsize | . 233 volkswagen | passat | 3.6 | 2008 | 6 | auto(s6) | f | 17 | 26 | p | midsize | . 234 rows × 11 columns . &#48169;&#48277;3: github&#46321;&#50640; &#44277;&#44060;&#46108; csv&#47484; &#51069;&#50612;&#50724;&#44592; . pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/DV2022/master/_notebooks/mpg.csv&#39;) . manufacturer model displ year cyl trans drv cty hwy fl class . 0 audi | a4 | 1.8 | 1999 | 4 | auto(l5) | f | 18 | 29 | p | compact | . 1 audi | a4 | 1.8 | 1999 | 4 | manual(m5) | f | 21 | 29 | p | compact | . 2 audi | a4 | 2.0 | 2008 | 4 | manual(m6) | f | 20 | 31 | p | compact | . 3 audi | a4 | 2.0 | 2008 | 4 | auto(av) | f | 21 | 30 | p | compact | . 4 audi | a4 | 2.8 | 1999 | 6 | auto(l5) | f | 16 | 26 | p | compact | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 229 volkswagen | passat | 2.0 | 2008 | 4 | auto(s6) | f | 19 | 28 | p | midsize | . 230 volkswagen | passat | 2.0 | 2008 | 4 | manual(m6) | f | 21 | 29 | p | midsize | . 231 volkswagen | passat | 2.8 | 1999 | 6 | auto(l5) | f | 16 | 26 | p | midsize | . 232 volkswagen | passat | 2.8 | 1999 | 6 | manual(m5) | f | 18 | 26 | p | midsize | . 233 volkswagen | passat | 3.6 | 2008 | 6 | auto(s6) | f | 17 | 26 | p | midsize | . 234 rows × 11 columns . - 깃허브 저장소에 아예 데이터만 따로 모아서 관리하는 것도 좋은 방법입니다. . data &#49444;&#47749; . - displ: 자동차의 엔진크기 . - hwy: 연료의 효율, 동일한 연료로 얼마나 멀리 가느냐? . - 자세한 설명은 R에서 ?mpg를 이용해 스스로 찾아볼 것 . p9&#47484; &#51060;&#50857;&#54620; &#49328;&#51216;&#46020; (2&#52264;&#50896;) . python&#50640;&#49436;: plotnine&#51012; &#51060;&#50857;&#54620; &#49328;&#51216;&#46020; . ggplot(data=mpg) + geom_point(mapping=aes(x=&#39;displ&#39;,y=&#39;hwy&#39;)) ## plotnine . &lt;ggplot: (8726736046009)&gt; . 산점도 해석: 엔진크기가 클수록 효율이 낮음. | . - 빠르게 그리기: data=와 mapping=은 생략가능함 . ggplot(mpg) + geom_point(aes(x=&#39;displ&#39;,y=&#39;hwy&#39;)) ## plotnine . &lt;ggplot: (8726735544581)&gt; . R&#50640;&#49436;: ggplot2&#47484; &#51060;&#50857;&#54620; &#49328;&#51216;&#46020; . - R에서도 거의 똑같은 문법으로 그릴 수 있음 (데이터프레임 혹은 티블에 저장된 column 이름을 사용할때 따옴표만 제거하면 된다!) . %%R -w 800 ggplot(mpg) + geom_point(aes(x=displ,y=hwy)) ## plotnine . python&#50640;&#49436;: &#44061;&#52404;&#51648;&#54693;&#51201;&#51064; &#45712;&#45196;&#51004;&#47196; &#49328;&#51216;&#46020; &#44536;&#47532;&#44592; . step1: 도화지를 준비한다. . fig = ggplot(data=mpg) fig . &lt;ggplot: (8726735085529)&gt; . step2 변수와 에스테틱사이의 맵핑을 설정한다. . a1= aes(x=&#39;displ&#39;,y=&#39;hwy&#39;) a1 . {&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;} . step3 점들의 집합을 만든다. 즉 포인트 지옴을 만든다. . point1=geom_point(mapping=a1) . geom_point(): 점들을 그려! 어떻게? | a1에서 설정된 표를 보고 | . step4 도화지와 지옴을 합친다. . fig+point1 . &lt;ggplot: (8726775447877)&gt; . p9&#47484; &#51060;&#50857;&#54620; &#49328;&#51216;&#46020; (3&#52264;&#50896;) . - 데이터를 다시 관찰 . mpg.head() . manufacturer model displ year cyl trans drv cty hwy fl class . 1 audi | a4 | 1.8 | 1999 | 4 | auto(l5) | f | 18 | 29 | p | compact | . 2 audi | a4 | 1.8 | 1999 | 4 | manual(m5) | f | 21 | 29 | p | compact | . 3 audi | a4 | 2.0 | 2008 | 4 | manual(m6) | f | 20 | 31 | p | compact | . 4 audi | a4 | 2.0 | 2008 | 4 | auto(av) | f | 21 | 30 | p | compact | . 5 audi | a4 | 2.8 | 1999 | 6 | auto(l5) | f | 16 | 26 | p | compact | . - class도 함께 plot에 표시하면 데이터를 탐색할때 좀 더 좋을 것 같다. . &#49328;&#51216;&#46020; + &#51216;&#53356;&#44592;&#48320;&#44221; . ggplot(data=mpg) + geom_point(mapping = aes(x=&#39;displ&#39;,y=&#39;hwy&#39;,size=&#39;class&#39;)) . /home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised. . &lt;ggplot: (8726734563561)&gt; . &#49328;&#51216;&#46020; + &#53804;&#47749;&#46020;&#48320;&#44221; . ggplot(data=mpg) + geom_point(mapping = aes(x=&#39;displ&#39;,y=&#39;hwy&#39;,alpha=&#39;class&#39;)) . /home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_alpha.py:70: PlotnineWarning: Using alpha for a discrete variable is not advised. . &lt;ggplot: (8726734989121)&gt; . &#49328;&#51216;&#46020; + &#53804;&#47749;&#46020;/&#51216;&#53356;&#44592;&#47484; &#46041;&#49884;&#50640; &#51201;&#50857; . ggplot(data=mpg) + geom_point(mapping = aes(x=&#39;displ&#39;,y=&#39;hwy&#39;,alpha=&#39;class&#39;,size=&#39;class&#39;)) . /home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_alpha.py:70: PlotnineWarning: Using alpha for a discrete variable is not advised. /home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised. . &lt;ggplot: (8726734522405)&gt; . &#49328;&#51216;&#46020; + &#54805;&#53468; . ggplot(data=mpg) + geom_point(mapping = aes(x=&#39;displ&#39;,y=&#39;hwy&#39;,shape=&#39;class&#39;)) . &lt;ggplot: (8726734265229)&gt; . &#49328;&#51216;&#46020; + &#49353;&#44628; . ggplot(data=mpg) + geom_point(mapping = aes(x=&#39;displ&#39;,y=&#39;hwy&#39;,color=&#39;class&#39;)) . &lt;ggplot: (8726734017473)&gt; . &#44061;&#52404;&#51648;&#54693;&#51201; &#45712;&#45196;&#51004;&#47196;? . a2 = aes(x=&#39;displ&#39;, y=&#39;hwy&#39;, color=&#39;class&#39;) . a1,a2 . ({&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;}, {&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;, &#39;color&#39;: &#39;class&#39;}) . point2=geom_point(a2) . fig+point2 . &lt;ggplot: (8726733712885)&gt; . &#49328;&#51216;&#46020; + &#49353;&#44628; + &#51201;&#54633;&#49440; . - 일단 색깔이 없는 포인트 지옴부터 연습 . fig+point1 . &lt;ggplot: (8726733452617)&gt; . line1 = geom_smooth(a1) . fig+point1+line1 . /home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. . &lt;ggplot: (8726732994973)&gt; . - point1(색깔없는 포인트 지옴)을 point2(색깔있는 포인트 지옴)으로 언제든지 바꿔치기 가능! . fig+point2+line1 . /home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. . &lt;ggplot: (8726732661565)&gt; . - 명령어로 한번에 그리기 . ggplot(data=mpg) + geom_point(mapping=aes(x=&#39;displ&#39;,y=&#39;hwy&#39;,color=&#39;class&#39;)) + geom_smooth(mapping=aes(x=&#39;displ&#39;,y=&#39;hwy&#39;)) . /home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. . &lt;ggplot: (8726732727485)&gt; . - 공통적인 맵핑규칙은 ggplot()쪽으로 빼기도 한다. (figure를 선언하는 곳에서 공통으로 선언함) . ggplot(data=mpg,mapping=aes(x=&#39;displ&#39;,y=&#39;hwy&#39;)) + geom_point(mapping=aes(color=&#39;class&#39;)) + geom_smooth() . /home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. . &lt;ggplot: (8726733489953)&gt; . - R에서는 confidence interval도 geom_smooth()를 이용하여 확인할 수 있다. . %%R -w 800 ggplot(data=mpg,mapping=aes(x=displ,y=hwy)) + geom_point(mapping=aes(color=class)) + geom_smooth() . R[write to console]: `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; . p9&#47484; &#51060;&#50857;&#54620; &#49328;&#51216;&#46020; (4&#52264;&#50896;) . - 데이터를 살펴보자. . mpg.head() . manufacturer model displ year cyl trans drv cty hwy fl class . 1 audi | a4 | 1.8 | 1999 | 4 | auto(l5) | f | 18 | 29 | p | compact | . 2 audi | a4 | 1.8 | 1999 | 4 | manual(m5) | f | 21 | 29 | p | compact | . 3 audi | a4 | 2.0 | 2008 | 4 | manual(m6) | f | 20 | 31 | p | compact | . 4 audi | a4 | 2.0 | 2008 | 4 | auto(av) | f | 21 | 30 | p | compact | . 5 audi | a4 | 2.8 | 1999 | 6 | auto(l5) | f | 16 | 26 | p | compact | . &#49328;&#51216;&#46020; + &#51216;&#53356;&#44592;&#48320;&#44221; + &#49353;&#44628; . - drv (전륜, 후륜, 4륜 구동)에 따라서 데이터를 시각화 하고 싶다. . ggplot(data=mpg, mapping=aes(x=&#39;displ&#39;,y=&#39;hwy&#39;)) + geom_point(mapping=aes(size=&#39;class&#39;,color=&#39;drv&#39;),alpha=0.3) . /home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised. . &lt;ggplot: (8726731152845)&gt; . 모든 $x$에 대하여 붉은색 점들이 대부분 초록색과 보라색 점들에 비하여 아래쪽에 있음 $ to$ 4륜구동방식이 연비가 좋지 않음 | . &#49328;&#51216;&#46020; + &#51216;&#53356;&#44592;&#48320;&#44221; + &#49353;&#44628; (&#44061;&#52404;&#51648;&#54693;&#48260;&#51204;) . - 맵핑규칙 . a1,a2 . ({&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;}, {&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;, &#39;color&#39;: &#39;class&#39;}) . a3 = a2.copy() . a3[&#39;color&#39;] = &#39;drv&#39; a3[&#39;size&#39;] = &#39;class&#39; a3 . {&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;, &#39;color&#39;: &#39;drv&#39;, &#39;size&#39;: &#39;class&#39;} . 아래와 같이 선언해도 괜찮음 a3= aes(x=&#39;displ&#39;,y=&#39;hwy&#39;,color=&#39;drv&#39;,size=&#39;class&#39;) . | . point3=geom_point(a3) . fig+point3 . /home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised. . &lt;ggplot: (8726731065581)&gt; . 그림의 전체적인 투명도를 조절하면 좋겠음 | . point3=geom_point(a3,alpha=0.2) fig+point3 . /home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised. . &lt;ggplot: (8726730819657)&gt; . &#49328;&#51216;&#46020; + &#51216;&#53356;&#44592;&#48320;&#44221; + &#49353;&#44628; + &#49440;&#52628;&#44032; . fig+point3+line1 . /home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised. /home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. . &lt;ggplot: (8726730575253)&gt; . &#49328;&#51216;&#46020; + &#51216;&#53356;&#44592;&#48320;&#44221; + &#49353;&#44628; + drv&#48324;&#47196; &#49440;&#52628;&#44032; . - 맵핑규칙 . a1,a2,a3 . ({&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;}, {&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;, &#39;color&#39;: &#39;class&#39;}, {&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;, &#39;color&#39;: &#39;drv&#39;, &#39;size&#39;: &#39;class&#39;}) . a4 = a2.copy() a4[&#39;color&#39;]=&#39;drv&#39; a4 . {&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;, &#39;color&#39;: &#39;drv&#39;} . line2 = geom_smooth(a4) . fig + point3 +line2 . /home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised. /home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. . &lt;ggplot: (8726729919385)&gt; . - 선의 색깔을 동일하게 하고 선의 타입을 변경하여 drv를 표시하고 싶다면? . a1,a2,a3,a4 . ({&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;}, {&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;, &#39;color&#39;: &#39;class&#39;}, {&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;, &#39;color&#39;: &#39;drv&#39;, &#39;size&#39;: &#39;class&#39;}, {&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;, &#39;color&#39;: &#39;drv&#39;}) . a5=a1.copy() a5[&#39;linetype&#39;]=&#39;drv&#39; a5 . {&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;, &#39;linetype&#39;: &#39;drv&#39;} . line3 = geom_smooth(a5,size=0.5,color=&#39;gray&#39;) . fig+point3+line3 . /home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised. /home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. . &lt;ggplot: (8726732637457)&gt; . - 전체적인 추세선도 추가하고 싶다면? . fig+point3+line3+line1 . /home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised. /home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. . &lt;ggplot: (8726732939513)&gt; . - 그려보니까 역시 drv별로 그려지는 추세선은 색깔별로 구분하는게 좋겠음. . line2 = geom_smooth(a4,size=0.5,linetype=&#39;dashed&#39;) fig+point3+line2+line1 . /home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised. /home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. . &lt;ggplot: (8726733678229)&gt; . - 고차원을 변수를 표현할 수 있는 무기는 다양하다. . 산점도(포인트지옴): 점의크기, 점의형태, 점의색깔, 점의투명도 | 라인플랏(스무스지옴,라인지옴): 선의형태, 선의색깔, 선의굵기 | . &#44208;&#47200; . - 잘 훈련한다면 여러가지 형태의 고차원 그래프를 우리도 그릴 수 있다. (마치 미나드처럼) . - 해들리위컴은 이러한 방법을 체계적으로 정리했다고 보여진다. . - 해들리위컴: 그래프는 데이터 + 지옴 + 맵핑(변수와 에스테틱간의 연결) + 스탯(통계) + 포지션 + 축 + 패싯그리드 7개의 조합으로 그릴 수 있다. . 내생각: 지옴과 맵핑만 잘 다루어도 아주 다양한 그래프를 그릴 수 있음. | .",
            "url": "https://guebin.github.io/DV2022/2022/10/06/(5%EC%A3%BC%EC%B0%A8)-10%EC%9B%946%EC%9D%BC-10%EC%9B%943%EC%9D%BC%EA%B0%95%EC%9D%98%EC%97%90-%EB%8C%80%ED%95%9C%EB%B3%B4%EC%B6%A9.html",
            "relUrl": "/2022/10/06/(5%EC%A3%BC%EC%B0%A8)-10%EC%9B%946%EC%9D%BC-10%EC%9B%943%EC%9D%BC%EA%B0%95%EC%9D%98%EC%97%90-%EB%8C%80%ED%95%9C%EB%B3%B4%EC%B6%A9.html",
            "date": " • Oct 6, 2022"
        }
        
    
  
    
        ,"post9": {
            "title": "(5주차) 10월5일",
            "content": "&#44053;&#51032;&#50689;&#49345; . . import . import numpy as np import pandas as pd import matplotlib.pyplot as plt import seaborn as sns . sns scatterplot . - data . x1,y1 = np.random.multivariate_normal([0,0],[[1,0],[0,1]],size=1000).T x2,y2 = np.random.multivariate_normal([2,2],[[1,0.7],[0.7,1]],size=1000).T . 이변량정규분포에서 샘플추출 (추출코드를 기억할 필요는 없음) | 특징: x1,y1은 무상관으로 x2,y2는 선형관계를 가지도록 추출 | . plt &#48373;&#49845; . plt.plot(x1,y1,&#39;o&#39;) plt.plot(x2,y2,&#39;o&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f6071f8a2d0&gt;] . sns: array . sns.scatterplot(data=None,x=x1,y=y1) sns.scatterplot(data=None,x=x2,y=y2) . &lt;AxesSubplot:&gt; . sns: wide df . sns.scatterplot(data=pd.DataFrame({&#39;x&#39;:x1,&#39;y&#39;:y1}),x=&#39;x&#39;,y=&#39;y&#39;) sns.scatterplot(data=pd.DataFrame({&#39;x&#39;:x2,&#39;y&#39;:y2}),x=&#39;x&#39;,y=&#39;y&#39;) #sns.scatterplot(data=None,x=x2,y=y2) . &lt;AxesSubplot:xlabel=&#39;x&#39;, ylabel=&#39;y&#39;&gt; . 억지로 그리긴 했는데 이 경우는 wide하게 만든 df는 별로 경쟁력이 없음 | . sns: long df . x= np.concatenate([x1,x2]) y= np.concatenate([y1,y2]) cat = [&#39;x1&#39;]*len(x1) + [&#39;x2&#39;]*len(x2) df2 = pd.DataFrame({&#39;x&#39;:x,&#39;y&#39;:y,&#39;cat&#39;:cat}) df2 . x y cat . 0 2.023919 | -0.400176 | x1 | . 1 1.229622 | -1.763752 | x1 | . 2 -0.413211 | 2.293004 | x1 | . 3 -1.343073 | 0.404232 | x1 | . 4 1.062845 | 0.030775 | x1 | . ... ... | ... | ... | . 1995 2.226805 | 3.683857 | x2 | . 1996 2.768263 | 2.678292 | x2 | . 1997 2.525295 | 2.815478 | x2 | . 1998 1.750193 | 2.289812 | x2 | . 1999 1.153290 | 2.095922 | x2 | . 2000 rows × 3 columns . sns.scatterplot(data=df2,x=&#39;x&#39;,y=&#39;y&#39;,hue=&#39;cat&#39;) . &lt;AxesSubplot:xlabel=&#39;x&#39;, ylabel=&#39;y&#39;&gt; . sns&#51012; &#51060;&#50857;&#54616;&#50668; matplotlib &#50529;&#49884;&#51592;&#50640; &#44536;&#47548; &#44536;&#47532;&#44592; ($ star$) . &#50696;&#51228;1 . fig,ax = plt.subplots(1,3,figsize=(12,4)) ax[0].plot([1,2,4,3],&#39;--o&#39;) sns.scatterplot(x=x1,y=y1,ax=ax[1]) sns.scatterplot(x=x1,y=y1,ax=ax[2]) sns.scatterplot(x=x2,y=y2,ax=ax[2]) ax[2].plot([1,2,4,3],&#39;-r&#39;,lw=5) . [&lt;matplotlib.lines.Line2D at 0x7f6077de7c10&gt;] . &#50696;&#51228;2 . import cv2 . !wget https://upload.wikimedia.org/wikipedia/commons/0/08/Unequalized_Hawkes_Bay_NZ.jpg img = cv2.imread(&#39;Unequalized_Hawkes_Bay_NZ.jpg&#39;,0) !rm Unequalized_Hawkes_Bay_NZ.jpg . --2022-10-05 16:33:56-- https://upload.wikimedia.org/wikipedia/commons/0/08/Unequalized_Hawkes_Bay_NZ.jpg Resolving upload.wikimedia.org (upload.wikimedia.org)... 103.102.166.240, 2001:df2:e500:ed1a::2:b Connecting to upload.wikimedia.org (upload.wikimedia.org)|103.102.166.240|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 110895 (108K) [image/jpeg] Saving to: ‘Unequalized_Hawkes_Bay_NZ.jpg’ Unequalized_Hawkes_ 100%[===================&gt;] 108.30K 548KB/s in 0.2s 2022-10-05 16:33:57 (548 KB/s) - ‘Unequalized_Hawkes_Bay_NZ.jpg’ saved [110895/110895] . img2 = cv2.equalizeHist(img) . img.reshape(-1) . array([127, 145, 149, ..., 146, 145, 144], dtype=uint8) . fig,ax = plt.subplots(2,2,figsize=(10,5)) ax[0,0].imshow(img,vmin=0,vmax=255,cmap=&#39;gray&#39;) sns.histplot(img.reshape(-1),ax=ax[0,1],bins=15,lw=0,kde=True,color=&#39;C1&#39;) ax[0,1].set_xlim(0,255) ax[1,0].imshow(img2,vmin=0,vmax=255,cmap=&#39;gray&#39;) sns.histplot(img2.reshape(-1),ax=ax[1,1],bins=15,lw=0,kde=True,color=&#39;C1&#39;) . &lt;AxesSubplot:ylabel=&#39;Count&#39;&gt; . - seaborn: figure-level vs axes-level 의 개념 . ref: https://seaborn.pydata.org/tutorial/function_overview.html#figure-level-vs-axes-level-functions . mpl &#48120;&#49464;&#47676;&#51648;&#54017; (2) . &#52629; &#44036;&#44201;&#51312;&#51221; . import matplotlib as mpl . fig, ax = plt.subplots() ax.plot([(xi/30)**2 for xi in range(30)],&#39;--o&#39;) ax.xaxis.set_major_locator(mpl.ticker.MultipleLocator(3)) # 큰 눈금간격을 3으로 ax.xaxis.set_minor_locator(mpl.ticker.MultipleLocator(1)) # 작은 눈금간격을 1로 . &#52629; &#49325;&#51228; . fig, ax = plt.subplots() ax.plot([(xi/30)**2 for xi in range(30)],&#39;--o&#39;) ax.xaxis.set_major_locator(mpl.ticker.NullLocator()) # x축 눈금삭제 ax.yaxis.set_major_locator(mpl.ticker.NullLocator()) # y축 눈금삭제 . &#52629; &#48276;&#50948;&#51312;&#51221; . fig, ax = plt.subplots() ax.plot([(xi/30)**2 for xi in range(30)],&#39;--o&#39;) ax.set_ylim(-1,2) ax.set_xlim(-5,35) #plt.ylim(-1,2) #plt.xlim(-5,35) . (-5.0, 35.0) . gcf, gca . - gcf . plt.plot([1,2,3,2]) fig = plt.gcf() . fig.suptitle(&#39;suptitle&#39;) . Text(0.5, 0.98, &#39;suptitle&#39;) . fig . - gca . fig . ax = fig.gca() . ax.set_title(&#39;title&#39;) fig .",
            "url": "https://guebin.github.io/DV2022/2022/10/03/(5%EC%A3%BC%EC%B0%A8)-10%EC%9B%945%EC%9D%BC.html",
            "relUrl": "/2022/10/03/(5%EC%A3%BC%EC%B0%A8)-10%EC%9B%945%EC%9D%BC.html",
            "date": " • Oct 3, 2022"
        }
        
    
  
    
        ,"post10": {
            "title": "(4주차) 9월28일",
            "content": "&#44053;&#51032;&#50689;&#49345; . . imports . import seaborn as sns import matplotlib.pyplot as plt import numpy as np import pandas as pd . seaborn &#53945;&#51669; . - 특1: 입력으로 데이터프레임을 선호한다. (matplotlib은 array를 선호) . 그렇다고 해서 데이터프레임이 아닌 경우 그림이 아예 안 그려지지는 않는다. | 데이터프레임 형태는 long form 과 wide form 이 있다. (ref) // 참고로 long form이 더 우수한 저장형태에요! | wide-df = [array1,array2,array3] | long-df = [array_val, array_cat] | . - 특2: matplotlib을 존경함. (ref) . sns boxplot . - 데이터: 전북고등학교 . y1=[75,75,76,76,77,77,79,79,79,98] # A선생님에게 통계학을 배운 학생의 점수들 y2=[76,76,77,77,78,78,80,80,80,81] # B선생님에게 통계학을 배운 학생의 점수들 . plt &#48373;&#49845; . plt.boxplot([y1,y2]); . sns wide df . df1=pd.DataFrame({1:y1,2:y2}) df1 . 1 2 . 0 75 | 76 | . 1 75 | 76 | . 2 76 | 77 | . 3 76 | 77 | . 4 77 | 78 | . 5 77 | 78 | . 6 79 | 80 | . 7 79 | 80 | . 8 79 | 80 | . 9 98 | 81 | . - 예시1 . sns.boxplot(data=df1) #sns.boxplot(data=np.stack([y1,y2],axis=1)) # &lt;- 잘 쓰진 않아요, 그냥 심심해서 해봤는데 되더라고요..? . &lt;AxesSubplot:&gt; . sns long df . df2=pd.DataFrame({&#39;score&#39;:y1+y2,&#39;class&#39;:[&#39;A&#39;]*len(y1)+[&#39;B&#39;]*len(y2)}) df2 . score class . 0 75 | A | . 1 75 | A | . 2 76 | A | . 3 76 | A | . 4 77 | A | . 5 77 | A | . 6 79 | A | . 7 79 | A | . 8 79 | A | . 9 98 | A | . 10 76 | B | . 11 76 | B | . 12 77 | B | . 13 77 | B | . 14 78 | B | . 15 78 | B | . 16 80 | B | . 17 80 | B | . 18 80 | B | . 19 81 | B | . - 예시1 . sns.boxplot(data=df2,x=&#39;class&#39;,y=&#39;score&#39;) . &lt;AxesSubplot:xlabel=&#39;class&#39;, ylabel=&#39;score&#39;&gt; . sns: array . - 예시1 . sns.boxplot(data=y1) . &lt;AxesSubplot:&gt; . - 예시2 . sns.boxplot(y=y1) . &lt;AxesSubplot:&gt; . - 예시3 . sns.boxplot(x=y1) . &lt;AxesSubplot:&gt; . sns histplot . - 데이터 . x= np.random.randn(10000) y= np.random.randn(10000) +1 . plt &#48373;&#49845; . - 예시1 . plt.hist(x,alpha=0.5) plt.hist(y,alpha=0.5); . - 예시2 . plt.hist([x,y]); . sns: wide df . df1=pd.DataFrame({&#39;x&#39;:x,&#39;y&#39;:y}) df1 . x y . 0 -2.110587 | 0.712687 | . 1 0.176404 | 1.587615 | . 2 0.592212 | 0.362025 | . 3 0.957655 | 0.485939 | . 4 1.689412 | 0.582304 | . ... ... | ... | . 9995 -0.935895 | 0.047778 | . 9996 1.521599 | 1.946658 | . 9997 -0.595255 | 0.671715 | . 9998 0.952991 | 2.263997 | . 9999 0.850642 | 1.578771 | . 10000 rows × 2 columns . - 예시1 . sns.histplot(data=df1) . &lt;AxesSubplot:ylabel=&#39;Count&#39;&gt; . - 예시2 . sns.histplot(data=df1,bins=20) . &lt;AxesSubplot:ylabel=&#39;Count&#39;&gt; . - 예시3 . sns.histplot(data=df1,bins=20,kde=True) . &lt;AxesSubplot:ylabel=&#39;Count&#39;&gt; . - 예시4 . sns.histplot(data=df1,bins=20,kde=True,element=&quot;step&quot;) . &lt;AxesSubplot:ylabel=&#39;Count&#39;&gt; . - 예시5 . sns.histplot(data=df1,bins=20,kde=True,element=&quot;step&quot;,lw=5) # mpl에 대한 존경심 확인 . &lt;AxesSubplot:ylabel=&#39;Count&#39;&gt; . sns: long df . df2=pd.DataFrame({&#39;val&#39;:np.concatenate([x,y]), &#39;var&#39;:[&#39;x&#39;]*len(x) + [&#39;y&#39;]*len(y)}) df2 . val var . 0 -2.110587 | x | . 1 0.176404 | x | . 2 0.592212 | x | . 3 0.957655 | x | . 4 1.689412 | x | . ... ... | ... | . 19995 0.047778 | y | . 19996 1.946658 | y | . 19997 0.671715 | y | . 19998 2.263997 | y | . 19999 1.578771 | y | . 20000 rows × 2 columns . - 예시1 . sns.histplot(data=df2,x=&#39;val&#39;,hue=&#39;var&#39;,bins=20,kde=True,lw=0) . &lt;AxesSubplot:xlabel=&#39;val&#39;, ylabel=&#39;Count&#39;&gt; . - 예시2 . sns.histplot(data=df2,y=&#39;val&#39;,hue=&#39;var&#39;,bins=20,lw=0,kde=True) . &lt;AxesSubplot:xlabel=&#39;Count&#39;, ylabel=&#39;val&#39;&gt; . sns: array . - 예시1 . sns.histplot(data=x) . &lt;AxesSubplot:ylabel=&#39;Count&#39;&gt; . - 예시2 . sns.histplot(x=x) . &lt;AxesSubplot:ylabel=&#39;Count&#39;&gt; . - 예시3 . sns.histplot(x=x,color=&#39;C0&#39;,bins=20,lw=0) sns.histplot(x=y,color=&#39;C1&#39;,bins=20,lw=0) . &lt;AxesSubplot:ylabel=&#39;Count&#39;&gt; . sns lineplot . - data . np.random.seed(43052) ϵ = np.random.randn(100) . y = np.cumsum(ϵ) . plt &#48373;&#49845; . plt.plot(ϵ,&#39;--o&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fd4f71b9810&gt;] . plt.plot(y,&#39;--o&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fd4f7131950&gt;] . sns: array . - 예시1 . sns.lineplot(data=ϵ) . &lt;AxesSubplot:&gt; . - 예시2 . sns.lineplot(data=y) . &lt;AxesSubplot:&gt; . sns: wide df . df1=pd.DataFrame({&#39;eps&#39;:ϵ, &#39;y&#39;:y}) df1 . eps y . 0 0.383420 | 0.383420 | . 1 1.084175 | 1.467595 | . 2 1.142778 | 2.610373 | . 3 0.307894 | 2.918267 | . 4 0.237787 | 3.156054 | . ... ... | ... | . 95 1.308688 | -10.598788 | . 96 0.405376 | -10.193412 | . 97 -0.185070 | -10.378481 | . 98 1.055388 | -9.323094 | . 99 1.187014 | -8.136079 | . 100 rows × 2 columns . - 예시1 . sns.lineplot(data=df1) . &lt;AxesSubplot:&gt; . - 예시2 . sns.lineplot(data=df1,dashes=False) . &lt;AxesSubplot:&gt; . - 예시3 . # sns.lineplot(data=df1,dashes=[(3,1),(3,1)]) # 이코드는 최신버전의 sns에서 동작하지 않으므로 삭제합니다. (collab 에서는 정상동작) . - 예시4 . # sns.lineplot(data=df1,dashes=[(3,1),(15,3)],markers=[&#39;o&#39;,&#39;o&#39;]) # 이코드는 최신버전의 sns에서 동작하지 않으므로 삭제합니다. (collab 에서는 정상동작) . sns: long df . df2= pd.DataFrame({&#39;idx&#39;:list(range(100))*2,&#39;val&#39;:np.concatenate([ϵ,y]),&#39;cat&#39;:[&#39;eps&#39;]*100 + [&#39;y&#39;]*100 }) df2 . idx val cat . 0 0 | 0.383420 | eps | . 1 1 | 1.084175 | eps | . 2 2 | 1.142778 | eps | . 3 3 | 0.307894 | eps | . 4 4 | 0.237787 | eps | . ... ... | ... | ... | . 195 95 | -10.598788 | y | . 196 96 | -10.193412 | y | . 197 97 | -10.378481 | y | . 198 98 | -9.323094 | y | . 199 99 | -8.136079 | y | . 200 rows × 3 columns . - 예시1 . sns.lineplot(data=df2, x=&#39;idx&#39;,y=&#39;val&#39;,hue=&#39;cat&#39;) . &lt;AxesSubplot:xlabel=&#39;idx&#39;, ylabel=&#39;val&#39;&gt; . - 예시2 . sns.lineplot(data=df2, x=&#39;idx&#39;,y=&#39;val&#39;,style=&#39;cat&#39;,hue=&#39;cat&#39;,markers=True) . &lt;AxesSubplot:xlabel=&#39;idx&#39;, ylabel=&#39;val&#39;&gt; . - 예시3 . sns.lineplot(data=df2, x=&#39;idx&#39;,y=&#39;val&#39;,style=&#39;cat&#39;,hue=&#39;cat&#39;,dashes=[(3,1),(3,3)],markers=[&#39;o&#39;,&#39;o&#39;]) . &lt;AxesSubplot:xlabel=&#39;idx&#39;, ylabel=&#39;val&#39;&gt; . &#49689;&#51228; . - 아래의 그림에 대응하는 그림을 seaborn을 이용하여 그려라. . y1 = np.random.randn(90).cumsum() y2 = np.random.randn(120).cumsum() . plt.plot(y1,&#39;--o&#39;) plt.plot(y2,&#39;--o&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fd4f3172210&gt;] .",
            "url": "https://guebin.github.io/DV2022/2022/09/28/(4%EC%A3%BC%EC%B0%A8)-9%EC%9B%9428%EC%9D%BC.html",
            "relUrl": "/2022/09/28/(4%EC%A3%BC%EC%B0%A8)-9%EC%9B%9428%EC%9D%BC.html",
            "date": " • Sep 28, 2022"
        }
        
    
  
    
        ,"post11": {
            "title": "(4주차) 9월26일",
            "content": "&#44053;&#51032;&#50689;&#49345; . . imports . import matplotlib.pyplot as plt import numpy as np import pandas as pd . &#49328;&#51216;&#46020; &#51025;&#50857;&#50696;&#51228; 4 (&#47924;&#49345;&#44288;&#44284; &#46021;&#47549;) . &#50696;&#51228;&#51088;&#47308; . 예시1: 사각형 . x1 = np.random.uniform(low=-1,high=1,size=10000) y1 = np.random.uniform(low=-1,high=1,size=10000) . plt.plot(x1,y1,&#39;,&#39;) . [&lt;matplotlib.lines.Line2D at 0x7efe739fa410&gt;] . 예시2: 원 . _r2 = x1**2+y1**2 . x2=x1[_r2&lt;1] y2=y1[_r2&lt;1] . plt.plot(x2,y2,&#39;,&#39;) . [&lt;matplotlib.lines.Line2D at 0x7efe73ae5410&gt;] . 예시3: 이변량정규분포 . x3 = np.random.randn(10000) y3 = np.random.randn(10000) . plt.plot(x3,y3,&#39;,&#39;) . [&lt;matplotlib.lines.Line2D at 0x7efe7396aad0&gt;] . &#49345;&#44288;&#44228;&#49688; . - 예시1, 예시2, 예시3의 산점도를 보고 상관계수가 얼마인지 예상해보라. 실제 계산결과와 확인하라. . np.corrcoef([x1,y1]) . array([[ 1. , -0.00255095], [-0.00255095, 1. ]]) . np.corrcoef([x2,y2]) . array([[ 1. , -0.01437794], [-0.01437794, 1. ]]) . np.corrcoef([x3,y3]) . array([[ 1. , -0.02282708], [-0.02282708, 1. ]]) . &#46021;&#47549; . - 예시1,2,3 중 독립인것은 무엇인가? . - 예시1 vs 예시2 . fig, ax = plt.subplots(1,2,figsize=(8,4)) ax[0].plot(x1,y1,&#39;,&#39;,color=&#39;gray&#39;) ax[1].plot(x2,y2,&#39;,&#39;,color=&#39;gray&#39;) . [&lt;matplotlib.lines.Line2D at 0x7efe69fbf750&gt;] . def g(intval, data, ax, col = &#39;r&#39;): a,b = intval x,y = data idx = (a&lt;x)&amp;(x&lt;b) ax.plot(x[idx],y[idx],&#39;,&#39;,color=col) . g([-0.1,0.1],[x1,y1],ax[0]) g([-0.1,0.1],[x2,y2],ax[1]) fig . g([0.79,0.99],[x1,y1],ax[0],col=&#39;b&#39;) g([0.79,0.99],[x2,y2],ax[1],col=&#39;b&#39;) fig . - 예시3 . fig,ax = plt.subplots() ax.plot(x3,y3,&#39;,&#39;,color=&#39;gray&#39;) . [&lt;matplotlib.lines.Line2D at 0x7efe695e41d0&gt;] . g([-2.5,-1.5],[x3,y3],ax,col=&#39;r&#39;) g([-0.5,+0.5],[x3,y3],ax,col=&#39;b&#39;) g([+1.5,+2.5],[x3,y3],ax,col=&#39;g&#39;) fig . def h(intval, data, ax, col): a,b = intval x,y = data idx = (a&lt;x) &amp; (x&lt;b) ax.hist(y[idx],color=col) . fig,ax = plt.subplots(5,2,figsize=(8,16)) ax[0,0].plot(x3,y3,&#39;,&#39;,color=&#39;gray&#39;); g([-2.5,-1.5],[x3,y3],ax[0,0],col=&#39;r&#39;) ax[1,0].plot(x3,y3,&#39;,&#39;,color=&#39;gray&#39;); g([-1.5,-0.5],[x3,y3],ax[1,0],col=&#39;g&#39;) ax[2,0].plot(x3,y3,&#39;,&#39;,color=&#39;gray&#39;); g([-0.5,+0.5],[x3,y3],ax[2,0],col=&#39;b&#39;) ax[3,0].plot(x3,y3,&#39;,&#39;,color=&#39;gray&#39;); g([+0.5,+1.5],[x3,y3],ax[3,0],col=&#39;m&#39;) ax[4,0].plot(x3,y3,&#39;,&#39;,color=&#39;gray&#39;); g([+1.5,+2.5],[x3,y3],ax[4,0],col=&#39;lime&#39;) h([-2.5,-1.5],[x3,y3],ax[0,1],col=&#39;r&#39;) h([-1.5,-0.5],[x3,y3],ax[1,1],col=&#39;g&#39;) h([-0.5,+0.5],[x3,y3],ax[2,1],col=&#39;b&#39;) h([+0.5,+1.5],[x3,y3],ax[3,1],col=&#39;m&#39;) h([+1.5,+2.5],[x3,y3],ax[4,1],col=&#39;lime&#39;) . mpl&#50640; &#45824;&#54620; &#48120;&#49464;&#47676;&#51648; &#54017; (1) . &#44536;&#47548;&#47564; &#48372;&#44256; &#49910;&#51012;&#46412; . plt.plot([1,2,3,4],[2,3,4,5]); . marker size, line width . plt.plot([1,2,3,4],[2,3,4,2],&#39;o&#39;,ms=10) . [&lt;matplotlib.lines.Line2D at 0x7f5883561350&gt;] . plt.plot([1,2,3,4],[2,3,4,5],&#39;--&#39;,lw=10) . [&lt;matplotlib.lines.Line2D at 0x7f5883c04ed0&gt;] . label + legend . plt.plot([1,2,3,4],[1,2,3,2],&#39;--o&#39;,label=&#39;A&#39;) plt.plot([1,2,3,4],[3,2.1,1,3],&#39;--o&#39;,label=&#39;B&#39;) plt.legend() . &lt;matplotlib.legend.Legend at 0x7f5889ead210&gt; . &#49353;&#44628;&#51312;&#51221; (C0,C1,...) . plt.plot([1,2,3,4],[1,2,3,2],&#39;--o&#39;,label=&#39;A&#39;,color=&#39;C1&#39;) plt.plot([1,2,3,4],[3,2.1,1,3],&#39;--o&#39;,label=&#39;B&#39;,color=&#39;C0&#39;) plt.legend() . &lt;matplotlib.legend.Legend at 0x7f588a29ef10&gt; . title &#49444;&#51221; . - (방법1) . plt.plot([1,2,3,4],[1,2,3,2],&#39;--o&#39;,label=&#39;A&#39;,color=&#39;C1&#39;) plt.plot([1,2,3,4],[3,2.1,1,3],&#39;--o&#39;,label=&#39;B&#39;,color=&#39;C0&#39;) plt.legend() plt.title(&#39;title&#39;) . Text(0.5, 1.0, &#39;title&#39;) . - (방법2) . fig, ax = plt.subplots() ax.plot([1,2,3,4],[1,2,3,2],&#39;--o&#39;,label=&#39;A&#39;,color=&#39;C1&#39;) ax.plot([1,2,3,4],[3,2.1,1,3],&#39;--o&#39;,label=&#39;B&#39;,color=&#39;C0&#39;) ax.legend() ax.set_title(&#39;title&#39;) . Text(0.5, 1.0, &#39;title&#39;) . suptitle &#49444;&#51221; . fig, ax = plt.subplots(2,2) ax[0,0].plot([1,2,3,2],&#39;--o&#39;,label=&#39;A&#39;,color=&#39;C0&#39;) ax[0,0].set_title(&#39;(a)&#39;) ax[0,1].plot([3,2.1,1,3],&#39;--o&#39;,label=&#39;B&#39;,color=&#39;C1&#39;) ax[0,1].set_title(&#39;(b)&#39;) ax[1,0].plot([-3,-2.1,-1,-3],&#39;--o&#39;,label=&#39;B&#39;,color=&#39;C2&#39;) ax[1,0].set_title(&#39;(c)&#39;) ax[1,1].plot([3,-2.1,1,-3],&#39;--o&#39;,label=&#39;B&#39;,color=&#39;C3&#39;) ax[1,1].set_title(&#39;(d)&#39;) #plt.suptitle(&#39;suptitle&#39;) fig.suptitle(&#39;suptitle&#39;) . Text(0.5, 0.98, &#39;suptitle&#39;) . tight_layout() . fig . fig.tight_layout() . fig . fig, ax, plt &#49548;&#49549; . - 일단 그림 하나 그리고 이야기좀 해보자. . fig, ax = plt.subplots() ax.plot([1,2,3,1]) . [&lt;matplotlib.lines.Line2D at 0x7efe4bdd9950&gt;] . - fig에는 있고 ax에는 없는 것 . add_axes, tight_layout, suptitle, ... . - ax에는 있고 fig에는 없는 것 . boxplot, hist, plot, set_title, ... . - plt는 대부분 다 있음. (의미상 명확한건 대충 알아서 fig, ax에 접근해서 처리해준다) . plt.tight_layout, plt.suptitle, plt.boxplot, plt.hist, plot.plot | plt.set_title 은 없지만 plt.title 은 있음 | plt.add_axes 는 없음.. | . x&#52629;, y&#52629; label &#49444;&#51221; . ax.xaxis.set_label_text(&#39;xlabel&#39;,size=16,family=&#39;serif&#39;,weight=1000,style=&#39;italic&#39;) #_fontsettings={&#39;size&#39;:16,&#39;family&#39;:&#39;serif&#39;,&#39;weight&#39;=1000,&#39;style&#39;:&#39;italic&#39;} #ax.xaxis.set_label_text(&#39;xlabel&#39;,_fontsettings) fig . 폰트ref . size: | fontweight: 0~1000 | family: &#39;serif&#39;, &#39;sans-serif&#39;, &#39;monospace&#39; | style: &#39;normal&#39;, &#39;italic&#39; | . ax.set_ylabel(&#39;ylabel&#39;,size=16) fig . &#49689;&#51228; (&#45212;&#51060;&#46020; &#49345;) -- &#45796;&#51020;&#49884;&#44036;&#50640; &#54400;&#50612;&#51460;&#44144;&#50640;&#50836; . 아래와 같이 표준정규분포에서 100개의 난수를 생성하여 $ boldsymbol{ epsilon}=( epsilon_1, epsilon_2, dots, epsilon_{100})$ 와 같은 벡터를 만들었다고 하자. . np.random.seed(43052) ϵ = np.random.randn(100) . 아래는 $(t, epsilon_t)$를 그린 그림이다. (단 $t=1,2, dots,100$) . plt.plot(np.arange(1,101),ϵ,&#39;--o&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f59b74466d0&gt;] . (1) $ epsilon_t$ 와 $ epsilon_{t-1}$은 독립이라고 보여지는가? . (2) 아래의 수식을 만족하는 벡터 ${ boldsymbol y} = (y_1,y_2, dots, y_{100})$ 을 생성하라. (단 $y_1= epsilon_1$) . $$ y_t = y_{t-1} + epsilon_t$$ . (3) $(t,y_t)$의 dot-connected plot을 그려라. . # 아래와 같은 그림이 나와야 한다. . [&lt;matplotlib.lines.Line2D at 0x7f59b8f81850&gt;] . (4) $y_t$와 $y_{t-1}$은 독립이라고 볼 수 있는가? .",
            "url": "https://guebin.github.io/DV2022/2022/09/26/(4%EC%A3%BC%EC%B0%A8)-9%EC%9B%9426%EC%9D%BC.html",
            "relUrl": "/2022/09/26/(4%EC%A3%BC%EC%B0%A8)-9%EC%9B%9426%EC%9D%BC.html",
            "date": " • Sep 26, 2022"
        }
        
    
  
    
        ,"post12": {
            "title": "(3주차) 9월21일",
            "content": "&#44053;&#51032;&#50689;&#49345; . . imports . import matplotlib.pyplot as plt import numpy as np import plotly.express as px from IPython.display import HTML . &#49328;&#51216;&#46020; &#51025;&#50857;&#50696;&#51228;1 - &#54364;&#48376;&#49345;&#44288;&#44228;&#49688; . &#50696;&#51228;&#49548;&#44060; . - 아래와 같은 자료를 수집하였다고 하자. . 몸무게 = [44,48,49,58,62,68,69,70,76,79] | 키 = [159,160,162,165,167,162,165,175,165,172] | . x=[44,48,49,58,62,68,69,70,76,79] y=[159,160,162,165,167,162,165,175,165,172] . plt.plot(x,y,&#39;o&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f49354a0ad0&gt;] . 키가 큰 사람일수록 몸무게도 많이 나간다. (반대도 성립) | 키와 몸무게는 관계가 있어보인다. (정비례) | . - 얼만큼 정비례인지? . 이 질문에 대답하기 위해서는 상관계수의 개념을 알아야 한다. | 상관계수는 산점도에서 가장 중요한 개념중 하나. | . &#49345;&#44288;&#44228;&#49688;&#51032; &#51221;&#51032; . - (표본)상관계수 . $$r= frac{ sum_{i=1}^{n}(x_i- bar{x})(y_i- bar{y}) }{ sqrt{ sum_{i=1}^{n}(x_i- bar{x})^2 sum_{i=1}^{n}(y_i- bar{y})^2 }}= sum_{i=1}^{n} tilde{x}_i tilde{y}_i $$ . 단, $ tilde{x}_i= frac{(x_i- bar{x})}{ sqrt{ sum_{i=1}^n(x_i- bar{x})^2}}$, $ tilde{y}_i= frac{(y_i- bar{y})}{ sqrt{ sum_{i=1}^n(y_i- bar{y})^2}}$ | . * 표본의 의미 . 평균과 표본평균 . np.random.seed(43052) x = np.random.randn(10) x . array([ 0.38342049, 1.0841745 , 1.14277825, 0.30789368, 0.23778744, 0.35595116, -1.66307542, -1.38277318, -1.92684484, -1.4862163 ]) . x는 의 각 원소는 모두 평균이 0인 정규분포에서 추출했다고 표현 | . np.mean(x) . 0.09434107867212947 . ${ tt x}=(x_1, dots, x_{10})$의 표본평균은 ${ bar x}=0.09434107867212947$ 라고 표현 | . &#49345;&#44288;&#44228;&#49688;&#51032; &#51032;&#48120; . - 의미? . x=np.array(x) y=np.array(y) . fig, (ax1,ax2,ax3) = plt.subplots(1,3,figsize=(9,4)) . ax1.plot(x,y,&#39;o&#39;) ax2.plot(x-np.mean(x),y-np.mean(y),&#39;o&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f03567ef610&gt;] . fig . - $ tilde{x}_i$와 $ tilde{y}_i$를 계산하기 위해서 $a= sqrt{ sum_{i=1}^{n}(x_i- bar{x})^2}, b= sqrt{ sum_{i=1}^{n}(y_i- bar{y})^2}$를 계산하자. . (방법1) . a=np.sqrt(np.sum((x-np.mean(x))**2)) b=np.sqrt(np.sum((y-np.mean(y))**2)) a,b . (2.8842557251032446, 15.218409903797438) . 해석: $a&gt;b$ 이므로 $ {x_i }$들이 $ {y_i }$들 보다 좀 더 퍼져있다. (=평균근처에 몰려있지 않다) | . (방법2) . - 사실 $a,b$는 아래와 같이 계산할 수 있다. . $a= sqrt{n} times{ tt np.std(x)}$ . $b= sqrt{n} times{ tt np.std(y)}$ . n=len(x) np.sqrt(n)*np.std(x), np.sqrt(n)*np.std(y) . (2.8842557251032446, 15.21840990379744) . ${ tt np.std(x)}= sqrt{ frac{1}{n} sum_{i=1}^{n}(x_i- bar{x})^2}$ | ${ tt np.std(y)}= sqrt{ frac{1}{n} sum_{i=1}^{n}(y_i- bar{y})^2}$ | . . Note: ${ tt np.std(x,ddof=1)}= sqrt{ frac{1}{n-1} sum_{i=1}^{n}(x_i- bar{x})^2}$ . - 이제 $( tilde{x}_i, tilde{y}_i)$를 ax3에 그려보자. . xx= (x-np.mean(x))/a yy= (y-np.mean(y))/b ax3.plot(xx,yy,&#39;o&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f03567b4290&gt;] . fig . 질문: $r$의 값이 양수인가? 음수인가? . - plotly 사용하여 $( tilde{x}_i, tilde{y}_i)$를 그려보자. . fig=px.scatter(x=xx, y=yy) HTML(fig.to_html(include_plotlyjs=&#39;cdn&#39;,include_mathjax=False)) . . . $ tilde{x}_i$, $ tilde{y}_i$ 를 곱한값이 양수인것과 음수인것을 체크해보자. | 양수인쪽이 많은지 음수인쪽이 많은지 생각해보자. | $r= sum_{i=1}^{n} tilde{x}_i tilde{y}_i$ 의 부호는? | . &#44536;&#47548;&#51012; &#48372;&#44256; &#49345;&#44288;&#44228;&#49688;&#51032; &#48512;&#54840;&#47484; &#50508;&#50500;&#45236;&#45716; &#48169;&#48277; . - $(x_i,y_i)$의 산점도를 보고 $( tilde{x}_i, tilde{y}_i)$ 의 산점도를 상상 $ to$ 1,3 분면에 점들이 많으면 양수, 2,4 분면에 점들이 많으면 음수 . &#44536;&#47548;&#51012; &#48372;&#44256; &#49345;&#44288;&#44228;&#49688;&#51032; &#51208;&#45824;&#44050;&#51012; &#50508;&#50500;&#45236;&#45716; &#48169;&#48277; . - 이해를 위한 예시 . x=np.arange(0,10,0.1) y1=x+np.random.normal(loc=0,scale=1.0,size=len(x)) y2=x+np.random.normal(loc=0,scale=7.0,size=len(x)) . plt.plot(x,y1,&#39;o&#39;) plt.plot(x,y2,&#39;x&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f03566c0650&gt;] . 각 데이터셋의 표준상관계수를 각각 $r_1$(파란색), $r_2$(주황색)라고 하자. . (1) $r_1$, $r_2$의 부호는 양수인가? 음수인가? --&gt; 양수 . (2) $r_1,r_2$의 값중 어떠한 값이 더 절대값이 큰가? --&gt; 잘모르겠음. 따져보자. . def tilde(x): n= len(x) return (x-np.mean(x)) / (np.std(x)*np.sqrt(n)) . xx= tilde(x) yy1= tilde(y1) yy2= tilde(y2) . fig, ax = plt.subplots(1,2) ax[0].plot(x,y1,&#39;o&#39;) ax[0].plot(x,y2,&#39;x&#39;) ax[1].plot(x,yy1,&#39;o&#39;) ax[1].plot(x,yy2,&#39;x&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f035666bc50&gt;] . r1, r2 = sum(xx*yy1), sum(xx*yy2) r1, r2 . (0.9473089524539402, 0.4445681691326099) . - 그림을 보고 상관계수의 절대값을 알아내는 방법!: 직선근처에 몰려있으면 절대값이 커요! . &#49328;&#51216;&#46020; &#51025;&#50857;&#50696;&#51228;2 -- &#50532;&#49828;&#53092;&#51032; 4&#48516;&#54624; . - Anscombe&#39;s quartet: 교과서에 나오는 그림임. . - 교훈1: 데이터를 분석하기 전에 항상 시각화를 하라. . x = [10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5] y1 = [8.04, 6.95, 7.58, 8.81, 8.33, 9.96, 7.24, 4.26, 10.84, 4.82, 5.68] y2 = [9.14, 8.14, 8.74, 8.77, 9.26, 8.10, 6.13, 3.10, 9.13, 7.26, 4.74] y3 = [7.46, 6.77, 12.74, 7.11, 7.81, 8.84, 6.08, 5.39, 8.15, 6.42, 5.73] x4 = [8, 8, 8, 8, 8, 8, 8, 19, 8, 8, 8] y4 = [6.58, 5.76, 7.71, 8.84, 8.47, 7.04, 5.25, 12.50, 5.56, 7.91, 6.89] . fig, ((ax1,ax2),(ax3,ax4)) = plt.subplots(2,2) ax1.plot(x,y1,&#39;o&#39;) ax2.plot(x,y2,&#39;o&#39;) ax3.plot(x,y3,&#39;o&#39;) ax4.plot(x4,y4,&#39;o&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f035648d290&gt;] . - 첫번째 그림의 상관계수를 구해보자. 즉 corr(x,y1)을 구해보자. . _xx = tilde(x) _yy1 = tilde(y1) . np.sum(_xx*_yy1) . 0.8164205163448399 . - 사실 아래와 같이 구해도 된다. . np.corrcoef([x,y1]) . array([[1. , 0.81642052], [0.81642052, 1. ]]) . - corr(x,y1), corr(x,y2), corr(x,y3)를 구해보자. . np.corrcoef([x,y1,y2,y3]) . array([[1. , 0.81642052, 0.81623651, 0.81628674], [0.81642052, 1. , 0.7500054 , 0.46871668], [0.81623651, 0.7500054 , 1. , 0.58791933], [0.81628674, 0.46871668, 0.58791933, 1. ]]) . 앤스콤의 4분할중 1,2,3 번째 그림의 상관계수는 0.81642052, 0.81623651, 0.81628674 이라는 의미 | 즉 corr(x,y1)=0.81642052, corr(x,y2)=0.81623651, corr(x,y3)=0.81628674 임 | . * 참고로 np.corrcoef([x,y1,y2,y3])의 계산결과는 정확하게 . $$ begin{bmatrix} corr(x,x) &amp; corr(x,y1) &amp; corr(x,y2) &amp; corr(x,y3) corr(y1,x) &amp; corr(y1,y1) &amp; corr(y1,y2) &amp; corr(y1,y3) corr(y2,x) &amp; corr(y2,y1) &amp; corr(y2,y2) &amp; corr(y2,y3) corr(y3,x) &amp; corr(y3,y1) &amp; corr(y3,y2) &amp; corr(y3,y3) end{bmatrix}$$ . 를 의미함 . - 앤스콤플랏의 4개의 그림은 모두 같은 상관계수를 가진다. $ to$ 하지만 4개의 그림은 느낌이 전혀 다르다. . - 같은 표본상관계수를 가진다고 하여 같은 관계성을 가지는 것은 아니다. 표본상관계수는 x,y의 비례정도를 측정하는데 그 값이 1에 가깝다고 하여 꼭 정비례의 관계가 있음을 의미하는게 아니다. $(x_i,y_i)$의 산점도가 선형성을 보일때만 &quot;표본상관계수가 1이므로 정비례의 관계에 있다&quot; 라는 논리전개가 성립한다. . 앤스콤의 1번째 플랏: 산점도가 선형 $ to$ 표본상관계수가 0.816 = 정비례의 관계가 0.816 정도 | 앤스콤의 2번째 플랏: 산점도가 선형이 아님 $ to$ 표본상관계수가 크게 의미없음 | 앤스콤의 3번째 플랏: 산점도가 선형인듯 보이나 하나의 이상치가 있음 $ to$ 하나의 이상치가 표본상관계수의 값을 무너뜨릴 수 있으므로 표본상관계수값을 신뢰할 수 없음. | 앤스콤의 4번째 플랏: 산점도를 그려보니 이상한그림 $ to$ 표존상관계수를 계산할수는 있음. 그런데 그게 무슨 의미가 있을지? | . - 앤스콤의 3번째 플랏: 하나의 이상치가 상관계수를 무너뜨리는 경우 시각화 . plt.plot(x,y1,&#39;x&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f0355d7e6d0&gt;] . 하나의 점을 잘 추가하면 이 상관계수값을 -1에 수렴시킬 수 있다? | . plt.plot(x+[99],y1+[-99],&#39;x&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f0355e77dd0&gt;] . np.corrcoef(x+[99],y1+[-99]) . array([[ 1. , -0.98450679], [-0.98450679, 1. ]]) . - 교훈2: 상관계수를 해석하기에 앞서서 산점도가 선형성을 보이는지 체크할 것! 항상 통계학과에서 배우는 통계량 (혹은 논리전개)는 적절한 가정하에서만 말이된다는 사실을 기억할 것! . &#49328;&#51216;&#46020; &#51025;&#50857;&#50696;&#51228;3 -- &#47924;&#49345;&#44288;&#51008; &#44288;&#44228;&#44032; &#50630;&#45796;&#45716; &#46907;? . np.random.seed(43052) x=np.linspace(-1,1,100,endpoint=True) y=x**2+np.random.normal(scale=0.1,size=100) . plt.plot(x,y,&#39;o&#39;) plt.title(&#39;y=x**2&#39;) . Text(0.5, 1.0, &#39;y=x**2&#39;) . np.corrcoef(x,y) . array([[1. , 0.00688718], [0.00688718, 1. ]]) . - 표본상관계수의 값이 0에 가까운 것은 두 변수의 직선관계가 약한것을 의미한 것이지 두 변수 사이에 아무런 함수관계가 없다는 것을 의미하는 것은 아니다. . &#49689;&#51228; . 아래의 그림을 보고 물음에 답하라. . . (1) 산점도 (a) - (f) 중 표본상관계수가 양수라 생각되는 그림은? . (2) 산점도 (a) - (f) 중 표본상관계수의 절대값이 가장 큰 그림은? 절대값이 가장 작은 그림은? .",
            "url": "https://guebin.github.io/DV2022/2022/09/21/(3%EC%A3%BC%EC%B0%A8)-9%EC%9B%9421%EC%9D%BC.html",
            "relUrl": "/2022/09/21/(3%EC%A3%BC%EC%B0%A8)-9%EC%9B%9421%EC%9D%BC.html",
            "date": " • Sep 21, 2022"
        }
        
    
  
    
        ,"post13": {
            "title": "(3주차) 9월19일 -- 숙제제출방법 영상추가",
            "content": "&#44053;&#51032;&#50689;&#49345; . . &#50724;&#45720; &#48176;&#50872; &#45236;&#50857;? . - 라인플랏과 산점도를 그리는 방법 . - 여러 그림그리기 (한 플랏에 그림을 겹치는 방법, subplot을 그리는 방법) . - fig, axes의 개념이해 (객체지향적 프로그래밍) . imports . import matplotlib.pyplot as plt import numpy as np . Line plot . &#44592;&#48376;&#54540;&#46991; . - 예시1 . x=[1,2,3,4] y=[1,2,4,3] . plt.plot(x,y) . [&lt;matplotlib.lines.Line2D at 0x7f3b261797d0&gt;] . &#47784;&#50577;&#48320;&#44221; . - 예시1 . plt.plot(x,y,&#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f3b260867d0&gt;] . - 예시2 . plt.plot(x,y,&#39;:&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f3b25f950d0&gt;] . - 예시3 . plt.plot(x,y,&#39;-.&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f3b25f15810&gt;] . &#49353;&#49345;&#48320;&#44221; . - 예시1 . plt.plot(x,y,&#39;r&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f3b25e1e9d0&gt;] . - 예시2 . plt.plot(x,y,&#39;k&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f3b25dad290&gt;] . &#47784;&#50577; + &#49353;&#49345;&#48320;&#44221; . - 예시1 . plt.plot(x,y,&#39;--r&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f3b25b2ab10&gt;] . - 예시2: 순서변경 가능 . plt.plot(x,y,&#39;r--&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f3b25942d10&gt;] . &#50896;&#47532;? . - r--등의 옵션은 Markers + Line Styles + Colors 의 조합으로 표현가능 . ref: https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.plot.html . --r: 점선(dashed)스타일 + 빨간색 | r--: 빨간색 + 점선(dashed)스타일 | :k: 점선(dotted)스타일 + 검은색 | k:: 검은색 + 점선(dotted)스타일 | . - 우선 Marker를 무시하면 Line Styles + Color로 표현가능한 조합은 $4 times 8=32$ 개 . (Line Styles) 모두 4개 . character description . &#39;-&#39; | solid line style | . &#39;--&#39; | dashed line style | . &#39;-.&#39; | dash-dot line style | . &#39;:&#39; | dotted line style | . (Color) 모두 8개 . character color . &#39;b&#39; | blue | . &#39;g&#39; | green | . &#39;r&#39; | red | . &#39;c&#39; | cyan | . &#39;m&#39; | magenta | . &#39;y&#39; | yellow | . &#39;k&#39; | black | . &#39;w&#39; | white | . - 예시1 . plt.plot(x,y,&#39;--m&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f3b25840e90&gt;] . - 예시2 . plt.plot(x,y,&#39;-.c&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f3b257c99d0&gt;] . - 예시3: line style + color 조합으로 사용하든 color + line style 조합으로 사용하든 상관없음 . plt.plot(x,y,&#39;-.c&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f3b256ea050&gt;] . plt.plot(x,y,&#39;c-.&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f3b256679d0&gt;] . - 예시4: line style을 중복으로 사용하거나 color를 중복으로 쓸 수 는 없다. . plt.plot(x,y,&#39;--:&#39;) . ValueError Traceback (most recent call last) /tmp/ipykernel_105674/54727817.py in &lt;module&gt; -&gt; 1 plt.plot(x,y,&#39;--:&#39;) ~/anaconda3/envs/py37/lib/python3.7/site-packages/matplotlib/pyplot.py in plot(scalex, scaley, data, *args, **kwargs) 2767 return gca().plot( 2768 *args, scalex=scalex, scaley=scaley, -&gt; 2769 **({&#34;data&#34;: data} if data is not None else {}), **kwargs) 2770 2771 ~/anaconda3/envs/py37/lib/python3.7/site-packages/matplotlib/axes/_axes.py in plot(self, scalex, scaley, data, *args, **kwargs) 1633 &#34;&#34;&#34; 1634 kwargs = cbook.normalize_kwargs(kwargs, mlines.Line2D) -&gt; 1635 lines = [*self._get_lines(*args, data=data, **kwargs)] 1636 for line in lines: 1637 self.add_line(line) ~/anaconda3/envs/py37/lib/python3.7/site-packages/matplotlib/axes/_base.py in __call__(self, data, *args, **kwargs) 310 this += args[0], 311 args = args[1:] --&gt; 312 yield from self._plot_args(this, kwargs) 313 314 def get_next_color(self): ~/anaconda3/envs/py37/lib/python3.7/site-packages/matplotlib/axes/_base.py in _plot_args(self, tup, kwargs, return_kwargs) 447 # xy is tup with fmt stripped (could still be (y,) only) 448 *xy, fmt = tup --&gt; 449 linestyle, marker, color = _process_plot_format(fmt) 450 elif len(tup) == 3: 451 raise ValueError(&#39;third arg must be a format string&#39;) ~/anaconda3/envs/py37/lib/python3.7/site-packages/matplotlib/axes/_base.py in _process_plot_format(fmt) 171 if linestyle is not None: 172 raise ValueError( --&gt; 173 &#39;Illegal format string &#34;%s&#34;; two linestyle symbols&#39; % fmt) 174 linestyle = fmt[i:i+2] 175 i += 2 ValueError: Illegal format string &#34;--:&#34;; two linestyle symbols . plt.plot(x,y,&#39;rb&#39;) . ValueError Traceback (most recent call last) /tmp/ipykernel_105674/3007505469.py in &lt;module&gt; -&gt; 1 plt.plot(x,y,&#39;rb&#39;) ~/anaconda3/envs/py37/lib/python3.7/site-packages/matplotlib/pyplot.py in plot(scalex, scaley, data, *args, **kwargs) 2767 return gca().plot( 2768 *args, scalex=scalex, scaley=scaley, -&gt; 2769 **({&#34;data&#34;: data} if data is not None else {}), **kwargs) 2770 2771 ~/anaconda3/envs/py37/lib/python3.7/site-packages/matplotlib/axes/_axes.py in plot(self, scalex, scaley, data, *args, **kwargs) 1633 &#34;&#34;&#34; 1634 kwargs = cbook.normalize_kwargs(kwargs, mlines.Line2D) -&gt; 1635 lines = [*self._get_lines(*args, data=data, **kwargs)] 1636 for line in lines: 1637 self.add_line(line) ~/anaconda3/envs/py37/lib/python3.7/site-packages/matplotlib/axes/_base.py in __call__(self, data, *args, **kwargs) 310 this += args[0], 311 args = args[1:] --&gt; 312 yield from self._plot_args(this, kwargs) 313 314 def get_next_color(self): ~/anaconda3/envs/py37/lib/python3.7/site-packages/matplotlib/axes/_base.py in _plot_args(self, tup, kwargs, return_kwargs) 447 # xy is tup with fmt stripped (could still be (y,) only) 448 *xy, fmt = tup --&gt; 449 linestyle, marker, color = _process_plot_format(fmt) 450 elif len(tup) == 3: 451 raise ValueError(&#39;third arg must be a format string&#39;) ~/anaconda3/envs/py37/lib/python3.7/site-packages/matplotlib/axes/_base.py in _process_plot_format(fmt) 189 if color is not None: 190 raise ValueError( --&gt; 191 &#39;Illegal format string &#34;%s&#34;; two color symbols&#39; % fmt) 192 color = c 193 i += 1 ValueError: Illegal format string &#34;rb&#34;; two color symbols . - 예시5: 색이 사실 8개만 있는건 아니다. . ref: https://matplotlib.org/2.0.2/examples/color/named_colors.html . plt.plot(x,y,&#39;--&#39;,color=&#39;lime&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f3b2511edd0&gt;] . - 예시6: 색을 바꾸려면 Hex코드를 밖아 넣는 방법이 젤 깔끔함 . ref: https://htmlcolorcodes.com/ . plt.plot(x,y,color=&#39;#277E41&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f3b2502dd90&gt;] . - 예시7: 당연히 라인스타일도 4개만 있진 않겠지 . ref: https://matplotlib.org/stable/gallery/lines_bars_and_markers/linestyles.html . plt.plot(x,y,linestyle=&#39;dashed&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f3b2707bd10&gt;] . plt.plot(x,y,linestyle=(0, (20, 5))) . [&lt;matplotlib.lines.Line2D at 0x7f3b240cd110&gt;] . Scatter plot . &#50896;&#47532; . - 그냥 마커를 설정하면 끝! . ref: https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.plot.html . character description . &#39;.&#39; | point marker | . &#39;,&#39; | pixel marker | . &#39;o&#39; | circle marker | . &#39;v&#39; | triangle_down marker | . &#39;^&#39; | triangle_up marker | . &#39;&lt;&#39; | triangle_left marker | . &#39;&gt;&#39; | triangle_right marker | . &#39;1&#39; | tri_down marker | . &#39;2&#39; | tri_up marker | . &#39;3&#39; | tri_left marker | . &#39;4&#39; | tri_right marker | . &#39;8&#39; | octagon marker | . &#39;s&#39; | square marker | . &#39;p&#39; | pentagon marker | . &#39;P&#39; | plus (filled) marker | . &#39;*&#39; | star marker | . &#39;h&#39; | hexagon1 marker | . &#39;H&#39; | hexagon2 marker | . &#39;+&#39; | plus marker | . &#39;x&#39; | x marker | . &#39;X&#39; | x (filled) marker | . &#39;D&#39; | diamond marker | . &#39;d&#39; | thin_diamond marker | . &#39;|&#39; | vline marker | . &#39;_&#39; | hline marker | . plt.plot(x,y,&#39;o&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f3b23934110&gt;] . &#44592;&#48376;&#54540;&#46991; . - 예시1 . plt.plot(x,y,&#39;.&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f3b237eaa10&gt;] . - 예시2 . plt.plot(x,y,&#39;x&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f3b235f4290&gt;] . &#49353;&#44628;&#48320;&#44221; . - 예시1 . plt.plot(x,y,&#39;or&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f3b2365c2d0&gt;] . - 예시2 . plt.plot(x,y,&#39;db&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f3b234bcb90&gt;] . - 예시3 . plt.plot(x,y,&#39;bx&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f3b233e4b10&gt;] . dot-connected plot . - 예시1: 마커와 라인스타일을 동시에 사용하면 dot-connected plot이 된다. . plt.plot(x,y,&#39;o-&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f3b232f3590&gt;] . - 예시2: 당연히 색도 적용가능함 . plt.plot(x,y,&#39;o--r&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f3b23200550&gt;] . - 예시3: 서로 순서를 바꿔도 상관없다. . plt.plot(x,y,&#39;ro--&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f3b23109590&gt;] . &#50668;&#47084; &#44536;&#47548; &#44536;&#47532;&#44592; . &#44217;&#52432;&#44536;&#47532;&#44592; . - 예시1 . x = np.arange(-5,5,0.1) ϵ = np.random.randn(100) y = 2*x + ϵ . plt.plot(x,y,&#39;.b&#39;) plt.plot(x,2*x,&#39;r&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f3b225d80d0&gt;] . &#46384;&#47196;&#44536;&#47532;&#44592; (subplot) // &#50808;&#50864;&#49464;&#50836; &#51060;&#44144; . - 예시1 . fig, axs = plt.subplots(2) axs[0].plot(x,y,&#39;.b&#39;) axs[1].plot(x,2*x,&#39;r&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f3b225274d0&gt;] . - 예시2 . fig, axs = plt.subplots(2,2) axs[0,0].plot(x,2*x,&#39;--b&#39;) axs[0,1].plot(x,ϵ,&#39;.r&#39;) axs[1,0].plot(x,y,&#39;.r&#39;) axs[1,1].plot(x,y,&#39;.r&#39;) axs[1,1].plot(x,2*x,&#39;-b&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f3b2193f390&gt;] . fig&#50752; axes&#51032; &#51060;&#54644; : matplotlib&#51004;&#47196; &#50612;&#47157;&#44172; &#44536;&#47548;&#51012; &#44536;&#47532;&#45716; &#48169;&#48277; . &#50696;&#51228;1 . - 목표: plt.plot()을 이용하지 않고 아래의 그림을 그려보자. . plt.plot([1,2,3,4],[1,2,4,3],&#39;or--&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f3b1f950a10&gt;] . - 구조: axis $ subset$ axes $ subset$ figure . ref: https://matplotlib.org/stable/gallery/showcase/anatomy.html#sphx-glr-gallery-showcase-anatomy-py . . - 전략: Fig을 만들고 (도화지를 준비) $ to$ axes를 만들고 (네모틀) $ to$ axes에 그림을 그린다. . - 그림객체를 생성한다. . fig = plt.figure() . &lt;Figure size 432x288 with 0 Axes&gt; . fig # 지금은 아무것도 없다. . &lt;Figure size 432x288 with 0 Axes&gt; . - 그림객체에는 여러 인스턴스 + 함수가 있는데 그중에서 axes도 있다. (그런데 그와중에 plot method는 없다) . fig.axes # 비어있는 리스트 . [] . - axes 추가 . fig.add_axes([0,0,1,1]) # (0,0)의 위치에 (1,1)인 액시즈(=네모틀)을 만들어라. . &lt;Axes:&gt; . fig.axes . [&lt;Axes:&gt;] . fig # 도화지안에 네모틀이 들어가 있다. . - 첫번째 액시즈를 ax1로 받음 (원래 axes1이어야하는데 그냥 편의상) . ax1 = fig.axes[0] . id(fig.axes[0]),id(ax1) . (139891930961872, 139891930961872) . - 잠깐만! (fig 오브젝트와 ax1 오브젝트는 포함관계에 있다) . id(fig.axes[0]),id(ax1) . (139891930961872, 139891930961872) . - 또 잠깐만! (fig 오브젝트에는 plot이 없지만 ax1 오브젝트에는 plot이 있다) . set(dir(fig)) &amp; {&#39;plot&#39;} . set() . set(dir(ax1)) &amp; {&#39;plot&#39;} . {&#39;plot&#39;} . - ax1.plot()을 사용하여 그림을 그려보자. . ax1.plot([1,2,3,4],[1,2,4,3],&#39;--or&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f3b1f8f8e10&gt;] . fig . &#50696;&#51228;2: &#50696;&#51228;1&#51032; &#51025;&#50857; . - 예제1상황 . fig . - 여기서 축을 하나 더 추가할거에요 . fig.axes . [&lt;Axes:&gt;] . fig.add_axes([1,1,1,1]) . &lt;Axes:&gt; . fig.axes . [&lt;Axes:&gt;, &lt;Axes:&gt;] . fig . ax1,ax2 = fig.axes . - ax2에 파란선으로 그림을 그리자. . ax2.plot([1,2,3,4],[1,2,4,3],&#39;--ob&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f3b2028e390&gt;] . fig . &#50696;&#51228;3: &#45908; &#51025;&#50857;! (&#48120;&#45768;&#47605;) . - 지금 상황 . fig . - 액시즈를 하나 더 추가 . fig.add_axes([0.65,0.1,0.3,0.3]) . &lt;Axes:&gt; . fig . fig.axes[-1].plot([1,2,3,4],[1,2,4,3],&#39;xr&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f3b1ff16690&gt;] . fig . &#50696;&#51228;4: &#51116;&#54644;&#49437;1 . (ver1) . plt.plot([1,2,3,4],[1,2,4,3]) . [&lt;matplotlib.lines.Line2D at 0x7f3b200c55d0&gt;] . (ver2) . ver1은 사실 아래가 연속적으로 실행된 축약구문임 . fig = plt.figure() fig.add_axes([?,?,?,?]) ax1 = fig.axes[0] ax1.plot([1,2,3,4],[1,2,4,3]) fig . &#50696;&#51228;5: &#51116;&#54644;&#49437;2 . - 아래의 코드도 재해석하자. . fig, axs = plt.subplots(2,2) . fig, axs = plt.subplots(2,2) axs[0,0].plot([1,2,3,4],[1,2,4,3],&#39;.&#39;) axs[0,1].plot([1,2,3,4],[1,2,4,3],&#39;--r&#39;) axs[1,0].plot([1,2,3,4],[1,2,4,3],&#39;o--&#39;) axs[1,1].plot([1,2,3,4],[1,2,4,3],&#39;o--&#39;,color=&#39;lime&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f3b206b2c90&gt;] . - fig, axs = plt.subplots(2,2)의 축약버전을 이해하면된다. . (ver1) . fig, axs = plt.subplots(2,2) . (ver2) . ver1은 사실 아래의 축약! . fig = plt.figure() fig.add_axes([?,?,?,?]) fig.add_axes([?,?,?,?]) fig.add_axes([?,?,?,?]) fig.add_axes([?,?,?,?]) ax1,ax2,ax3,ax4 = fig.axes axs = np.array(((ax1,ax2),(ax3,ax4))) . (ver3) . ver1은 아래와 같이 표현할 수도 있다. . fig = plt.figure() axs = fig.subplots(2,2) . HW . 제출: 이름(학번).ipynb, 이름(학번).html 형태로 정리하여 2개의 파일을 제출할 것 (작성방법 모르면 아래영상참고할것) . 즉 주피터노트북파일과 html파일을 모두 제출할 것 | . . 영상1: 코랩으로 실습하는 경우 | 영상2: local 아나콘다로 실습하는 경우 | . 1. &#50500;&#47000;&#50752; &#44057;&#51008; &#44536;&#47548;&#51012; &#44536;&#47140;&#46972;. . x,y = [1,2,3,4], [1,2,4,3] . . [&lt;matplotlib.lines.Line2D at 0x7f3b1ed2d1d0&gt;] . 2. &#50500;&#47000;&#50752; &#44057;&#51008; &#44536;&#47548;&#51012; &#44536;&#47140;&#46972;. . x,y = [1,2,3,4], [1,2,1,1] . . [&lt;matplotlib.lines.Line2D at 0x7f3b1e8ad0d0&gt;] . 3. &#50500;&#47000;&#50752; &#44057;&#51008; &#44536;&#47548;&#51012; &#44536;&#47140;&#46972;. . x = np.arange(-5,5,0.1) y1 = np.sin(x) y2 = np.sin(2*x) + 2 y3 = np.sin(4*x) + 4 y4 = np.sin(8*x) + 6 . . [&lt;matplotlib.lines.Line2D at 0x7f3b1cf24e10&gt;] .",
            "url": "https://guebin.github.io/DV2022/2022/09/19/(3%EC%A3%BC%EC%B0%A8)-9%EC%9B%9419%EC%9D%BC.html",
            "relUrl": "/2022/09/19/(3%EC%A3%BC%EC%B0%A8)-9%EC%9B%9419%EC%9D%BC.html",
            "date": " • Sep 19, 2022"
        }
        
    
  
    
        ,"post14": {
            "title": "(2주차) 9월14일",
            "content": "&#44053;&#51032;&#50689;&#49345; . . &#52280;&#44256;&#51088;&#47308; . - 넘파이 문법이 약하다면? (reshape, concatenate, stack) . (1) reshape: 아래 링크의 넘파이공부 2단계 reshape 참고 . https://guebin.github.io/IP2022/2022/04/06/(6%EC%A3%BC%EC%B0%A8)-4%EC%9B%946%EC%9D%BC.html | . (2) concatenate, stack: 아래 링크의 넘파이공부 4단계 참고 . https://guebin.github.io/IP2022/2022/04/11/(6%EC%A3%BC%EC%B0%A8)-4%EC%9B%9411%EC%9D%BC.html | . - 주피터에서 !로 시작하는 명령의 기원, 혹은 원리를 알고싶다면? 아래링크에서 3세대 프로그래머의 삶까지 살펴볼 것 . https://guebin.github.io/IP2022/2022/03/28/(4%EC%A3%BC%EC%B0%A8)-3%EC%9B%9428%EC%9D%BC.html | . - import, from ... import ... 등 모듈을 임포트하는 방식이 낯설다면? . https://guebin.github.io/IP2022/2022/04/03/(5%EC%A3%BC%EC%B0%A8)-4%EC%9B%942%EC%9D%BC.html | . &#50724;&#45720; &#48176;&#50872; &#45236;&#50857;? . - 히스토그램의 활용: 정규분포인지 판단 &lt;- 지난시간 내용 . - 히스토그램의 활용2: 이미지 보정! 히스토그램 이퀄라이제이션 &lt;-- 오늘소개할 내용 . imports . !pip install opencv-python . import cv2 import matplotlib.pyplot as plt import pandas as pd import numpy as np . &#51060;&#48120;&#51648;&#51088;&#47308; &#45796;&#50868;&#47196;&#46300; . !wget https://upload.wikimedia.org/wikipedia/commons/0/08/Unequalized_Hawkes_Bay_NZ.jpg img = cv2.imread(&#39;Unequalized_Hawkes_Bay_NZ.jpg&#39;) . --2022-09-14 17:57:58-- https://upload.wikimedia.org/wikipedia/commons/0/08/Unequalized_Hawkes_Bay_NZ.jpg Resolving upload.wikimedia.org (upload.wikimedia.org)... 103.102.166.240, 2001:df2:e500:ed1a::2:b Connecting to upload.wikimedia.org (upload.wikimedia.org)|103.102.166.240|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 110895 (108K) [image/jpeg] Saving to: ‘Unequalized_Hawkes_Bay_NZ.jpg.5’ Unequalized_Hawkes_ 100%[===================&gt;] 108.30K 505KB/s in 0.2s 2022-09-14 17:57:59 (505 KB/s) - ‘Unequalized_Hawkes_Bay_NZ.jpg.5’ saved [110895/110895] . img.shape . (683, 1024, 3) . plt.imshow(img) . &lt;matplotlib.image.AxesImage at 0x7f385c732850&gt; . &#51060;&#48120;&#51648;&#51088;&#47308;&#51032; &#51060;&#54644; . &#48708;&#48128;1: &#51060;&#48120;&#51648;&#45716; &#49324;&#49892; &#49707;&#51088;&#46308;&#51032; &#51665;&#54633;&#51060;&#50632;&#51020;. . - 예시1 . _img1 = np.array([0,30,90,120,150,180,210,240,255]).reshape(3,3) _img1 . array([[ 0, 30, 90], [120, 150, 180], [210, 240, 255]]) . plt.imshow(_img1,cmap=&#39;gray&#39;) plt.colorbar() . &lt;matplotlib.colorbar.Colorbar at 0x7f385a14c450&gt; . - 예시2 . _img2 = np.array([0,20,40,60,80,100,120,140,160]).reshape(3,3) _img2 . array([[ 0, 20, 40], [ 60, 80, 100], [120, 140, 160]]) . plt.imshow(_img2,cmap=&#39;gray&#39;,vmin=0,vmax=255) plt.colorbar() . &lt;matplotlib.colorbar.Colorbar at 0x7f385a04e590&gt; . - 예시3 . _img3 = np.concatenate([_img1,_img2],axis=1) _img3 . array([[ 0, 30, 90, 0, 20, 40], [120, 150, 180, 60, 80, 100], [210, 240, 255, 120, 140, 160]]) . plt.imshow(_img3,cmap=&#39;gray&#39;) . &lt;matplotlib.image.AxesImage at 0x7f3859fda8d0&gt; . &#48708;&#48128;2: &#52860;&#46972;&#51060;&#48120;&#51648;&#45716; red + green + blue &#51032; &#51312;&#54633;&#51004;&#47196; &#54364;&#54788;&#44032;&#45733; (&#45796;&#47480;&#48169;&#49885;&#46020; &#44032;&#45733;) . - 예시1 . r = np.array([0]*25*3).reshape(5,5,3) g = np.array([0]*25*3).reshape(5,5,3) b = np.array([0]*25*3).reshape(5,5,3) . r[:3,:3,0] = 255 g[:3,2:,1] = 255 b[2:,:,2] = 255 . plt.imshow(r) . &lt;matplotlib.image.AxesImage at 0x7f3859f00a50&gt; . plt.imshow(g) . &lt;matplotlib.image.AxesImage at 0x7f3859e8a4d0&gt; . plt.imshow(b) . &lt;matplotlib.image.AxesImage at 0x7f3859e47590&gt; . plt.imshow(r+g+b) . &lt;matplotlib.image.AxesImage at 0x7f3859dd67d0&gt; . - 예시2: R,G,B를 같은 비율로 섞으면 무채색이 된다. . r = np.array([0]*25*3).reshape(5,5,3) g = np.array([0]*25*3).reshape(5,5,3) b = np.array([0]*25*3).reshape(5,5,3) r[:3,:3,0] = 80 g[:3,2:,1] = 80 b[2:,:,2] = 80 . plt.imshow(r+g+b) . &lt;matplotlib.image.AxesImage at 0x7f3859d53610&gt; . - 예시3: 우리가 관심있는 자료 . img.shape . (683, 1024, 3) . img_red = img * 0 img_green = img * 0 img_blue = img * 0 . img_red[...,0] = img[...,0] img_green[...,1] = img[...,1] img_blue[...,2] = img[...,2] . plt.imshow(img_blue) . &lt;matplotlib.image.AxesImage at 0x7f3859ccb750&gt; . &#55176;&#49828;&#53664;&#44536;&#47016; &#51060;&#53252;&#46972;&#51060;&#51228;&#51060;&#49496; . - 이미지를 rgb로 각각 분리하고 각 색깔들의 히스토그램을 그려보자. . plt.hist(img[:,:,0].reshape(-1)) . (array([ 3691., 56282., 235628., 170392., 120545., 60511., 22052., 14354., 15246., 691.]), array([114. , 123.4, 132.8, 142.2, 151.6, 161. , 170.4, 179.8, 189.2, 198.6, 208. ]), &lt;BarContainer object of 10 artists&gt;) . 히스토그램 그림1 | . _fig = plt.hist(img[:,:,0].reshape(-1),bins=255, range=[0,255]) . 히스토그램 그림2 | 120-200 사이에 값이 몰려있음 | 그런데 컴퓨터가 표현가능한 색은 0~255.. | 만약에 120-200까지의 분포된 모양은 그대로 유지하면서 range를 0-255 까지 늘린다면? | . - 분포의 모양은 대략적으로 유지하면서 값을 퍼트리자! . img2_red = cv2.equalizeHist(img[...,0]) . plt.hist(img2_red.reshape(-1)) . (array([59973., 57426., 82721., 73706., 61999., 76539., 72114., 72030., 72601., 70283.]), array([ 0. , 25.5, 51. , 76.5, 102. , 127.5, 153. , 178.5, 204. , 229.5, 255. ]), &lt;BarContainer object of 10 artists&gt;) . _fig=plt.hist(img2_red.reshape(-1),bins=255,range=(0,255)) . - red말고 다른채널에도 이와 같은 변환을 정의한다면? . img2 = np.stack([img2_red,img2_red,img2_red],axis=-1) . plt.imshow(img2) . &lt;matplotlib.image.AxesImage at 0x7f3848570810&gt; . plt.imshow(img) . &lt;matplotlib.image.AxesImage at 0x7f38484eea90&gt; . plt.imshow(np.concatenate([img,img2],axis=1)) . &lt;matplotlib.image.AxesImage at 0x7f3848446ad0&gt; . &#55176;&#49828;&#53664;&#44536;&#47016; &#51060;&#53252;&#46972;&#51060;&#51228;&#51060;&#49496; (&#55121;&#48177;&#48260;&#51204;) . img_black = cv2.imread(&#39;Unequalized_Hawkes_Bay_NZ.jpg&#39;,0) . img_black2 = cv2.equalizeHist(img_black) . plt.imshow(np.concatenate([img_black,img_black2],axis=1),cmap=&#39;gray&#39;) . &lt;matplotlib.image.AxesImage at 0x7f384840bc90&gt; . &#49689;&#51228; . - HE(Histogram Equalization)을 이용하여 아래주소에 저장된 이미지의 명암비를 보존하라 . https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/hw_img.png .",
            "url": "https://guebin.github.io/DV2022/2022/09/14/(2%EC%A3%BC%EC%B0%A8)-9%EC%9B%9414%EC%9D%BC.html",
            "relUrl": "/2022/09/14/(2%EC%A3%BC%EC%B0%A8)-9%EC%9B%9414%EC%9D%BC.html",
            "date": " • Sep 14, 2022"
        }
        
    
  
    
        ,"post15": {
            "title": "(1주차) 9월5일에 대한 보강",
            "content": "&#44053;&#51032;&#50689;&#49345; . . import . import matplotlib.pyplot as plt import numpy as np . boxplot . motivating example . (예제1) 전북고등학교: 평균은 좋은 측정값인가? . - 전북고등학교에서 통계학을 수업하는 A선생님과 B선생님의 있다. A선생님에게서 수업을 들을 학생들의 평균은 79.1이고 B선생님에게서 수업을 들은 학생들의 평균은 78.3이다. . y1=[75,75,76,76,77,77,79,79,79,98] # A선생님에게 통계학을 배운 학생의 점수들 y2=[76,76,77,77,78,78,80,80,80,81] # B선생님에게 통계학을 배운 학생의 점수들 . np.mean(y1),np.mean(y2) . (79.1, 78.3) . - 의사결정: A선생님에게 배운 학생들의 실력이 평균적으로 더 좋을 것이다. . - 평균은 A반(=A선생님에게 통계학을 배운 반)이 더 높다. 그런데 98점을 받은 학생이 A반에 포함되어서 A반이 전체평균이 높게 나온것이고 나머지 학생들은 전체적으로 B반 학생들이 더 시험을 잘 보았다고 해석할 수 있다. . - 교훈: 단순한 평균비교보다 학생들이 받은 점수의 분포를 비교해보는 것이 중요하다. 분포를 살펴보는 방법 중 유용한 방법이 박스플랏이다. . matplotlib&#51004;&#47196; boxplot &#44536;&#47532;&#44592; . - A반 학생들의 박스플랏 그리기 . plt.boxplot(y1) . {&#39;whiskers&#39;: [&lt;matplotlib.lines.Line2D at 0x7f5261164550&gt;, &lt;matplotlib.lines.Line2D at 0x7f5261164810&gt;], &#39;caps&#39;: [&lt;matplotlib.lines.Line2D at 0x7f5261164b50&gt;, &lt;matplotlib.lines.Line2D at 0x7f5261164e90&gt;], &#39;boxes&#39;: [&lt;matplotlib.lines.Line2D at 0x7f5261164310&gt;], &#39;medians&#39;: [&lt;matplotlib.lines.Line2D at 0x7f52609a4250&gt;], &#39;fliers&#39;: [&lt;matplotlib.lines.Line2D at 0x7f52609a4550&gt;], &#39;means&#39;: []} . - B반 학생들의 박스플랏 그리기 . plt.boxplot(y2) . {&#39;whiskers&#39;: [&lt;matplotlib.lines.Line2D at 0x7f52608abc10&gt;, &lt;matplotlib.lines.Line2D at 0x7f52608abf50&gt;], &#39;caps&#39;: [&lt;matplotlib.lines.Line2D at 0x7f52608b32d0&gt;, &lt;matplotlib.lines.Line2D at 0x7f52608b3610&gt;], &#39;boxes&#39;: [&lt;matplotlib.lines.Line2D at 0x7f52608ab910&gt;], &#39;medians&#39;: [&lt;matplotlib.lines.Line2D at 0x7f52608b3990&gt;], &#39;fliers&#39;: [&lt;matplotlib.lines.Line2D at 0x7f52608b3cd0&gt;], &#39;means&#39;: []} . - A반 학생들의 점수와 B반 학생들의 점수를 나란히 박스플랏으로 그리자. . plt.boxplot([y1,y2]) . {&#39;whiskers&#39;: [&lt;matplotlib.lines.Line2D at 0x7f526082bc10&gt;, &lt;matplotlib.lines.Line2D at 0x7f526082bf50&gt;, &lt;matplotlib.lines.Line2D at 0x7f52608413d0&gt;, &lt;matplotlib.lines.Line2D at 0x7f52608416d0&gt;], &#39;caps&#39;: [&lt;matplotlib.lines.Line2D at 0x7f52608322d0&gt;, &lt;matplotlib.lines.Line2D at 0x7f5260832610&gt;, &lt;matplotlib.lines.Line2D at 0x7f5260841a10&gt;, &lt;matplotlib.lines.Line2D at 0x7f5260841d50&gt;], &#39;boxes&#39;: [&lt;matplotlib.lines.Line2D at 0x7f526082b990&gt;, &lt;matplotlib.lines.Line2D at 0x7f5260841090&gt;], &#39;medians&#39;: [&lt;matplotlib.lines.Line2D at 0x7f5260832990&gt;, &lt;matplotlib.lines.Line2D at 0x7f526084d0d0&gt;], &#39;fliers&#39;: [&lt;matplotlib.lines.Line2D at 0x7f5260832cd0&gt;, &lt;matplotlib.lines.Line2D at 0x7f526084d410&gt;], &#39;means&#39;: []} . boxplot&#51060;&#46976;? . - ref: https://github.com/mGalarnyk/Python_Tutorials/blob/master/Statistics/boxplot/box_plot.ipynb . np.random.seed(916170) # connection path is here: https://stackoverflow.com/questions/6146290/plotting-a-line-over-several-graphs mu, sigma = 0, 1 # mean and standard deviation s = np.random.normal(mu, sigma, 1000) fig, axes = plt.subplots(nrows = 1, ncols = 1, figsize=(10, 5)) # rectangular box plot bplot = axes.boxplot(s, vert=False, patch_artist=True, showfliers=True, # This would show outliers (the remaining .7% of the data) positions = [0], boxprops = dict(linestyle=&#39;--&#39;, linewidth=2, color=&#39;Black&#39;, facecolor = &#39;red&#39;, alpha = .4), medianprops = dict(linestyle=&#39;-&#39;, linewidth=2, color=&#39;Yellow&#39;), whiskerprops = dict(linestyle=&#39;-&#39;, linewidth=2, color=&#39;Blue&#39;, alpha = .4), capprops = dict(linestyle=&#39;-&#39;, linewidth=2, color=&#39;Black&#39;), flierprops = dict(marker=&#39;o&#39;, markerfacecolor=&#39;green&#39;, markersize=10, linestyle=&#39;none&#39;, alpha = .4), widths = .3, zorder = 1) axes.set_xlim(-4, 4) plt.xticks(fontsize = 14) axes.set_yticks([]) axes.annotate(r&#39;&#39;, xy=(-.73, .205), xycoords=&#39;data&#39;, xytext=(.66, .205), textcoords=&#39;data&#39;, arrowprops=dict(arrowstyle=&quot;|-|&quot;, connectionstyle=&quot;arc3&quot;) ); axes.text(0, .25, &quot;Interquartile Range n(IQR)&quot;, horizontalalignment=&#39;center&#39;, fontsize=18) axes.text(0, -.21, r&quot;Median&quot;, horizontalalignment=&#39;center&#39;, fontsize=16); axes.text(2.65, -.15, &quot; &quot;Maximum &quot;&quot;, horizontalalignment=&#39;center&#39;, fontsize=18); axes.text(-2.65, -.15, &quot; &quot;Minimum &quot;&quot;, horizontalalignment=&#39;center&#39;, fontsize=18); axes.text(-.68, -.24, r&quot;Q1&quot;, horizontalalignment=&#39;center&#39;, fontsize=18); axes.text(-2.65, -.21, r&quot;(Q1 - 1.5*IQR)&quot;, horizontalalignment=&#39;center&#39;, fontsize=16); axes.text(.6745, -.24, r&quot;Q3&quot;, horizontalalignment=&#39;center&#39;, fontsize=18); axes.text(.6745, -.30, r&quot;(75th Percentile)&quot;, horizontalalignment=&#39;center&#39;, fontsize=12); axes.text(-.68, -.30, r&quot;(25th Percentile)&quot;, horizontalalignment=&#39;center&#39;, fontsize=12); axes.text(2.65, -.21, r&quot;(Q3 + 1.5*IQR)&quot;, horizontalalignment=&#39;center&#39;, fontsize=16); axes.annotate(&#39;Outliers&#39;, xy=(2.93,0.015), xytext=(2.52,0.20), fontsize = 18, arrowprops={&#39;arrowstyle&#39;: &#39;-&gt;&#39;, &#39;color&#39;: &#39;black&#39;, &#39;lw&#39;: 2}, va=&#39;center&#39;); axes.annotate(&#39;Outliers&#39;, xy=(-3.01,0.015), xytext=(-3.41,0.20), fontsize = 18, arrowprops={&#39;arrowstyle&#39;: &#39;-&gt;&#39;, &#39;color&#39;: &#39;black&#39;, &#39;lw&#39;: 2}, va=&#39;center&#39;); . . plotly&#47196; boxplot &#44536;&#47532;&#44592; . - 로컬에서 하기 위해서는 아래를 설치 (코랩은 필요없음) . !pip install plotly !pip install ipywidgets !pip install jupyter-dash !pip install dash !pip install pandas . import plotly.express as px import pandas as pd from IPython.display import HTML . df= pd.DataFrame({&#39;score&#39;:y1+y2,&#39;class&#39;:[&#39;A&#39;]*len(y1) + [&#39;B&#39;]*len(y2)}) df . score class . 0 75 | A | . 1 75 | A | . 2 76 | A | . 3 76 | A | . 4 77 | A | . 5 77 | A | . 6 79 | A | . 7 79 | A | . 8 79 | A | . 9 98 | A | . 10 76 | B | . 11 76 | B | . 12 77 | B | . 13 77 | B | . 14 78 | B | . 15 78 | B | . 16 80 | B | . 17 80 | B | . 18 80 | B | . 19 81 | B | . fig = px.box(df,x=&#39;class&#39;,y=&#39;score&#39;) HTML(fig.to_html(include_plotlyjs=&#39;cdn&#39;,include_mathjax=False)) . . . histogram . motivating example . - 전북고예제에서 우리의 소망: 그냥 A반 B반 중에 어떤 반이 공부를 더 잘하냐? . 보통 이러한 질문은 중심경향값 중 하나를 골라서 비교하면 되었다. | 여기에서 중심경향값이란 데이터 분포의 중심을 보여주는 값으로 자료 전체를 대표할 수 있는 값을 말함. 평균, 중앙값등이 대표적인 중심경향값이다. | . - 전북고예제에서는 &quot;A반 B반 중에서 어떤 반이 공부를 더 잘하냐?&quot; 라는 질문의 대답으로 단순평균비교로는 의미가 없었다. 오히려 결과론적으로 보면 중앙값이 더 타당해 보인다. . - 그런데 사실 생각해보면 중앙값을 기준으로 B반이 공부를 더 잘했다고 주장하는 것도 애매하다. 어쨌든 가장 공부잘한 학생은 A반에 있으니까! (에이 한명 뿐이잖아요? 라고 생각할 수 있는데 그 한명이 2명 3명으로 점점 늘어난다고 생각해보자, 합리적인 기준을 제시할 수 있는가?) . - 사실 &quot;A반 B반중에 누가 더 공부를 잘하냐?&quot; 라는 질문은 굉장히 대답하기 곤란한 질문이다. 왜냐하면 . 이슈1: 단순 평균비교로 이러한 질문에 답을 하기 어렵다. | 이슈2: 박스플랏으로 전체분포를 파악해도 어떠한 반이 더 공부를 잘한다는 기준을 잡는게 애매하다. | . 그런데 특수한 경우에는 &quot;A반 B반중에 누가 더 공부를 잘하냐?&quot; 라는 질문에 대한 대답을 깔끔하게 할 수 있다. . (예제2) 정규분포 전북고등학교: 평균은 좋은 측정값인가? . - A반과 B반의 통계학 성적이 아래와 같다고 하자. . np.random.seed(43052) y1 = np.random.randn(10000) y2 = np.random.randn(10000) + 0.5 . np.mean(y1),np.mean(y2) . (-0.011790879905079434, 0.4979147460611458) . np.mean(y2) - np.mean(y1) . 0.5097056259662253 . y2의 값이 y1의 값보다 전체적으로 0.5097056259662253 정도 높다고 볼 수 있다? . plt.boxplot([y1,y2]) . {&#39;whiskers&#39;: [&lt;matplotlib.lines.Line2D at 0x7f525cf74250&gt;, &lt;matplotlib.lines.Line2D at 0x7f525cf74d10&gt;, &lt;matplotlib.lines.Line2D at 0x7f525cf9ca90&gt;, &lt;matplotlib.lines.Line2D at 0x7f525cf9cf10&gt;], &#39;caps&#39;: [&lt;matplotlib.lines.Line2D at 0x7f525cee43d0&gt;, &lt;matplotlib.lines.Line2D at 0x7f525cee4e90&gt;, &lt;matplotlib.lines.Line2D at 0x7f525dc05c90&gt;, &lt;matplotlib.lines.Line2D at 0x7f525cf29090&gt;], &#39;boxes&#39;: [&lt;matplotlib.lines.Line2D at 0x7f525cf74950&gt;, &lt;matplotlib.lines.Line2D at 0x7f525cf9c310&gt;], &#39;medians&#39;: [&lt;matplotlib.lines.Line2D at 0x7f525cee4a10&gt;, &lt;matplotlib.lines.Line2D at 0x7f525cf27990&gt;], &#39;fliers&#39;: [&lt;matplotlib.lines.Line2D at 0x7f525cee47d0&gt;, &lt;matplotlib.lines.Line2D at 0x7f525cf27690&gt;], &#39;means&#39;: []} . 분포의 모양이 거의 비슷, 왼쪽그림을 컨트롤+C 하여 오른쪽에 붙인다음 0.5정도 y축으로 올린느낌이다! | . - 이러한 상황에서는 &quot;B반의 성적 $ approx$ A반의 성적 + 0.5&quot; 라고 주장해도 큰 무리가 없어보인다. 따라서 이 경우에는 &quot;A반 B반 중에 어떤반이 더 공부를 잘하냐?&quot; 라는 질문에 대하여 &quot;B반이 평균적으로 0.5점정도 더 공부를 잘합니다&quot; 라고 대답해도 괜찮다. . - 결론: 정규분포 분포가정을 한다면 이슈1,2에 대한 문제를 한번에 해결가능함 . - 정규분포가정은 어떻게 할 수 있나? (= 데이터를 보고 어떻게 정규분포라고 알 수 있는가?): 데이터의 히스토그램을 그려서 종 모양이 되는지 확인해본다. (아직 초보단걔라서 이것밖에 모를 수 있어요) . histogram &#51060;&#46976;? . - 히스토그램: X축이 변수의 구간, Y축은 그 구간에 포함된 빈도를 의미하는 그림 . matplotlib&#51004;&#47196; histogram &#44536;&#47532;&#44592; . - 히스토그램의 예시1 . y=[10,11,12,15,16,20,21,22,23,24,25] . plt.hist(y) . (array([2., 1., 0., 1., 1., 0., 1., 1., 2., 2.]), array([10. , 11.5, 13. , 14.5, 16. , 17.5, 19. , 20.5, 22. , 23.5, 25. ]), &lt;BarContainer object of 10 artists&gt;) . plt.hist(y,bins=10) . (array([2., 1., 0., 1., 1., 0., 1., 1., 2., 2.]), array([10. , 11.5, 13. , 14.5, 16. , 17.5, 19. , 20.5, 22. , 23.5, 25. ]), &lt;BarContainer object of 10 artists&gt;) . - 히스토그램 예시2 . plt.hist(y,bins=2) #plt.hist(y,bins=1) . (array([5., 6.]), array([10. , 17.5, 25. ]), &lt;BarContainer object of 2 artists&gt;) . - 히스토그램 예시3 . plt.hist(y,bins=3) . (array([3., 2., 6.]), array([10., 15., 20., 25.]), &lt;BarContainer object of 3 artists&gt;) . 가장 큰 값은 25, 가장 작은 값은 10이므로 range는 15이다. | range / bins = 15 / 3 = 5 이므로 각 구간의 간격은 5이다. | 구간은 [10,15), [15,20), [20,25] 로 나눈다. | 각 구간에 포함된 자료의 수는 3,2,6 이다. | . - 히스토그램 예시4 . plt.hist(y,bins=7) . (array([3., 0., 2., 0., 1., 2., 3.]), array([10. , 12.14285714, 14.28571429, 16.42857143, 18.57142857, 20.71428571, 22.85714286, 25. ]), &lt;BarContainer object of 7 artists&gt;) . 가장 큰 값은 25, 가장 작은 값은 10이므로 range는 15이다. | range / bins = 15 / 7 = 2.142857142857143 이므로 각 구간의 간격은 2.142857142857143이다. | 구간은 [10,12.14285714), [12.14285714,14.28571429,), [22.85714286,25] 로 나눈다. | 각 구간에 포함된 자료의 수는 3,0,2,0,1,2,3 이다. | . - 히스토그램 예시5 . # np.random.seed(43052) # y1 = np.random.randn(10000) # y2 = np.random.randn(10000) + 0.5 plt.hist([y1,y2],bins=50) . (array([[ 1., 1., 3., 0., 2., 4., 9., 14., 16., 33., 44., 54., 95., 136., 168., 243., 293., 327., 406., 514., 531., 606., 664., 661., 719., 641., 622., 587., 531., 486., 385., 312., 249., 188., 150., 91., 66., 47., 33., 20., 19., 13., 8., 4., 2., 1., 0., 1., 0., 0.], [ 0., 0., 0., 1., 0., 3., 2., 5., 5., 6., 10., 23., 26., 43., 78., 104., 123., 158., 244., 284., 374., 396., 468., 542., 595., 680., 701., 715., 636., 592., 590., 496., 437., 394., 323., 250., 194., 145., 123., 75., 49., 38., 29., 20., 11., 3., 3., 4., 1., 1.]]), array([-4.12186916, -3.95213741, -3.78240567, -3.61267392, -3.44294217, -3.27321042, -3.10347867, -2.93374692, -2.76401517, -2.59428342, -2.42455167, -2.25481992, -2.08508817, -1.91535642, -1.74562467, -1.57589292, -1.40616117, -1.23642942, -1.06669767, -0.89696592, -0.72723417, -0.55750243, -0.38777068, -0.21803893, -0.04830718, 0.12142457, 0.29115632, 0.46088807, 0.63061982, 0.80035157, 0.97008332, 1.13981507, 1.30954682, 1.47927857, 1.64901032, 1.81874207, 1.98847382, 2.15820557, 2.32793732, 2.49766906, 2.66740081, 2.83713256, 3.00686431, 3.17659606, 3.34632781, 3.51605956, 3.68579131, 3.85552306, 4.02525481, 4.19498656, 4.36471831]), &lt;a list of 2 BarContainer objects&gt;) . seaborn&#51004;&#47196; histogram &#44536;&#47532;&#44592; . import seaborn as sns . df=pd.DataFrame({&#39;score&#39;:np.concatenate([y1,y2]), &#39;class&#39;:[&#39;A&#39;]*len(y1)+[&#39;B&#39;]*len(y2)}) df . score class . 0 0.383420 | A | . 1 1.084175 | A | . 2 1.142778 | A | . 3 0.307894 | A | . 4 0.237787 | A | . ... ... | ... | . 19995 0.493276 | B | . 19996 0.619512 | B | . 19997 -0.500529 | B | . 19998 1.267551 | B | . 19999 1.004863 | B | . 20000 rows × 2 columns . sns.histplot(df,x=&#39;score&#39;,hue=&#39;class&#39;) . &lt;AxesSubplot:xlabel=&#39;score&#39;, ylabel=&#39;Count&#39;&gt; . plotnine&#51004;&#47196; histogram &#44536;&#47532;&#44592; . from plotnine import * . ggplot(df) + geom_histogram(aes(x=&#39;score&#39;,fill=&#39;class&#39;),position=&#39;identity&#39;,alpha=0.5) . /home/cgb2/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/stat_bin.py:95: PlotnineWarning: &#39;stat_bin()&#39; using &#39;bins = 84&#39;. Pick better value with &#39;binwidth&#39;. . &lt;ggplot: (8749427142589)&gt; . ggplot(df) + geom_histogram(aes(x=&#39;score&#39;,fill=&#39;class&#39;),alpha=0.5) ## 비교를 위해서 관찰만 할것 . /home/cgb2/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/stat_bin.py:95: PlotnineWarning: &#39;stat_bin()&#39; using &#39;bins = 84&#39;. Pick better value with &#39;binwidth&#39;. . &lt;ggplot: (8749427066673)&gt; . plotly&#47196; histogram &#44536;&#47532;&#44592; . import plotly.figure_factory as ff hist_data = [y1, y2] group_labels = [&#39;A&#39;, &#39;B&#39;] # Create distplot with curve_type set to &#39;normal&#39; fig = ff.create_distplot(hist_data, group_labels, bin_size=.2, show_rug=False) HTML(fig.to_html(include_plotlyjs=&#39;cdn&#39;,include_mathjax=False)) . . . &#49689;&#51228; . (1) 자기학번으로 np.random.seed(202043052)를 만들고 . (2) y1, y2 // 10만개의 정규분포를 생성해서 저장 . y1: 평균 0, 표준편차=1 | y2: 평균 1, 표준편차=1 | . (3) plotly 를 활용하여 히스토그램을 겹쳐서 그려보는것. .",
            "url": "https://guebin.github.io/DV2022/2022/09/10/(1%EC%A3%BC%EC%B0%A8)-9%EC%9B%945%EC%9D%BC.html",
            "relUrl": "/2022/09/10/(1%EC%A3%BC%EC%B0%A8)-9%EC%9B%945%EC%9D%BC.html",
            "date": " • Sep 10, 2022"
        }
        
    
  
    
        ,"post16": {
            "title": "(A3) mpl 미세먼지팁",
            "content": "&#44536;&#47548;&#47564; &#48372;&#44256; &#49910;&#51012;&#46412; . plt.plot([1,2,3,4],[2,3,4,5]); . marker size, line width . plt.plot([1,2,3,4],[2,3,4,2],&#39;o&#39;,ms=10) . [&lt;matplotlib.lines.Line2D at 0x7f5883561350&gt;] . plt.plot([1,2,3,4],[2,3,4,5],&#39;--&#39;,lw=10) . [&lt;matplotlib.lines.Line2D at 0x7f5883c04ed0&gt;] . label + legend . plt.plot([1,2,3,4],[1,2,3,2],&#39;--o&#39;,label=&#39;A&#39;) plt.plot([1,2,3,4],[3,2.1,1,3],&#39;--o&#39;,label=&#39;B&#39;) plt.legend() . &lt;matplotlib.legend.Legend at 0x7f5889ead210&gt; . &#49353;&#44628;&#51312;&#51221; (C0,C1,...) . plt.plot([1,2,3,4],[1,2,3,2],&#39;--o&#39;,label=&#39;A&#39;,color=&#39;C1&#39;) plt.plot([1,2,3,4],[3,2.1,1,3],&#39;--o&#39;,label=&#39;B&#39;,color=&#39;C0&#39;) plt.legend() . &lt;matplotlib.legend.Legend at 0x7f588a29ef10&gt; . title &#49444;&#51221; . - (방법1) . plt.plot([1,2,3,4],[1,2,3,2],&#39;--o&#39;,label=&#39;A&#39;,color=&#39;C1&#39;) plt.plot([1,2,3,4],[3,2.1,1,3],&#39;--o&#39;,label=&#39;B&#39;,color=&#39;C0&#39;) plt.legend() plt.title(&#39;title&#39;) . Text(0.5, 1.0, &#39;title&#39;) . - (방법2) . fig, ax = plt.subplots() ax.plot([1,2,3,4],[1,2,3,2],&#39;--o&#39;,label=&#39;A&#39;,color=&#39;C1&#39;) ax.plot([1,2,3,4],[3,2.1,1,3],&#39;--o&#39;,label=&#39;B&#39;,color=&#39;C0&#39;) ax.legend() ax.set_title(&#39;title&#39;) . Text(0.5, 1.0, &#39;title&#39;) . suptitle &#49444;&#51221; . fig, ax = plt.subplots(2,2) ax[0,0].plot([1,2,3,2],&#39;--o&#39;,label=&#39;A&#39;,color=&#39;C0&#39;) ax[0,0].set_title(&#39;(a)&#39;) ax[0,1].plot([3,2.1,1,3],&#39;--o&#39;,label=&#39;B&#39;,color=&#39;C1&#39;) ax[0,1].set_title(&#39;(b)&#39;) ax[1,0].plot([-3,-2.1,-1,-3],&#39;--o&#39;,label=&#39;B&#39;,color=&#39;C2&#39;) ax[1,0].set_title(&#39;(c)&#39;) ax[1,1].plot([3,-2.1,1,-3],&#39;--o&#39;,label=&#39;B&#39;,color=&#39;C3&#39;) ax[1,1].set_title(&#39;(d)&#39;) #plt.suptitle(&#39;suptitle&#39;) fig.suptitle(&#39;suptitle&#39;) . Text(0.5, 0.98, &#39;suptitle&#39;) . tight_layout() . fig . fig.tight_layout() . fig . fig, ax, plt &#49548;&#49549; . - 일단 그림 하나 그리고 이야기좀 해보자. . fig, ax = plt.subplots() ax.plot([1,2,3,1]) . [&lt;matplotlib.lines.Line2D at 0x7efe4bdd9950&gt;] . - fig에는 있고 ax에는 없는 것 . add_axes, tight_layout, suptitle, ... . - ax에는 있고 fig에는 없는 것 . boxplot, hist, plot, set_title, ... . - plt는 대부분 다 있음. (의미상 명확한건 대충 알아서 fig, ax에 접근해서 처리해준다) . plt.tight_layout, plt.suptitle, plt.boxplot, plt.hist, plot.plot | plt.set_title 은 없지만 plt.title 은 있음 | plt.add_axes 는 없음.. | . x&#52629;, y&#52629; label &#49444;&#51221; . ax.xaxis.set_label_text(&#39;xlabel&#39;,size=16,family=&#39;serif&#39;,weight=1000,style=&#39;italic&#39;) #_fontsettings={&#39;size&#39;:16,&#39;family&#39;:&#39;serif&#39;,&#39;weight&#39;=1000,&#39;style&#39;:&#39;italic&#39;} #ax.xaxis.set_label_text(&#39;xlabel&#39;,_fontsettings) fig . 폰트ref . size: | fontweight: 0~1000 | family: &#39;serif&#39;, &#39;sans-serif&#39;, &#39;monospace&#39; | style: &#39;normal&#39;, &#39;italic&#39; | . ax.set_ylabel(&#39;ylabel&#39;,size=16) fig . Latex . - 예시1 . import numpy as np import matplotlib.pyplot as plt . x1= np.linspace(-2,2,1000) y1= (x1-1)**2 fig, ax = plt.subplots() ax.plot(x1,y1,&#39;--&#39;) ax.set_title(&#39;$y_1=(x_1-1)^2$&#39;) . Text(0.5, 1.0, &#39;$y_1=(x_1-1)^2$&#39;) . - 예시2 . x1 = np.linspace(-2,2,1000) y1 = 0.5*(x1-1)**2 fig, ax = plt.subplots() ax.plot(x1,y1,&#39;--&#39;) ax.set_title(r&#39;$y_1= frac{1}{2}(x_1-1)^2$&#39;,size=20); . - 예시3 . x1 = np.linspace(-2,2,1000) y1 = 0.5*(x1-1)**2 fig, ax = plt.subplots() ax.plot(x1,y1,&#39;--&#39;) ax.set_title(r&#39;$y_1= frac{1}{2}(x_1-1)^2$&#39;,size=20) ax.set_xlabel(r&#39;$x_1$&#39;,size=15) ax.set_ylabel(r&#39;$y_1$&#39;,size=15); . - 예시4 . x1 = np.linspace(-2,2,1000) y1 = 0.5*(x1-1)**2 y2 = 0.5*(x1+1)**2 fig, ax = plt.subplots() ax.plot(x1,y1,&#39;--&#39;,label=r&#39;$ frac{1}{2}(x-1)^2$&#39;) ax.plot(x1,y2,&#39;--&#39;,label=r&#39;$ frac{1}{2}(x+1)^2$&#39;) ax.legend() . &lt;matplotlib.legend.Legend at 0x7f0076915510&gt; . fig.subplots() . fig,ax = plt.subplots(2,2) ax[0,0].plot([1,2,4,3],&#39;o&#39;,color=&#39;C0&#39;) ax[0,1].plot([1,2,4,3],&#39;o&#39;,color=&#39;C1&#39;) ax[1,0].plot([1,2,4,3],&#39;o&#39;,color=&#39;C2&#39;) ax[1,1].plot([1,2,4,3],&#39;o&#39;,color=&#39;C3&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f007c350e10&gt;] . fig = plt.figure() ax = fig.subplots(2,2) ax[0,0].plot([1,2,4,3],&#39;o&#39;,color=&#39;C0&#39;) ax[0,1].plot([1,2,4,3],&#39;o&#39;,color=&#39;C1&#39;) ax[1,0].plot([1,2,4,3],&#39;o&#39;,color=&#39;C2&#39;) ax[1,1].plot([1,2,4,3],&#39;o&#39;,color=&#39;C3&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f007cfcce90&gt;] . plt.subplot . 끝에 s가 없어요!! | . - 기능1: 몰라도 됩니당.. (아마도) . - 기능2: 특이해요.. fig를 안받아도 무방함 . ax1 = plt.subplot(221) ax2 = plt.subplot(222) ax3 = plt.subplot(223) ax4 = plt.subplot(224) ax1.plot([1,2,4,3],&#39;o&#39;,color=&#39;C0&#39;);ax1.set_title(&#39;221&#39;) ax2.plot([1,2,4,3],&#39;o&#39;,color=&#39;C1&#39;);ax2.set_title(&#39;222&#39;) ax3.plot([1,2,4,3],&#39;o&#39;,color=&#39;C2&#39;);ax3.set_title(&#39;223&#39;) ax4.plot([1,2,4,3],&#39;o&#39;,color=&#39;C3&#39;);ax4.set_title(&#39;224&#39;) fig=plt.gcf() fig.suptitle(&quot;plt.subplot(22x)&quot;,size=15) fig.tight_layout() . 위는 아래와 같은 코드임 . fig = plt.figure() ax1 = fig.add_subplot(221) ax2 = fig.add_subplot(222) ax3 = fig.add_subplot(223) ax4 = fig.add_subplot(224) ax1.plot([1,2,4,3],&#39;o&#39;,color=&#39;C0&#39;);ax1.set_title(&#39;221&#39;) ax2.plot([1,2,4,3],&#39;o&#39;,color=&#39;C1&#39;);ax2.set_title(&#39;222&#39;) ax3.plot([1,2,4,3],&#39;o&#39;,color=&#39;C2&#39;);ax3.set_title(&#39;223&#39;) ax4.plot([1,2,4,3],&#39;o&#39;,color=&#39;C3&#39;);ax4.set_title(&#39;224&#39;) fig.tight_layout() fig.suptitle(&quot;fig.add_subplot(22x)&quot;,size=15) fig.tight_layout() . - fig.add_subplot() vs fig.add_axes() . fig.add_subplot(): 입력으로 nrows, ncols, index 전달 (편하게 쓰기엔 좋아) | fig.add_axes(): 입력으로 left, bottom, width, height 전달 (이상한 그래프 만들기 좋아) | . - plt.subplots() vs plt.subplot() . plt.subplots(): 넣을 수 있는 액시즈 종류가 한가지 | plt.subplot(): 여러 (특이한) 액시즈를 넣을 수 있음 | . (기본액시즈) . plt.subplot(111,projection=None) . &lt;AxesSubplot:&gt; . (3d 액시즈) . ax=plt.subplot(111,projection=&#39;3d&#39;) ax.plot([1,2,3,4],[1,2,-3,4],[1,2,-3,-4],&#39;--o&#39;) fig=plt.gcf() fig.set_figheight(12) . (polar 액시즈) . ax=plt.subplot(111,projection=&#39;polar&#39;) r = np.linspace(0,5,100) theta = np.linspace(0,2*np.pi,100) ax.plot(theta,r) . [&lt;matplotlib.lines.Line2D at 0x7f007e52e650&gt;] .",
            "url": "https://guebin.github.io/DV2022/2022/09/06/(A3)-MPL-%EB%AF%B8%EC%84%B8%EB%A8%BC%EC%A7%80%ED%8C%81.html",
            "relUrl": "/2022/09/06/(A3)-MPL-%EB%AF%B8%EC%84%B8%EB%A8%BC%EC%A7%80%ED%8C%81.html",
            "date": " • Sep 6, 2022"
        }
        
    
  
    
        ,"post17": {
            "title": "(A2) 데이터시각화 강의소개",
            "content": "&#44596;&#44553;&#44277;&#51648; . - 강의실 변경: (221 $ to$ 227 (?)) . - 노트북 지참필수 . 노트북이 없으면? 자연대 2호관 121호 빅데이터사업단, 조성균 선생님 (063-219-5627) 에게 (1) 신분증(or 학생증) (2) 시간표를 출력하여 방문할 시 한학기 동안 대여 가능 | . - 휴강: 9월5일, 7일, 12일 휴강 -&gt; 강의영상업로드로 보충 . &#51068;&#48152;&#44277;&#51648; . - 강의노트는 어디에? . 2022년 강의노트 | 2021년 강의노트 &lt;- 2021년 중간고사/기말고사 기출문제 + 풀이포함 | . - 학점은 어떻게? . F가 나갈 수 있음!! | . - 출석? . 고민중 | . - 질문하는 방법? (여기로 가서 적당한 방법으로) . 인사생략하고 용건만 간단히! | . &#51452;&#51032;&#49324;&#54637; (&#51060; &#49688;&#50629;&#51012; &#46307;&#51648; &#47568;&#50500;&#50556; &#54624; &#51060;&#50976;?) . - 시험문제의 난이도 . - 수업시간이 너무 길다 . - 재미없음 . - cost-effective 하지 않음.. (특히 파이썬입문을 듣지 않았다면!) .",
            "url": "https://guebin.github.io/DV2022/2022/09/05/(A2)-%EA%B0%95%EC%9D%98%EC%86%8C%EA%B0%9C.html",
            "relUrl": "/2022/09/05/(A2)-%EA%B0%95%EC%9D%98%EC%86%8C%EA%B0%9C.html",
            "date": " • Sep 5, 2022"
        }
        
    
  
    
        ,"post18": {
            "title": "(A1) 깃허브와 fastpages를 이용하여 블로그 개설하기",
            "content": "About this doc . - 본 포스트는 2021년 1학기 Python 입문 강의내용중 일부를 업로드 하였음. . - Github, fastpages를 사용하여 블로그를 개설하고 관리하는 방법에 대한 설명임. . .",
            "url": "https://guebin.github.io/DV2022/2021/08/17/(A1)-%EA%B9%83%ED%97%88%EB%B8%8C%EC%99%80-fastpages%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%98%EC%97%AC-%EB%B8%94%EB%A1%9C%EA%B7%B8-%EA%B0%9C%EC%84%A4%ED%95%98%EA%B8%B0.html",
            "relUrl": "/2021/08/17/(A1)-%EA%B9%83%ED%97%88%EB%B8%8C%EC%99%80-fastpages%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%98%EC%97%AC-%EB%B8%94%EB%A1%9C%EA%B7%B8-%EA%B0%9C%EC%84%A4%ED%95%98%EA%B8%B0.html",
            "date": " • Aug 17, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "최규빈 . guebin@jbnu.ac.kr | 자연과학대학교 본관 205호 | 카카오톡 오픈채널1 | . 2022년 2학기 종료 후 폐쇄 예정 &#8617; . |",
          "url": "https://guebin.github.io/DV2022/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://guebin.github.io/DV2022/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}